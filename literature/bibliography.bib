@inproceedings{10.1007/978-3-642-15561-1_16,
    abstract  = {Domain adaptation is an important emerging topic in computer vision. In this paper, we present one of the first studies of domain shift in the context of object recognition. We introduce a method that adapts object models acquired in a particular visual domain to new imaging conditions by learning a transformation that minimizes the effect of domain-induced changes in the feature distribution. The transformation is learned in a supervised manner and can be applied to categories for which there are no labeled examples in the new domain. While we focus our evaluation on object recognition tasks, the transform-based adaptation technique we develop is general and could be applied to non-image data. Another contribution is a new multi-domain object database, freely available for download. We experimentally demonstrate the ability of our method to improve recognition on categories with few or no target domain labels and moderate to large changes in the imaging conditions.},
    address   = {Berlin, Heidelberg},
    author    = {Saenko, Kate
                 and Kulis, Brian
                 and Fritz, Mario
                 and Darrell, Trevor},
    booktitle = {Computer Vision -- ECCV 2010},
    doi       = {10.1007/978-3-642-15561-1_16},
    editor    = {Daniilidis, Kostas
                 and Maragos, Petros
                 and Paragios, Nikos},
    isbn      = {978-3-642-15561-1},
    pages     = {213--226},
    publisher = {Springer Berlin Heidelberg},
    title     = {Adapting Visual Category Models to New Domains},
    year      = {2010}
}
@article{10.1007/s10489-018-1150-1,
    abstract   = {In recent years, crowd counting in still images has attracted many research interests due to its applications in public safety. However, it remains a challenging task for reasons of perspective and scale variations. In this paper, we propose an effective Skip-connection Convolutional Neural Network (SCNN) for crowd counting to overcome the issue of scale variations. The proposed SCNN architecture consists of several multi-scale units to extract multi-scale features. Each multi-scale unit including three convolutional layers builds connections between the input and each convolutional layer. In addition, we propose a scale-related training method to improve the accuracy and robustness of crowd counting. We evaluate our method on three crowd counting benchmarks. Experimental results verify the efficiency of the proposed method, and it achieves superior performance compared with other methods.},
    address    = {USA},
    author     = {Wang, Luyang and Yin, Baoqun and Guo, Aixin and Ma, Hao and Cao, Jie},
    doi        = {10.1007/s10489-018-1150-1},
    issn       = {0924-669X},
    issue_date = {October   2018},
    journal    = {Applied Intelligence},
    keywords   = {Convolutional neural network, Multi-scale unit, Crowd counting, Scale-related training method},
    month      = {10},
    number     = {10},
    numpages   = {12},
    pages      = {3360–3371},
    publisher  = {Kluwer Academic Publishers},
    title      = {Skip-Connection Convolutional Neural Network for Still Image Crowd Counting},
    volume     = {48},
    year       = {2018}
}
@article{10.1093/nsr/nwx105,
    abstract = {{As a promising area in machine learning, multi-task learning (MTL) aims to improve the performance of multiple related learning tasks by leveraging useful information among them. In this paper, we give an overview of MTL by first giving a definition of MTL. Then several different settings of MTL are introduced, including multi-task supervised learning, multi-task unsupervised learning, multi-task semi-supervised learning, multi-task active learning, multi-task reinforcement learning, multi-task online learning and multi-task multi-view learning. For each setting, representative MTL models are presented. In order to speed up the learning process, parallel and distributed MTL models are introduced. Many areas, including computer vision, bioinformatics, health informatics, speech, natural language processing, web applications and ubiquitous computing, use MTL to improve the performance of the applications involved and some representative works are reviewed. Finally, recent theoretical analyses for MTL are presented.}},
    author   = {Zhang, Yu and Yang, Qiang},
    doi      = {10.1093/nsr/nwx105},
    issn     = {2095-5138},
    journal  = {National Science Review},
    month    = {09},
    number   = {1},
    pages    = {30-43},
    title    = {{An overview of multi-task learning}},
    volume   = {5},
    year     = {2017}
}
@article{10.1093/nsr/nwx106,
    abstract = {{Supervised learning techniques construct predictive models by learning from a large number of training examples, where each training example has a label indicating its ground-truth output. Though current techniques have achieved great success, it is noteworthy that in many tasks it is difficult to get strong supervision information like fully ground-truth labels due to the high cost of the data-labeling process. Thus, it is desirable for machine-learning techniques to work with weak supervision. This article reviews some research progress of weakly supervised learning, focusing on three typical types of weak supervision: incomplete supervision, where only a subset of training data is given with labels; inexact supervision, where the training data are given with only coarse-grained labels; and inaccurate supervision, where the given labels are not always ground-truth.}},
    author   = {Zhou, Zhi-Hua},
    doi      = {10.1093/nsr/nwx106},
    eprint   = {https://academic.oup.com/nsr/article-pdf/5/1/44/31567770/nwx106.pdf},
    issn     = {2095-5138},
    journal  = {National Science Review},
    month    = {08},
    number   = {1},
    pages    = {44-53},
    title    = {{A brief introduction to weakly supervised learning}},
    volume   = {5},
    year     = {2017}
}
@inproceedings{10.1145/2818346.2830593,
    abstract  = {This paper presents the techniques employed in our team's submissions to the 2015 Emotion Recognition in the Wild contest, for the sub-challenge of Static Facial Expression Recognition in the Wild. The objective of this sub-challenge is to classify the emotions expressed by the primary human subject in static images extracted from movies. We follow a transfer learning approach for deep Convolutional Neural Network (CNN) architectures. Starting from a network pre-trained on the generic ImageNet dataset, we perform supervised fine-tuning on the network in a two-stage process, first on datasets relevant to facial expressions, followed by the contest's dataset. Experimental results show that this cascading fine-tuning approach achieves better results, compared to a single stage fine-tuning with the combined datasets. Our best submission exhibited an overall accuracy of 48.5{\%} in the validation set and 55.6{\%} in the test set, which compares favorably to the respective 35.96{\%} and 39.13{\%} of the challenge baseline.},
    author    = {Ng, Hong-Wei and Nguyen, Viet Dung and Vonikakis, Vassilios and Winkler, Stefan},
    booktitle = {Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},
    doi       = {10.1145/2818346.2830593},
    isbn      = {9781450339124},
    keywords  = {emotion classification, facial expression analysis, deep learning networks},
    location  = {Seattle, Washington, USA},
    numpages  = {7},
    pages     = {443–449},
    publisher = {Association for Computing Machinery},
    series    = {ICMI '15},
    title     = {Deep Learning for Emotion Recognition on Small Datasets Using Transfer Learning},
    year      = {2015}
}
@inproceedings{10.1145/3341016.3341020,
    abstract  = {Augment the training data has a significant effect for deep learning on small-scale dataset. For practical semantic segmentation applications, it is a hard work to collect and annotate enough training data for training the deep neural network. In this paper, we focus on which data augmentation (DA) method is better, and what combination of different DA methods can improve the network performance more. Our target application is highland AI-Ranch which is hard to collect many training data. We firstly collect and produce a small-scale open source of sheep segmentation dataset including hundreds images, referred to as SSG dataset. Seven frequently used data augmentation methods are evaluated, including global augmentation (augment for the whole image) such as flipping, and local augmentation (augment only for the region of interest) such as cropping, etc. Especially, a novel image compression global DA method is proposed which can achieve the best augmentation performance in global methods. Furthermore, we explore the performance of the cross-combination data augmentation technique when applying to a small-scale semantic segmentation dataset. As different DA method will cover the different sample distribution, more augmentation fed more good training data and meanwhile more bad training data to the network. Therefore, too much augmentation may pull down the performance sometimes. Experiment results show that the combination of compression, cropping and local shift can achieve the best augmentation performance for our AI-Ranch application, the average coverage mean-IoU improve from 73.3{\%} to 91.3{\%}, even better than the combination of whole augmentation methods.},
    author    = {Ma, Rui and Tao, Pin and Tang, Huiyun},
    booktitle = {Proceedings of the 2nd International Conference on Control and Computer Vision},
    doi       = {10.1145/3341016.3341020},
    isbn      = {9781450363228},
    keywords  = {cross-combination, semantic segmentation, data augmentation},
    location  = {Jeju, Republic of Korea},
    numpages  = {5},
    pages     = {77–81},
    publisher = {Association for Computing Machinery},
    series    = {ICCCV '19},
    title     = {Optimizing Data Augmentation for Semantic Segmentation on Small-Scale Dataset},
    year      = {2019}
}
@article{10.1145/3448250,
    abstract   = {How can neural networks learn the rich internal representations required for difficult tasks such as recognizing objects or understanding language?},
    address    = {New York, NY, USA},
    author     = {Bengio, Yoshua and Lecun, Yann and Hinton, Geoffrey},
    doi        = {10.1145/3448250},
    issn       = {0001-0782},
    issue_date = {July 2021},
    journal    = {Commun. ACM},
    month      = {06},
    number     = {7},
    numpages   = {8},
    pages      = {58–65},
    publisher  = {Association for Computing Machinery},
    title      = {Deep Learning for AI},
    volume     = {64},
    year       = {2021}
}
@article{10.1145/3457607,
    abstract   = {With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
    address    = {New York, NY, USA},
    articleno  = {115},
    author     = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
    doi        = {10.1145/3457607},
    issn       = {0360-0300},
    issue_date = {July 2022},
    journal    = {ACM Comput. Surv.},
    keywords   = {Fairness and bias in artificial intelligence, natural language processing, deep learning, representation learning, machine learning},
    month      = {07},
    number     = {6},
    numpages   = {35},
    publisher  = {Association for Computing Machinery},
    title      = {A Survey on Bias and Fairness in Machine Learning},
    volume     = {54},
    year       = {2021}
}
@article{10.1145/3472291,
    abstract   = {Active learning (AL) attempts to maximize a model’s performance gain while annotating the fewest samples possible. Deep learning (DL) is greedy for data and requires a large amount of data supply to optimize a massive number of parameters if the model is to learn how to extract high-quality features. In recent years, due to the rapid development of internet technology, we have entered an era of information abundance characterized by massive amounts of available data. As a result, DL has attracted significant attention from researchers and has been rapidly developed. Compared with DL, however, researchers have a relatively low interest in AL. This is mainly because before the rise of DL, traditional machine learning requires relatively few labeled samples, meaning that early AL is rarely according the value it deserves. Although DL has made breakthroughs in various fields, most of this success is due to a large number of publicly available annotated datasets. However, the acquisition of a large number of high-quality annotated datasets consumes a lot of manpower, making it unfeasible in fields that require high levels of expertise (such as speech recognition, information extraction, medical images, etc.). Therefore, AL is gradually coming to receive the attention it is due.It is therefore natural to investigate whether AL can be used to reduce the cost of sample annotation while retaining the powerful learning capabilities of DL. As a result of such investigations, deep active learning (DeepAL) has emerged. Although research on this topic is quite abundant, there has not yet been a comprehensive survey of DeepAL-related works; accordingly, this article aims to fill this gap. We provide a formal classification method for the existing work, along with a comprehensive and systematic overview. In addition, we also analyze and summarize the development of DeepAL from an application perspective. Finally, we discuss the confusion and problems associated with DeepAL and provide some possible development directions.},
    address    = {New York, NY, USA},
    articleno  = {180},
    author     = {Ren, Pengzhen and Xiao, Yun and Chang, Xiaojun and Huang, Po-Yao and Li, Zhihui and Gupta, Brij B. and Chen, Xiaojiang and Wang, Xin},
    doi        = {10.1145/3472291},
    issn       = {0360-0300},
    issue_date = {December 2022},
    journal    = {ACM Comput. Surv.},
    keywords   = {Deep learning, active learning, deep active learning},
    month      = {10},
    number     = {9},
    numpages   = {40},
    publisher  = {Association for Computing Machinery},
    title      = {A Survey of Deep Active Learning},
    volume     = {54},
    year       = {2021}
}

@article{10.1371/journal.pone.0263656,
    abstract  = {Deep learning increasingly accelerates biomedical research, deploying neural networks for multiple tasks, such as image classification, object detection, and semantic segmentation. However, neural networks are commonly trained supervised on large-scale, labeled datasets. These prerequisites raise issues in biomedical image recognition, as datasets are generally small-scale, challenging to obtain, expensive to label, and frequently heterogeneously labeled. Furthermore, heterogeneous labels are a challenge for supervised methods. If not all classes are labeled for an individual sample, supervised deep learning approaches can only learn on a subset of the dataset with common labels for each individual sample; consequently, biomedical image recognition engineers need to be frugal concerning their label and ground truth requirements. This paper discusses the effects of frugal labeling and proposes to train neural networks for multi-class semantic segmentation on heterogeneously labeled data based on a novel objective function. The objective function combines a class asymmetric loss with the Dice loss. The approach is demonstrated for training on the sparse ground truth of a heterogeneous labeled dataset, training within a transfer learning setting, and the use-case of merging multiple heterogeneously labeled datasets. For this purpose, a biomedical small-scale, multi-class semantic segmentation dataset is utilized. The heartSeg dataset is based on the medaka fish’s position as a cardiac model system. Automating image recognition and semantic segmentation enables high-throughput experiments and is essential for biomedical research. Our approach and analysis show competitive results in supervised training regimes and encourage frugal labeling within biomedical image recognition.},
    author    = {Schutera, Mark AND Rettenberger, Luca AND Pylatiuk, Christian AND Reischl, Markus},
    doi       = {10.1371/journal.pone.0263656},
    journal   = {PLOS ONE},
    month     = {02},
    number    = {2},
    pages     = {1-14},
    publisher = {Public Library of Science},
    title     = {Methods for the frugal labeler: Multi-class semantic segmentation on heterogeneous labels},
    volume    = {17},
    year      = {2022}
}
@article{10.5555/2188385.2188395,
    abstract   = {Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent "High Throughput" methods achieve surprising success--they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
    author     = {Bergstra, James and Bengio, Yoshua},
    doi        = {10.5555/2188385.2188395},
    issn       = {1532-4435},
    issue_date = {3/1/2012},
    journal    = {J. Mach. Learn. Res.},
    keywords   = {deep learning, global optimization, neural networks, model selection, response surface modeling},
    month      = {02},
    number     = {null},
    numpages   = {25},
    pages      = {281–305},
    publisher  = {JMLR.org},
    title      = {Random Search for Hyper-Parameter Optimization},
    volume     = {13},
    year       = {2012}
}
@inproceedings{1434171,
    author    = {Ma Yi-de and Liu Qing and Qian Zhi-bai},
    booktitle = {Proceedings of 2004 International Symposium on Intelligent Multimedia, Video and Speech Processing, 2004.},
    doi       = {10.1109/ISIMP.2004.1434171},
    number    = {},
    pages     = {743-746},
    title     = {Automated image segmentation using improved PCNN model based on cross-entropy},
    volume    = {},
    year      = {2004}
}
@article{392253,
    author  = {Tianping Chen and Hong Chen},
    doi     = {10.1109/72.392253},
    journal = {IEEE Transactions on Neural Networks},
    number  = {4},
    pages   = {911-917},
    title   = {Universal approximation to nonlinear operators by neural networks with arbitrary activation functions and its application to dynamical systems},
    volume  = {6},
    year    = {1995}
}
@inproceedings{4036653,
    author    = {Wu, Yi and Kozintsev, Igor and Bouguet, Jean-yves and Dulong, Carole},
    booktitle = {2006 IEEE International Conference on Multimedia and Expo},
    doi       = {10.1109/ICME.2006.262442},
    number    = {},
    pages     = {529-532},
    title     = {Sampling Strategies for Active Learning in Personal Photo Retrieval},
    volume    = {},
    year      = {2006}
}
@inproceedings{6247757,
    author    = {Vezhnevets, Alexander and Ferrari, Vittorio and Buhmann, Joachim M.},
    booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
    doi       = {10.1109/CVPR.2012.6247757},
    number    = {},
    pages     = {845-852},
    title     = {Weakly supervised structured output learning for semantic segmentation},
    volume    = {},
    year      = {2012}
} 
@article{6945865,
    author  = {van Opbroek, Annegreet and Ikram, M. Arfan and Vernooij, Meike W. and de Bruijne, Marleen},
    doi     = {10.1109/TMI.2014.2366792},
    journal = {IEEE Transactions on Medical Imaging},
    number  = {5},
    pages   = {1018-1030},
    title   = {Transfer Learning Improves Supervised Image Segmentation Across Imaging Protocols},
    volume  = {34},
    year    = {2015}
}
@article{7775087,
    author  = {Wei, Yunchao and Liang, Xiaodan and Chen, Yunpeng and Shen, Xiaohui and Cheng, Ming-Ming and Feng, Jiashi and Zhao, Yao and Yan, Shuicheng},
    doi     = {10.1109/TPAMI.2016.2636150},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    number  = {11},
    pages   = {2314-2320},
    title   = {STC: A Simple to Complex Framework for Weakly-Supervised Semantic Segmentation},
    volume  = {39},
    year    = {2017}
}
@article{7775087,
    author  = {Wei, Yunchao and Liang, Xiaodan and Chen, Yunpeng and Shen, Xiaohui and Cheng, Ming-Ming and Feng, Jiashi and Zhao, Yao and Yan, Shuicheng},
    doi     = {10.1109/TPAMI.2016.2636150},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    number  = {11},
    pages   = {2314-2320},
    title   = {STC: A Simple to Complex Framework for Weakly-Supervised Semantic Segmentation},
    volume  = {39},
    year    = {2017}
}
@inproceedings{8031178,
    author    = {Liu, Ying and Logan, Brent and Liu, Ning and Xu, Zhiyuan and Tang, Jian and Wang, Yangzhi},
    booktitle = {2017 IEEE International Conference on Healthcare Informatics (ICHI)},
    doi       = {10.1109/ICHI.2017.45},
    number    = {},
    pages     = {380-385},
    title     = {Deep Reinforcement Learning for Dynamic Treatment Regimes on Medical Registry Data},
    volume    = {},
    year      = {2017}
}
@inproceedings{8226700,
    author    = {Ramadhan, W.P. and Astri Novianty, S.T.M.T. and Casi Setianingsih, S.T.M.T.},
    booktitle = {2017 International Conference on Control, Electronics, Renewable Energy and Communications (ICCREC)},
    doi       = {10.1109/ICCEREC.2017.8226700},
    number    = {},
    pages     = {46-49},
    title     = {Sentiment analysis using multinomial logistic regression},
    volume    = {},
    year      = {2017}
}
@inproceedings{8354272,
    author    = {Nigam, Ishan and Huang, Chen and Ramanan, Deva},
    booktitle = {2018 IEEE Winter Conference on Applications of Computer Vision (WACV)},
    doi       = {10.1109/WACV.2018.00168},
    number    = {},
    pages     = {1499-1508},
    title     = {Ensemble Knowledge Transfer for Semantic Segmentation},
    volume    = {},
    year      = {2018}
}
@inproceedings{8451495,
    author    = {Siam, Mennatullah and Gamal, Mostafa and Abdel-Razek, Moemen and Yogamani, Senthil and Jagersand, Martin},
    booktitle = {2018 25th IEEE International Conference on Image Processing (ICIP)},
    doi       = {10.1109/ICIP.2018.8451495},
    number    = {},
    pages     = {1603-1607},
    title     = {RTSeg: Real-Time Semantic Segmentation Comparative Study},
    volume    = {},
    year      = {2018}
}
@article{8618415,
    author  = {Gao, Hongyang and Yuan, Hao and Wang, Zhengyang and Ji, Shuiwang},
    doi     = {10.1109/TPAMI.2019.2893965},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    number  = {5},
    pages   = {1218-1227},
    title   = {Pixel Transposed Convolutional Networks},
    volume  = {42},
    year    = {2020}
}

@inproceedings{8675643,
    author    = {Nguyen, Hai and La, Hung},
    booktitle = {2019 Third IEEE International Conference on Robotic Computing (IRC)},
    doi       = {10.1109/IRC.2019.00120},
    number    = {},
    pages     = {590-595},
    title     = {Review of Deep Reinforcement Learning for Robot Manipulation},
    volume    = {},
    year      = {2019}
}
@article{8693644,
    author  = {Ghassemi, Sina and Fiandrotti, Attilio and Francini, Gianluca and Magli, Enrico},
    doi     = {10.1109/TGRS.2019.2906689},
    journal = {IEEE Transactions on Geoscience and Remote Sensing},
    number  = {9},
    pages   = {6517-6529},
    title   = {Learning and Adapting Robust Features for Satellite Image Segmentation on Heterogeneous Data Sets},
    volume  = {57},
    year    = {2019}
}
@inproceedings{8701368,
    author    = {Hu, Yuh-Jong and Lin, Shang-Jen},
    booktitle = {2019 Amity International Conference on Artificial Intelligence (AICAI)},
    doi       = {10.1109/AICAI.2019.8701368},
    number    = {},
    pages     = {14-20},
    title     = {Deep Reinforcement Learning for Optimizing Finance Portfolio Management},
    volume    = {},
    year      = {2019}
}

@article{8756165,
    author  = {Lei, Xinyu and Pan, Hongguang and Huang, Xiangdong},
    doi     = {10.1109/ACCESS.2019.2927169},
    journal = {IEEE Access},
    number  = {},
    pages   = {124087-124095},
    title   = {A Dilated CNN Model for Image Classification},
    volume  = {7},
    year    = {2019}
}

@article{8767031,
    author  = {Karimi, Davood and Salcudean, Septimiu E.},
    doi     = {10.1109/TMI.2019.2930068},
    journal = {IEEE Transactions on Medical Imaging},
    number  = {2},
    pages   = {499-513},
    title   = {Reducing the Hausdorff Distance in Medical Image Segmentation With Convolutional Neural Networks},
    volume  = {39},
    year    = {2020}
}

    @article{8930464,
    author  = {Pan, Shiwen and Zhang, Wei and Zhang, Wanjun and Xu, Liang and Fan, Guohua and Gong, Jianping and Zhang, Bo and Gu, Haibo},
    doi     = {10.1109/ACCESS.2019.2958825},
    journal = {IEEE Access},
    number  = {},
    pages   = {177997-178006},
    title   = {Diagnostic Model of Coronary Microvascular Disease Combined With Full Convolution Deep Network With Balanced Cross-Entropy Cost Function},
    volume  = {7},
    year    = {2019}
}
@inproceedings{8953484,
    author    = {Chen, Xu and Williams, Bryan M. and Vallabhaneni, Srinivasa R. and Czanner, Gabriela and Williams, Rachel and Zheng, Yalin},
    booktitle = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    doi       = {10.1109/CVPR.2019.01190},
    number    = {},
    pages     = {11624-11632},
    title     = {Learning Active Contour Models for Medical Image Segmentation},
    volume    = {},
    year      = {2019}
}
@inproceedings{8970918,
    author    = {Kolarik, Martin and Burget, Radim and Riha, Kamil},
    booktitle = {2019 11th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT)},
    doi       = {10.1109/ICUMT48472.2019.8970918},
    number    = {},
    pages     = {1-5},
    title     = {Upsampling Algorithms for Autoencoder Segmentation Neural Networks: A Comparison Study},
    volume    = {},
    year      = {2019}
}
@inproceedings{8991232,
    author    = {Dhawan, Aashish and Bodani, Pankaj and Garg, Vishal},
    booktitle = {2019 6th International Conference on Computing for Sustainable Global Development (INDIACom)},
    doi       = {},
    number    = {},
    pages     = {729-734},
    title     = {Post Processing of Image Segmentation using Conditional Random Fields},
    volume    = {},
    year      = {2019}
}

@article{9066969,
    author  = {Sinha, Ashish and Dolz, Jose},
    doi     = {10.1109/JBHI.2020.2986926},
    journal = {IEEE Journal of Biomedical and Health Informatics},
    number  = {1},
    pages   = {121-130},
    title   = {Multi-Scale Self-Guided Attention for Medical Image Segmentation},
    volume  = {25},
    year    = {2021}
}
@article{9076866,
    author  = {Mou, Lichao and Hua, Yuansheng and Zhu, Xiao Xiang},
    doi     = {10.1109/TGRS.2020.2979552},
    journal = {IEEE Transactions on Geoscience and Remote Sensing},
    number  = {11},
    pages   = {7557-7569},
    title   = {Relation Matters: Relational Context-Aware Fully Convolutional Network for Semantic Segmentation of High-Resolution Aerial Images},
    volume  = {58},
    year    = {2020}
}
@article{9109297,
    author  = {Wang, Guotai and Liu, Xinglong and Li, Chaoping and Xu, Zhiyong and Ruan, Jiugen and Zhu, Haifeng and Meng, Tao and Li, Kang and Huang, Ning and Zhang, Shaoting},
    doi     = {10.1109/TMI.2020.3000314},
    journal = {IEEE Transactions on Medical Imaging},
    number  = {8},
    pages   = {2653-2663},
    title   = {A Noise-Robust Framework for Automatic Segmentation of COVID-19 Pneumonia Lesions From CT Images},
    volume  = {39},
    year    = {2020}
}
@article{9122009,
    author  = {Cui, Binge and Chen, Xin and Lu, Yan},
    doi     = {10.1109/ACCESS.2020.3003914},
    journal = {IEEE Access},
    number  = {},
    pages   = {116744-116755},
    title   = {Semantic Segmentation of Remote Sensing Images Using Transfer Learning and Deep Convolutional Neural Network With Dense Connection},
    volume  = {8},
    year    = {2020}
} 
@article{9302891,
    author  = {Li, Zeju and Kamnitsas, Konstantinos and Glocker, Ben},
    doi     = {10.1109/TMI.2020.3046692},
    journal = {IEEE Transactions on Medical Imaging},
    number  = {3},
    pages   = {1065-1077},
    title   = {Analyzing Overfitting Under Class Imbalance in Neural Networks for Image Segmentation},
    volume  = {40},
    year    = {2021}
}
@article{9325521,
    author  = {Niu, Shuteng and Liu, Meryl and Liu, Yongxin and Wang, Jian and Song, Houbing},
    doi     = {10.1109/JBHI.2021.3051470},
    journal = {IEEE Journal of Biomedical and Health Informatics},
    number  = {10},
    pages   = {3784-3793},
    title   = {Distant Domain Transfer Learning for Medical Imaging},
    volume  = {25},
    year    = {2021}
} 
@inproceedings{9338261,
    author    = {Zhao, Rongjian and Qian, Buyue and Zhang, Xianli and Li, Yang and Wei, Rong and Liu, Yang and Pan, Yinggang},
    booktitle = {2020 IEEE International Conference on Data Mining (ICDM)},
    doi       = {10.1109/ICDM50108.2020.00094},
    number    = {},
    pages     = {851-860},
    title     = {Rethinking Dice Loss for Medical Image Segmentation},
    volume    = {},
    year      = {2020}
}
@article{9352207,
    author  = {Papadomanolaki, Maria and Vakalopoulou, Maria and Karantzalos, Konstantinos},
    doi     = {10.1109/TGRS.2021.3055584},
    journal = {IEEE Transactions on Geoscience and Remote Sensing},
    number  = {9},
    pages   = {7651-7668},
    title   = {A Deep Multitask Learning Framework Coupling Semantic Segmentation and Fully Convolutional LSTM Networks for Urban Change Detection},
    volume  = {59},
    year    = {2021}
}
@article{9442775,
    author  = {Schmarje, Lars and Santarossa, Monty and Schröder, Simon-Martin and Koch, Reinhard},
    doi     = {10.1109/ACCESS.2021.3084358},
    journal = {IEEE Access},
    number  = {},
    pages   = {82146-82168},
    title   = {A Survey on Semi-, Self- and Unsupervised Learning for Image Classification},
    volume  = {9},
    year    = {2021}
}
@inproceedings{9504761,
    author    = {Alibrahim, Hussain and Ludwig, Simone A.},
    booktitle = {2021 IEEE Congress on Evolutionary Computation (CEC)},
    doi       = {10.1109/CEC45853.2021.9504761},
    number    = {},
    pages     = {1551-1559},
    title     = {Hyperparameter Optimization: Comparing Genetic Algorithm against Grid Search and Bayesian Optimization},
    volume    = {},
    year      = {2021}
}
@article{9513251,
    author  = {Zhao, Qi and Liu, Jiahui and Li, Yuewen and Zhang, Hong},
    doi     = {10.1109/TGRS.2021.3085889},
    journal = {IEEE Transactions on Geoscience and Remote Sensing},
    number  = {},
    pages   = {1-13},
    title   = {Semantic Segmentation With Attention Mechanism for Remote Sensing Images},
    volume  = {60},
    year    = {2022}
}
@article{9609539,
    author  = {Brauwers, Gianni and Frasincar, Flavius},
    doi     = {10.1109/TKDE.2021.3126456},
    journal = {IEEE Transactions on Knowledge and Data Engineering},
    number  = {},
    pages   = {1-1},
    title   = {A General Survey on Attention Mechanisms in Deep Learning},
    volume  = {},
    year    = {2021}
}
@inproceedings{9616331,
    author    = {Sagie, Nimrod and Greenspan, Hayit and Goldberger, Jacob},
    booktitle = {2021 29th European Signal Processing Conference (EUSIPCO)},
    doi       = {10.23919/EUSIPCO54536.2021.9616331},
    number    = {},
    pages     = {985-989},
    title     = {Transfer Learning via Parameter Regularization for Medical Image Segmentation},
    volume    = {},
    year      = {2021}
}
@article{abdi2010principal,
    abstract = {Abstract Principal component analysis (PCA) is a multivariate technique that analyzes a data table in which observations are described by several inter-correlated quantitative dependent variables. Its goal is to extract the important information from the table, to represent it as a set of new orthogonal variables called principal components, and to display the pattern of similarity of the observations and of the variables as points in maps. The quality of the PCA model can be evaluated using cross-validation techniques such as the bootstrap and the jackknife. PCA can be generalized as correspondence analysis (CA) in order to handle qualitative variables and as multiple factor analysis (MFA) in order to handle heterogeneous sets of variables. Mathematically, PCA depends upon the eigen-decomposition of positive semi-definite matrices and upon the singular value decomposition (SVD) of rectangular matrices. Copyright © 2010 John Wiley \& Sons, Inc. This article is categorized under: Statistical and Graphical Methods of Data Analysis > Multivariate Analysis Statistical and Graphical Methods of Data Analysis > Dimension Reduction},
    author   = {Abdi, Hervé and Williams, Lynne J.},
    doi      = {https://doi.org/10.1002/wics.101},
    journal  = {WIREs Computational Statistics},
    keywords = {singular and eigen value decomposition, bilinear decomposition, factor scores and loadings, RESS PRESS, multiple factor analysis},
    number   = {4},
    pages    = {433-459},
    title    = {Principal component analysis},
    volume   = {2},
    year     = {2010}
}
@inproceedings{agarwal2020contextual,
    abstract  = {Requirement of large annotated datasets restrict the use of deep convolutional neural networks (CNNs) for many practical applications. The problem can be mitigated by using active learning (AL) techniques which, under a given annotation budget, allow to select a subset of data that yields maximum accuracy upon fine tuning. State of the art AL approaches typically rely on measures of visual diversity or prediction uncertainty, which are unable to effectively capture the variations in spatial context. On the other hand, modern CNN architectures make heavy use of spatial context for achieving highly accurate predictions. Since the context is difficult to evaluate in the absence of ground-truth labels, we introduce the notion of contextual diversity that captures the confusion associated with spatially co-occurring classes. Contextual Diversity (CD) hinges on a crucial observation that the probability vector predicted by a CNN for a region of interest typically contains information from a larger receptive field. Exploiting this observation, we use the proposed CD measure within two AL frameworks: (1) a core-set based strategy and (2) a reinforcement learning based policy, for active frame selection. Our extensive empirical evaluation establish state of the art results for active learning on benchmark datasets of Semantic Segmentation, Object Detection and Image classification. Our ablation studies show clear advantages of using contextual diversity for active learning. The source code and additional results are available at https://github.com/sharat29ag/CDAL.},
    address   = {Cham},
    author    = {Agarwal, Sharat
                 and Arora, Himanshu
                 and Anand, Saket
                 and Arora, Chetan},
    booktitle = {Computer Vision -- ECCV 2020},
    doi       = {10.48550/arXiv.2008.05723},
    editor    = {Vedaldi, Andrea
                 and Bischof, Horst
                 and Brox, Thomas
                 and Frahm, Jan-Michael},
    isbn      = {978-3-030-58517-4},
    pages     = {137--153},
    publisher = {Springer International Publishing},
    title     = {Contextual Diversity for Active Learning},
    year      = {2020}
} 
@article{Ahn_2018_CVPR,
    author     = {Jiwoon Ahn and
                  Suha Kwak},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1803-10464.bib},
    doi        = {10.48550/arXiv.1803.10464},
    eprint     = {1803.10464},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:48:43 +0200},
    title      = {Learning Pixel-level Semantic Affinity with Image-level Supervision
                  for Weakly Supervised Semantic Segmentation},
    volume     = {abs/1803.10464},
    year       = {2018}
}
@article{akalin2021reinforcement,
    abstract       = {This article surveys reinforcement learning approaches in social robotics. Reinforcement learning is a framework for decision-making problems in which an agent interacts through trial-and-error with its environment to discover an optimal behavior. Since interaction is a key component in both reinforcement learning and social robotics, it can be a well-suited approach for real-world interactions with physically embodied social robots. The scope of the paper is focused particularly on studies that include social physical robots and real-world human-robot interactions with users. We present a thorough analysis of reinforcement learning approaches in social robotics. In addition to a survey, we categorize existent reinforcement learning approaches based on the used method and the design of the reward mechanisms. Moreover, since communication capability is a prominent feature of social robots, we discuss and group the papers based on the communication medium used for reward formulation. Considering the importance of designing the reward function, we also provide a categorization of the papers based on the nature of the reward. This categorization includes three major themes: interactive reinforcement learning, intrinsically motivated methods, and task performance-driven methods. The benefits and challenges of reinforcement learning in social robotics, evaluation methods of the papers regarding whether or not they use subjective and algorithmic measures, a discussion in the view of real-world reinforcement learning challenges and proposed solutions, the points that remain to be explored, including the approaches that have thus far received less attention is also given in the paper. Thus, this paper aims to become a starting point for researchers interested in using and applying reinforcement learning methods in this particular research field.},
    article-number = {1292},
    author         = {Akalin, Neziha and Loutfi, Amy},
    doi            = {10.3390/s21041292},
    issn           = {1424-8220},
    journal        = {Sensors},
    number         = {4},
    pubmedid       = {33670257},
    title          = {Reinforcement Learning Approaches in Social Robotics},
    volume         = {21},
    year           = {2021}
}
@incollection{almuallim2002development,
    abstract  = {Publisher Summary
                 This chapter presents a basic method for automatically constructing decision trees from examples. It reviews various extensions of this basic procedure. The chapter provides a sample of real-world applications for which the decision tree learning approach has been shown to be successful. Considerable effort has been put to develop methods that induce the desired classification knowledge from a given set of pre-classified examples. Constructing classifiers in the form of decision trees has obtained much popularity. Decision trees have the advantage of being comprehensible by human experts and of being directly convertible into production rules. When used to handle a given case, a decision tree not only gives the solution for that case, but also mentions the reasons behind its choice. These features are very important in typical application domains in which human experts seek tools to help them in performing their job. Another advantage of using decision trees is the ease and efficiency of their construction compared to that of other classifiers such as neural networks.},
    address   = {Burlington},
    author    = {Hussein Almuallim and Shigeo Kaneda and Yasuhiro Akiba},
    booktitle = {Expert Systems},
    doi       = {https://doi.org/10.1016/B978-012443880-4/50047-8},
    editor    = {Cornelius T. Leondes},
    isbn      = {978-0-12-443880-4},
    pages     = {53-77},
    publisher = {Academic Press},
    title     = {3 - Development and Applications of Decision Trees},
    year      = {2002}
}
@article{alonso2015challenges,
    abstract   = {Organizations that develop and use technologies around information retrieval, machine learning, recommender systems, and natural language processing depend on labels for engineering and experimentation. These labels, usually gathered via human computation, are used in machine-learned models for prediction and evaluation purposes. In such scenarios, collecting high-quality labels is a very important part of the overall process. We elaborate on these challenges and discuss research directions.},
    address    = {New York, NY, USA},
    articleno  = {2},
    author     = {Alonso, Omar},
    doi        = {10.1145/2724721},
    issn       = {1936-1955},
    issue_date = {March 2015},
    journal    = {J. Data and Information Quality},
    keywords   = {crowdsourcing, Label quality, machine learning, human computation},
    month      = {03},
    number     = {1},
    numpages   = {3},
    publisher  = {Association for Computing Machinery},
    title      = {Challenges with Label Quality for Supervised Learning},
    volume     = {6},
    year       = {2015}
}
@book{alpaydin2020introduction,
    author    = {Alpaydin, Ethem},
    publisher = {MIT press},
    title     = {Introduction to machine learning},
    year      = {2020}
}
@article{app122111248,
    abstract       = {Deep learning has been widely used in various fields because of its accuracy and efficiency. At present, the improvement of image semantic segmentation accuracy has become the area of most concern. In terms of increasing accuracy, improved semantic segmentation models have attracted more attention. In this paper, a hybrid model is proposed to solve the problems of edge splitting and small objects disappearing from complex scene images. The hybrid model consists of three parts: (1) an improved HED network, (2) an improved PSP-Net, (3) an AFF attention mechanism. Continuous edges can be obtained by combining the improved HED network with an improved PSP-Net. The AFF attention mechanism can improve the segmentation effect of small target objects by enhancing its response recognition ability for specific semantic scenes. The experiments were carried out on Cityspaces, SIFT Flow, NYU-V2 and CamVid datasets, and the experimental results show that the segmentation accuracy of our method is improved by 2{\%} for small target objects, and by 3{\%} for scenes with complex object edges.},
    article-number = {11248},
    author         = {Jiao, Yijie and Wang, Xiaohua and Wang, Wenjie and Li, Shuang},
    doi            = {10.3390/app122111248},
    issn           = {2076-3417},
    journal        = {Applied Sciences},
    number         = {21},
    title          = {Image Semantic Segmentation Fusion of Edge Detection and AFF Attention Mechanism},
    volume         = {12},
    year           = {2022}
}
@article{article,
    author  = {Ganaye, Pierre-Antoine and Sdika, Michaël and Triggs, Bill and Benoit-Cattin, Hugues},
    doi     = {10.1016/j.media.2019.101551},
    journal = {Medical Image Analysis},
    month   = {08},
    pages   = {101551},
    title   = {Removing Segmentation Inconsistencies with Semi-Supervised Non-Adjacency Constraint},
    volume  = {58},
    year    = {2019}
} 
@article{asgari2021deep,
    abstract = {The semantic image segmentation task consists of classifying each pixel of an image into an instance, where each instance corresponds to a class. This task is a part of the concept of scene understanding or better explaining the global context of an image. In the medical image analysis domain, image segmentation can be used for image-guided interventions, radiotherapy, or improved radiological diagnostics. In this review, we categorize the leading deep learning-based medical and non-medical image segmentation solutions into six main groups of deep architectural, data synthesis-based, loss function-based, sequenced models, weakly supervised, and multi-task methods and provide a comprehensive review of the contributions in each of these groups. Further, for each group, we analyze each variant of these groups and discuss the limitations of the current approaches and present potential future research directions for semantic image segmentation.},
    author   = {Asgari Taghanaki, Saeid
                and Abhishek, Kumar
                and Cohen, Joseph Paul
                and Cohen-Adad, Julien
                and Hamarneh, Ghassan},
    day      = {01},
    doi      = {10.1007/s10462-020-09854-1},
    issn     = {1573-7462},
    journal  = {Artificial Intelligence Review},
    month    = {01},
    number   = {1},
    pages    = {137-178},
    title    = {Deep semantic segmentation of natural and medical images: a review},
    volume   = {54},
    year     = {2021}
}
@inbook{awad2015support,
    abstract  = {This chapter covers details of the support vector machine (SVM) technique, a sparse kernel decision machine that avoids computing posterior probabilities when building its learning model. SVM offers a principled approach to problems because of its mathematical foundation in statistical learning theory. SVM constructs its solution in terms of a subset of the training input. SVM has been extensively used for classification, regression, novelty detection tasks, and feature reduction. This chapter focuses on SVM for supervised classification tasks only, providing SVM formulations for when the input space is linearly separable or linearly nonseparable and when the data are unbalanced, along with examples. The chapter also presents recent improvements to and extensions of the original SVM formulation. A case study concludes the chapter.},
    address   = {Berkeley, CA},
    author    = {Awad, Mariette
                 and Khanna, Rahul},
    booktitle = {Efficient Learning Machines: Theories, Concepts, and Applications for Engineers and System Designers},
    doi       = {10.1007/978-1-4302-5990-9_3},
    isbn      = {978-1-4302-5990-9},
    pages     = {39--66},
    publisher = {Apress},
    title     = {Support Vector Machines for Classification},
    year      = {2015}
}
@misc{bakas2018identifying,
    author    = {Bakas, Spyridon and Reyes, Mauricio and Jakab, Andras and Bauer, Stefan and Rempfler, Markus and Crimi, Alessandro and Shinohara, Russell Takeshi and Berger, Christoph and Ha, Sung Min and Rozycki, Martin and Prastawa, Marcel and Alberts, Esther and Lipkova, Jana and Freymann, John and Kirby, Justin and Bilello, Michel and Fathallah-Shaykh, Hassan and Wiest, Roland and Kirschke, Jan and Wiestler, Benedikt and Colen, Rivka and Kotrotsou, Aikaterini and Lamontagne, Pamela and Marcus, Daniel and Milchenko, Mikhail and Nazeri, Arash and Weber, Marc-Andre and Mahajan, Abhishek and Baid, Ujjwal and Gerstner, Elizabeth and Kwon, Dongjin and Acharya, Gagan and Agarwal, Manu and Alam, Mahbubul and Albiol, Alberto and Albiol, Antonio and Albiol, Francisco J. and Alex, Varghese and Allinson, Nigel and Amorim, Pedro H. A. and Amrutkar, Abhijit and Anand, Ganesh and Andermatt, Simon and Arbel, Tal and Arbelaez, Pablo and Avery, Aaron and Azmat, Muneeza and B., Pranjal and Bai, W and Banerjee, Subhashis and Barth, Bill and Batchelder, Thomas and Batmanghelich, Kayhan and Battistella, Enzo and Beers, Andrew and Belyaev, Mikhail and Bendszus, Martin and Benson, Eze and Bernal, Jose and Bharath, Halandur Nagaraja and Biros, George and Bisdas, Sotirios and Brown, James and Cabezas, Mariano and Cao, Shilei and Cardoso, Jorge M. and Carver, Eric N and Casamitjana, Adrià and Castillo, Laura Silvana and Catà, Marcel and Cattin, Philippe and Cerigues, Albert and Chagas, Vinicius S. and Chandra, Siddhartha and Chang, Yi-Ju and Chang, Shiyu and Chang, Ken and Chazalon, Joseph and Chen, Shengcong and Chen, Wei and Chen, Jefferson W and Chen, Zhaolin and Cheng, Kun and Choudhury, Ahana Roy and Chylla, Roger and Clérigues, Albert and Colleman, Steven and Colmeiro, Ramiro German Rodriguez and Combalia, Marc and Costa, Anthony and Cui, Xiaomeng and Dai, Zhenzhen and Dai, Lutao and Daza, Laura Alexandra and Deutsch, Eric and Ding, Changxing and Dong, Chao and Dong, Shidu and Dudzik, Wojciech and Eaton-Rosen, Zach and Egan, Gary and Escudero, Guilherme and Estienne, Théo and Everson, Richard and Fabrizio, Jonathan and Fan, Yong and Fang, Longwei and Feng, Xue and Ferrante, Enzo and Fidon, Lucas and Fischer, Martin and French, Andrew P. and Fridman, Naomi and Fu, Huan and Fuentes, David and Gao, Yaozong and Gates, Evan and Gering, David and Gholami, Amir and Gierke, Willi and Glocker, Ben and Gong, Mingming and González-Villá, Sandra and Grosges, T. and Guan, Yuanfang and Guo, Sheng and Gupta, Sudeep and Han, Woo-Sup and Han, Il Song and Harmuth, Konstantin and He, Huiguang and Hernández-Sabaté, Aura and Herrmann, Evelyn and Himthani, Naveen and Hsu, Winston and Hsu, Cheyu and Hu, Xiaojun and Hu, Xiaobin and Hu, Yan and Hu, Yifan and Hua, Rui and Huang, Teng-Yi and Huang, Weilin and Van Huffel, Sabine and Huo, Quan and HV, Vivek and Iftekharuddin, Khan M. and Isensee, Fabian and Islam, Mobarakol and Jackson, Aaron S. and Jambawalikar, Sachin R. and Jesson, Andrew and Jian, Weijian and Jin, Peter and Jose, V Jeya Maria and Jungo, Alain and Kainz, B and Kamnitsas, Konstantinos and Kao, Po-Yu and Karnawat, Ayush and Kellermeier, Thomas and Kermi, Adel and Keutzer, Kurt and Khadir, Mohamed Tarek and Khened, Mahendra and Kickingereder, Philipp and Kim, Geena and King, Nik and Knapp, Haley and Knecht, Urspeter and Kohli, Lisa and Kong, Deren and Kong, Xiangmao and Koppers, Simon and Kori, Avinash and Krishnamurthi, Ganapathy and Krivov, Egor and Kumar, Piyush and Kushibar, Kaisar and Lachinov, Dmitrii and Lambrou, Tryphon and Lee, Joon and Lee, Chengen and Lee, Yuehchou and Lee, M and Lefkovits, Szidonia and Lefkovits, Laszlo and Levitt, James and Li, Tengfei and Li, Hongwei and Li, Wenqi and Li, Hongyang and Li, Xiaochuan and Li, Yuexiang and Li, Heng and Li, Zhenye and Li, Xiaoyu and Li, Zeju and Li, XiaoGang and Li, Wenqi and Lin, Zheng-Shen and Lin, Fengming and Lio, Pietro and Liu, Chang and Liu, Boqiang and Liu, Xiang and Liu, Mingyuan and Liu, Ju and Liu, Luyan and Llado, Xavier and Lopez, Marc Moreno and Lorenzo, Pablo Ribalta and Lu, Zhentai and Luo, Lin and Luo, Zhigang and Ma, Jun and Ma, Kai and Mackie, Thomas and Madabushi, Anant and Mahmoudi, Issam and Maier-Hein, Klaus H. and Maji, Pradipta and Mammen, CP and Mang, Andreas and Manjunath, B. S. and Marcinkiewicz, Michal and McDonagh, S and McKenna, Stephen and McKinley, Richard and Mehl, Miriam and Mehta, Sachin and Mehta, Raghav and Meier, Raphael and Meinel, Christoph and Merhof, Dorit and Meyer, Craig and Miller, Robert and Mitra, Sushmita and Moiyadi, Aliasgar and Molina-Garcia, David and Monteiro, Miguel A. B. and Mrukwa, Grzegorz and Myronenko, Andriy and Nalepa, Jakub and Ngo, Thuyen and Nie, Dong and Ning, Holly and Niu, Chen and Nuechterlein, Nicholas K and Oermann, Eric and Oliveira, Arlindo and Oliveira, Diego D. C. and Oliver, Arnau and Osman, Alexander F. I. and Ou, Yu-Nian and Ourselin, Sebastien and Paragios, Nikos and Park, Moo Sung and Paschke, Brad and Pauloski, J. Gregory and Pawar, Kamlesh and Pawlowski, Nick and Pei, Linmin and Peng, Suting and Pereira, Silvio M. and Perez-Beteta, Julian and Perez-Garcia, Victor M. and Pezold, Simon and Pham, Bao and Phophalia, Ashish and Piella, Gemma and Pillai, G. N. and Piraud, Marie and Pisov, Maxim and Popli, Anmol and Pound, Michael P. and Pourreza, Reza and Prasanna, Prateek and Prkovska, Vesna and Pridmore, Tony P. and Puch, Santi and Puybareau, Élodie and Qian, Buyue and Qiao, Xu and Rajchl, Martin and Rane, Swapnil and Rebsamen, Michael and Ren, Hongliang and Ren, Xuhua and Revanuru, Karthik and Rezaei, Mina and Rippel, Oliver and Rivera, Luis Carlos and Robert, Charlotte and Rosen, Bruce and Rueckert, Daniel and Safwan, Mohammed and Salem, Mostafa and Salvi, Joaquim and Sanchez, Irina and Sánchez, Irina and Santos, Heitor M. and Sartor, Emmett and Schellingerhout, Dawid and Scheufele, Klaudius and Scott, Matthew R. and Scussel, Artur A. and Sedlar, Sara and Serrano-Rubio, Juan Pablo and Shah, N. Jon and Shah, Nameetha and Shaikh, Mazhar and Shankar, B. Uma and Shboul, Zeina and Shen, Haipeng and Shen, Dinggang and Shen, Linlin and Shen, Haocheng and Shenoy, Varun and Shi, Feng and Shin, Hyung Eun and Shu, Hai and Sima, Diana and Sinclair, M and Smedby, Orjan and Snyder, James M. and Soltaninejad, Mohammadreza and Song, Guidong and Soni, Mehul and Stawiaski, Jean and Subramanian, Shashank and Sun, Li and Sun, Roger and Sun, Jiawei and Sun, Kay and Sun, Yu and Sun, Guoxia and Sun, Shuang and Suter, Yannick R and Szilagyi, Laszlo and Talbar, Sanjay and Tao, Dacheng and Tao, Dacheng and Teng, Zhongzhao and Thakur, Siddhesh and Thakur, Meenakshi H and Tharakan, Sameer and Tiwari, Pallavi and Tochon, Guillaume and Tran, Tuan and Tsai, Yuhsiang M. and Tseng, Kuan-Lun and Tuan, Tran Anh and Turlapov, Vadim and Tustison, Nicholas and Vakalopoulou, Maria and Valverde, Sergi and Vanguri, Rami and Vasiliev, Evgeny and Ventura, Jonathan and Vera, Luis and Vercauteren, Tom and Verrastro, C. A. and Vidyaratne, Lasitha and Vilaplana, Veronica and Vivekanandan, Ajeet and Wang, Guotai and Wang, Qian and Wang, Chiatse J. and Wang, Weichung and Wang, Duo and Wang, Ruixuan and Wang, Yuanyuan and Wang, Chunliang and Wang, Guotai and Wen, Ning and Wen, Xin and Weninger, Leon and Wick, Wolfgang and Wu, Shaocheng and Wu, Qiang and Wu, Yihong and Xia, Yong and Xu, Yanwu and Xu, Xiaowen and Xu, Peiyuan and Yang, Tsai-Ling and Yang, Xiaoping and Yang, Hao-Yu and Yang, Junlin and Yang, Haojin and Yang, Guang and Yao, Hongdou and Ye, Xujiong and Yin, Changchang and Young-Moxon, Brett and Yu, Jinhua and Yue, Xiangyu and Zhang, Songtao and Zhang, Angela and Zhang, Kun and Zhang, Xuejie and Zhang, Lichi and Zhang, Xiaoyue and Zhang, Yazhuo and Zhang, Lei and Zhang, Jianguo and Zhang, Xiang and Zhang, Tianhao and Zhao, Sicheng and Zhao, Yu and Zhao, Xiaomei and Zhao, Liang and Zheng, Yefeng and Zhong, Liming and Zhou, Chenhong and Zhou, Xiaobing and Zhou, Fan and Zhu, Hongtu and Zhu, Jin and Zhuge, Ying and Zong, Weiwei and Kalpathy-Cramer, Jayashree and Farahani, Keyvan and Davatzikos, Christos and van Leemput, Koen and Menze, Bjoern},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1811.02629},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Identifying the Best Machine Learning Algorithms for Brain Tumor Segmentation, Progression Assessment, and Overall Survival Prediction in the BRATS Challenge},
    year      = {2018}
} 
@article{balado2019road,
    abstract       = {In the near future, the communication between autonomous cars will produce a network of sensors that will allow us to know the state of the roads in real time. Lidar technology, upon which most autonomous cars are based, allows the acquisition of 3D geometric information of the environment. The objective of this work is to use point clouds acquired by Mobile Laser Scanning (MLS) to segment the main elements of road environment (road surface, ditches, guardrails, fences, embankments, and borders) through the use of PointNet. Previously, the point cloud was automatically divided into sections in order for semantic segmentation to be scalable to different case studies, regardless of their shape or length. An overall accuracy of 92.5{\%} has been obtained, but with large variations between classes. Elements with a greater number of points have been segmented more effectively than the other elements. In comparison with other point-by-point extraction and ANN-based classification techniques, the same success rates have been obtained for road surfaces and fences, and better results have been obtained for guardrails. Semantic segmentation with PointNet is suitable when segmenting the scene as a whole, however, if certain classes have more interest, there are other alternatives that do not need a high training cost.},
    article-number = {3466},
    author         = {Balado, Jesús and Martínez-Sánchez, Joaquín and Arias, Pedro and Novo, Ana},
    doi            = {10.3390/s19163466},
    issn           = {1424-8220},
    journal        = {Sensors},
    number         = {16},
    pubmedid       = {31398928},
    title          = {Road Environment Semantic Segmentation with Deep Learning from MLS Point Cloud Data},
    volume         = {19},
    year           = {2019}
}
@article{balakrishnama1998linear,
    author    = {Balakrishnama, Suresh and Ganapathiraju, Aravind},
    journal   = {Institute for Signal and information Processing},
    number    = {1998},
    pages     = {1--8},
    publisher = {Mississippi},
    title     = {Linear discriminant analysis-a brief tutorial},
    url       = {https://www.researchgate.net/publication/240093048_Linear_Discriminant_Analysis-A_Brief_Tutorial},
    volume    = {18},
    year      = {1998}
}
@inproceedings{Barz_2020_WACV,
    author    = {Barz, Bjorn and Denzler, Joachim},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    doi       = {10.48550/arXiv.1901.09054},
    month     = {3},
    title     = {Deep Learning on Small Datasets without Pre-Training using Cosine Loss},
    year      = {2020}
}
@misc{bevandi2019simultaneous,
    archiveprefix = {arXiv},
    author        = {Petra Bevandic and Ivan Kreso and Marin Orsic and Sinisa Segvic},
    doi           = {10.48550/arXiv.1908.01098},
    eprint        = {1908.01098},
    primaryclass  = {cs.CV},
    title         = {Simultaneous Semantic Segmentation and Outlier Detection in Presence of Domain Shift},
    year          = {2019}
}

@inproceedings{bhuriya2017stock,
    author       = {Bhuriya, Dinesh and Kaushal, Girish and Sharma, Ashish and Singh, Upendra},
    booktitle    = {2017 international conference of electronics, communication and aerospace technology (ICECA)},
    doi          = {10.1109/ICECA.2017.8212716},
    organization = {IEEE},
    pages        = {510--513},
    title        = {Stock market predication using a linear regression},
    volume       = {2},
    year         = {2017}
}

@misc{BibEntry2023MarAmbiguity,
    month = mar,
    note  = {[Online; accessed 7. Mar. 2023]},
    title = {{Visual perception is complicated because our cognitive systems are not adept at analyzing visual stimuli.}},
    url   = {https://brainmass.com/psychology/perception/what-is-a-visual-ambiguity-223578},
    year  = {2023}
}
@article{Blischak2016Jan,
    author    = {Blischak, John D. and Davenport, Emily R. and Wilson, Greg},
    doi       = {10.1371/journal.pcbi.1004668},
    issn      = {1553-7358},
    journal   = {PLoS Comput. Biol.},
    month     = jan,
    number    = {1},
    pages     = {e1004668},
    publisher = {Public Library of Science},
    title     = {{A Quick Introduction to Version Control with Git and GitHub}},
    volume    = {12},
    year      = {2016}
}
@inproceedings{blum2019fishyscapes,
    author    = {Blum, Hermann and Sarlin, Paul-Edouard and Nieto, Juan and Siegwart, Roland and Cadena, Cesar},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
    doi       = {10.1109/ICCVW.2019.00294},
    pages     = {0--0},
    title     = {Fishyscapes: A benchmark for safe semantic segmentation in autonomous driving},
    year      = {2019}
}
@article{Bogdanchikov_2013,
    abstract  = {Today we have a lot of programming languages that can realize our needs, but the most important question is how to teach programming to beginner students. In this paper we suggest using Python for this purpose, because it is a programming language that has neatly organized syntax and powerful tools to solve any task. Moreover it is very close to simple math thinking. Python is chosen as a primary programming language for freshmen in most of leading universities. Writing code in python is easy. In this paper we give some examples of program codes written in Java, C++ and Python language, and we make a comparison between them. Firstly, this paper proposes advantages of Python language in relation to C++ and JAVA. Then it shows the results of a comparison of short program codes written in three different languages, followed by a discussion on how students understand programming. Finally experimental results of students' success in programming courses are shown.},
    author    = {A Bogdanchikov and M Zhaparov and R Suliyev},
    doi       = {10.1088/1742-6596/423/1/012027},
    journal   = {Journal of Physics: Conference Series},
    month     = {04},
    number    = {1},
    pages     = {012027},
    publisher = {},
    title     = {Python to learn programming},
    volume    = {423},
    year      = {2013}
}
@inproceedings{bolya2019yolact,
    author    = {Bolya, Daniel and Zhou, Chong and Xiao, Fanyi and Lee, Yong Jae},
    booktitle = {Proceedings of the IEEE/CVF international conference on computer vision},
    doi       = {10.48550/arXiv.1904.02689},
    pages     = {9157--9166},
    title     = {Yolact: Real-time instance segmentation},
    year      = {2019}
}

@article{boring1930new,
    author    = {Boring, Edwin G},
    doi       = {10.2307/1415447},
    journal   = {The American Journal of Psychology},
    publisher = {Univ of Illinois Press},
    title     = {A new ambiguous figure.},
    year      = {1930}
}

@inbook{bottou2012stochastic,
    abstract  = {Chapter 1 strongly advocates the stochastic back-propagation method to train neural networks. This is in fact an instance of a more general technique called stochastic gradient descent (SGD). This chapter provides background material, explains why SGD is a good learning algorithm when the training set is large, and provides useful recommendations.},
    address   = {Berlin, Heidelberg},
    author    = {Bottou, L{\'e}on},
    booktitle = {Neural Networks: Tricks of the Trade: Second Edition},
    doi       = {10.1007/978-3-642-35289-8_25},
    editor    = {Montavon, Gr{\'e}goire
                 and Orr, Genevi{\`e}ve B.
                 and M{\"u}ller, Klaus-Robert},
    isbn      = {978-3-642-35289-8},
    pages     = {421--436},
    publisher = {Springer Berlin Heidelberg},
    title     = {Stochastic Gradient Descent Tricks},
    year      = {2012}
}
@inproceedings{boutilier2009online,
    abstract  = {Most models of utility elicitation in decision support and interactive optimization assume a predefined set of "catalog" features over which user preferences are expressed. However, users may differ in the features over which they are most comfortable expressing their preferences. In this work we consider the problem of feature elicitation: a user's utility function is expressed using features whose definitions (in terms of "catalog" features) are unknown. We cast this as a problem of concept learning, but whose goal is to identify only enough about the concept to enable a good decision to be recommended. We describe computational procedures for identifying optimal alternatives w.r.t. minimax regret in the presence of concept uncertainty; and describe several heuristic query strategies that focus on reduction of relevant concept uncertainty.},
    author    = {Boutilier, Craig and Regan, Kevin and Viappiani, Paolo},
    booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
    doi       = {10.1145/1553374.1553384},
    isbn      = {9781605585161},
    location  = {Montreal, Quebec, Canada},
    numpages  = {8},
    pages     = {73–80},
    publisher = {Association for Computing Machinery},
    series    = {ICML '09},
    title     = {Online Feature Elicitation in Interactive Optimization},
    year      = {2009}
}
@inproceedings{boykov2006integral,
    abstract  = {We introduce a new approach to modelling gradient flows of contours and surfaces. While standard variational methods (e.g. level sets) compute local interface motion in a differential fashion by estimating local contour velocity via energy derivatives, we propose to solve surface evolution PDEs by explicitly estimating integral motion of the whole surface. We formulate an optimization problem directly based on an integral characterization of gradient flow as an infinitesimal move of the (whole) surface giving the largest energy decrease among all moves of equal size. We show that this problem can be efficiently solved using recent advances in algorithms for global hypersurface optimization [4,2,11]. In particular, we employ the geo-cuts method [4] that uses ideas from integral geometry to represent continuous surfaces as cuts on discrete graphs. The resulting interface evolution algorithm is validated on some 2D and 3D examples similar to typical demonstrations of level-set methods. Our method can compute gradient flows of hypersurfaces with respect to a fairly general class of continuous functionals and it is flexible with respect to distance metrics on the space of contours/surfaces. Preliminary tests for standard L2 distance metric demonstrate numerical stability, topological changes and an absence of any oscillatory motion.},
    address   = {Berlin, Heidelberg},
    author    = {Boykov, Yuri
                 and Kolmogorov, Vladimir
                 and Cremers, Daniel
                 and Delong, Andrew},
    booktitle = {Computer Vision -- ECCV 2006},
    doi       = {10.1007/11744078_32},
    editor    = {Leonardis, Ale{\v{s}}
                 and Bischof, Horst
                 and Pinz, Axel},
    isbn      = {978-3-540-33837-6},
    pages     = {409--422},
    publisher = {Springer Berlin Heidelberg},
    title     = {An Integral Solution to Surface Evolution PDEs Via Geo-cuts},
    year      = {2006}
} 
@article{bradski2000opencv,
    author    = {Bradski, Gary},
    journal   = {Dr. Dobb's Journal: Software Tools for the Professional Programmer},
    note      = {[Online; accessed 2. Jul. 2023]},
    number    = {11},
    pages     = {120--123},
    publisher = {Miller Freeman Inc.},
    title     = {The openCV library.},
    url       = {https://www.scirp.org/(S(351jmbntvnsjt1aadkposzje))/reference/ReferencesPapers.aspx?ReferenceID=1692176},
    volume    = {25},
    year      = {2000}
}
@article{Breiman1996,
    abstract = {Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.},
    author   = {Breiman, Leo},
    day      = {01},
    doi      = {10.1007/BF00058655},
    issn     = {1573-0565},
    journal  = {Machine Learning},
    month    = {08},
    number   = {2},
    pages    = {123-140},
    title    = {Bagging predictors},
    volume   = {24},
    year     = {1996}
}
@article{Bright2020Nov,
    author  = {Bright, Jerrin},
    journal = {Value ML},
    month   = {11},
    title   = {{Instance Segmentation with Custom Datasets in Python - Value ML}},
    url     = {https://valueml.com/instance-segmentation-with-custom-datasets-in-python},
    year    = {2020}
}
@article{brostow2009semantic,
    abstract = {Visual object analysis researchers are increasingly experimenting with video, because it is expected that motion cues should help with detection, recognition, and other analysis tasks. This paper presents the Cambridge-driving Labeled Video Database (CamVid) as the first collection of videos with object class semantic labels, complete with metadata. The database provides ground truth labels that associate each pixel with one of 32 semantic classes. The database addresses the need for experimental data to quantitatively evaluate emerging algorithms. While most videos are filmed with fixed-position CCTV-style cameras, our data was captured from the perspective of a driving automobile. The driving scenario increases the number and heterogeneity of the observed object classes. Over 10min of high quality 30Hz footage is being provided, with corresponding semantically labeled images at 1Hz and in part, 15Hz. The CamVid Database offers four contributions that are relevant to object analysis researchers. First, the per-pixel semantic segmentation of over 700 images was specified manually, and was then inspected and confirmed by a second person for accuracy. Second, the high-quality and large resolution color video images in the database represent valuable extended duration digitized footage to those interested in driving scenarios or ego-motion. Third, we filmed calibration sequences for the camera color response and intrinsics, and computed a 3D camera pose for each frame in the sequences. Finally, in support of expanding this or other databases, we present custom-made labeling software for assisting users who wish to paint precise class-labels for other images and videos. We evaluate the relevance of the database by measuring the performance of an algorithm from each of three distinct domains: multi-class object recognition, pedestrian detection, and label propagation.},
    author   = {Gabriel J. Brostow and Julien Fauqueur and Roberto Cipolla},
    doi      = {https://doi.org/10.1016/j.patrec.2008.04.005},
    issn     = {0167-8655},
    journal  = {Pattern Recognition Letters},
    keywords = {Object recognition, Video database, Video understanding, Semantic segmentation, Label propagation},
    note     = {Video-based Object and Event Analysis},
    number   = {2},
    pages    = {88-97},
    title    = {Semantic object classes in video: A high-definition ground truth database},
    volume   = {30},
    year     = {2009}
}
@book{brownlee2019deep,
    author    = {Brownlee, Jason},
    publisher = {Machine Learning Mastery},
    title     = {Deep learning for computer vision: image classification, object detection, and face recognition in python},
    url       = {https://books.google.de/books/about/Deep_Learning_for_Computer_Vision.html?id=DOamDwAAQBAJ&redir_esc=y},
    year      = {2019}
}
@inproceedings{Budvytis_2017_ICCV,
    author    = {Budvytis, Ignas and Sauer, Patrick and Roddick, Thomas and Breen, Kesar and Cipolla, Roberto},
    booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV) Workshops},
    doi       = {10.1109/ICCVW.2017.36},
    month     = {10},
    title     = {Large Scale Labelled Video Data Augmentation for Semantic Segmentation in Driving Scenarios},
    year      = {2017}
}
  @article{budvytis2011semi,
    author  = {Badrinarayanan, Vijay and Budvytis, Ignas and Cipolla, Roberto},
    doi     = {10.1109/TPAMI.2013.54},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    number  = {11},
    pages   = {2751-2764},
    title   = {Semi-Supervised Video Segmentation Using Tree Structured Graphical Models},
    volume  = {35},
    year    = {2013}
}
@article{bueno2017hierarchical,
    author    = {Bueno, M{\'\i}riam Bellver and Nieto, Xavier Gir{\'o}-i and Marqu{\'e}s, Ferran and Torres, Jordi},
    doi       = {10.48550/arXiv.1611.03718},
    journal   = {Deep Learning for Image Processing Applications},
    number    = {164},
    pages     = {3},
    publisher = {IOS Press Amsterdam, The Netherlands},
    title     = {Hierarchical object detection with deep reinforcement learning},
    volume    = {31},
    year      = {2017}
}
@book{busoniu2017reinforcement,
    author    = {Busoniu, Lucian and Babuska, Robert and De Schutter, Bart and Ernst, Damien},
    doi       = {10.1201/9781439821091},
    publisher = {CRC press},
    title     = {Reinforcement learning and dynamic programming using function approximators},
    year      = {2017}
}
@misc{caliva2019distance,
    author = {Francesco Caliva and Claudia Iriondo and Alejandro Morales Martinez and Sharmila Majumdar and Valentina Pedoia},
    doi    = {10.48550/arXiv.1908.03679},
    title  = {Distance Map Loss Penalty Term for Semantic Segmentation},
    year   = {2019}
}
@inproceedings{cane2018evaluating,
    author    = {Cane, Tom and Ferryman, James},
    booktitle = {2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)},
    doi       = {10.1109/AVSS.2018.8639077},
    number    = {},
    pages     = {1-6},
    title     = {Evaluating deep semantic segmentation networks for object detection in maritime surveillance},
    volume    = {},
    year      = {2018}
}
@article{Carass2020-rj,
    abstract = {The S{\o}rensen-Dice index (SDI) is a widely used measure for
                evaluating medical image segmentation algorithms. It offers a
                standardized measure of segmentation accuracy which has proven
                useful. However, it offers diminishing insight when the number of
                objects is unknown, such as in white matter lesion segmentation
                of multiple sclerosis (MS) patients. We present a refinement for
                finer grained parsing of SDI results in situations where the
                number of objects is unknown. We explore these ideas with two
                case studies showing what can be learned from our two presented
                studies. Our first study explores an inter-rater comparison,
                showing that smaller lesions cannot be reliably identified. In
                our second case study, we demonstrate fusing multiple MS lesion
                segmentation algorithms based on the insights into the algorithms
                provided by our analysis to generate a segmentation that exhibits
                improved performance. This work demonstrates the wealth of
                information that can be learned from refined analysis of medical
                image segmentations.},
    address  = {England},
    author   = {Carass, Aaron and Roy, Snehashis and Gherman, Adrian and
                Reinhold, Jacob C and Jesson, Andrew and Arbel, Tal and Maier,
                Oskar and Handels, Heinz and Ghafoorian, Mohsen and Platel, Bram
                and Birenbaum, Ariel and Greenspan, Hayit and Pham, Dzung L and
                Crainiceanu, Ciprian M and Calabresi, Peter A and Prince, Jerry L
                and Roncal, William R Gray and Shinohara, Russell T and Oguz,
                Ipek},
    doi      = {10.1038/s41598-020-64803-w},
    journal  = {Sci Rep},
    language = {en},
    month    = may,
    number   = 1,
    pages    = {8242},
    title    = {Evaluating White Matter Lesion Segmentations with Refined
                {S{\o}rensen-Dice} Analysis},
    volume   = 10,
    year     = 2020
}
@article{Caruana1997,
    abstract = {Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. This paper reviews prior work on MTL, presents new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals, and presents new results for MTL with k-nearest neighbor and kernel regression. In this paper we demonstrate multitask learning in three domains. We explain how multitask learning works, and show that there are many opportunities for multitask learning in real domains. We present an algorithm and results for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Because multitask learning works, can be applied to many different kinds of domains, and can be used with different learning algorithms, we conjecture there will be many opportunities for its use on real-world problems.},
    author   = {Caruana, Rich},
    day      = {01},
    doi      = {10.1023/A:1007379606734},
    issn     = {1573-0565},
    journal  = {Machine Learning},
    month    = {07},
    number   = {1},
    pages    = {41-75},
    title    = {Multitask Learning},
    volume   = {28},
    year     = {1997}
}
@article{Chen_2018_ECCV,
    author     = {Liang{-}Chieh Chen and
                  Yukun Zhu and
                  George Papandreou and
                  Florian Schroff and
                  Hartwig Adam},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1802-02611.bib},
    doi        = {10.48550/arXiv.1802.02611},
    eprint     = {1802.02611},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Sat, 23 Jan 2021 01:20:31 +0100},
    title      = {Encoder-Decoder with Atrous Separable Convolution for Semantic Image
                  Segmentation},
    volume     = {abs/1802.02611},
    year       = {2018}
}
@article{Chen_Dou_Chen_Qin_Heng_2019,
    abstractnote = {&lt;p&gt;This paper presents a novel unsupervised domain adaptation framework, called &lt;em&gt;Synergistic Image and Feature Adaptation (SIFA)&lt;/em&gt;, to effectively tackle the problem of domain shift. Domain adaptation has become an important and hot topic in recent studies on deep learning, aiming to recover performance degradation when applying the neural networks to new testing domains. Our proposed SIFA is an elegant learning diagram which presents synergistic fusion of adaptations from both image and feature perspectives. In particular, we simultaneously transform the appearance of images across domains and enhance domain-invariance of the extracted features towards the segmentation task. The feature encoder layers are shared by both perspectives to grasp their mutual benefits during the end-to-end learning procedure. Without using any annotation from the target domain, the learning of our unified model is guided by adversarial losses, with multiple discriminators employed from various aspects. We have extensively validated our method with a challenging application of crossmodality medical image segmentation of cardiac structures. Experimental results demonstrate that our SIFA model recovers the degraded performance from 17.2{\%} to 73.0{\%}, and outperforms the state-of-the-art methods by a significant margin.&lt;/p&gt;},
    author       = {Chen, Cheng and Dou, Qi and Chen, Hao and Qin, Jing and Heng, Pheng-Ann},
    doi          = {10.1609/aaai.v33i01.3301865},
    journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
    month        = {07},
    number       = {01},
    pages        = {865-872},
    title        = {Synergistic Image and Feature Adaptation: Towards Cross-Modality Domain Adaptation for Medical Image Segmentation},
    volume       = {33},
    year         = {2019}
}
@article{chen2015study,
    abstract = {Objectives
                Named entity recognition (NER), a sequential labeling task, is one of the fundamental tasks for building clinical natural language processing (NLP) systems. Machine learning (ML) based approaches can achieve good performance, but they often require large amounts of annotated samples, which are expensive to build due to the requirement of domain experts in annotation. Active learning (AL), a sample selection approach integrated with supervised ML, aims to minimize the annotation cost while maximizing the performance of ML-based models. In this study, our goal was to develop and evaluate both existing and new AL methods for a clinical NER task to identify concepts of medical problems, treatments, and lab tests from the clinical notes.
                Methods
                Using the annotated NER corpus from the 2010 i2b2/VA NLP challenge that contained 349 clinical documents with 20,423 unique sentences, we simulated AL experiments using a number of existing and novel algorithms in three different categories including uncertainty-based, diversity-based, and baseline sampling strategies. They were compared with the passive learning that uses random sampling. Learning curves that plot performance of the NER model against the estimated annotation cost (based on number of sentences or words in the training set) were generated to evaluate different active learning and the passive learning methods and the area under the learning curve (ALC) score was computed.
                Results
                Based on the learning curves of F-measure vs. number of sentences, uncertainty sampling algorithms outperformed all other methods in ALC. Most diversity-based methods also performed better than random sampling in ALC. To achieve an F-measure of 0.80, the best method based on uncertainty sampling could save 66{\%} annotations in sentences, as compared to random sampling. For the learning curves of F-measure vs. number of words, uncertainty sampling methods again outperformed all other methods in ALC. To achieve 0.80 in F-measure, in comparison to random sampling, the best uncertainty based method saved 42{\%} annotations in words. But the best diversity based method reduced only 7{\%} annotation effort.
                Conclusion
                In the simulated setting, AL methods, particularly uncertainty-sampling based approaches, seemed to significantly save annotation cost for the clinical NER task. The actual benefit of active learning in clinical NER should be further evaluated in a real-time setting.},
    author   = {Yukun Chen and Thomas A. Lasko and Qiaozhu Mei and Joshua C. Denny and Hua Xu},
    doi      = {https://doi.org/10.1016/j.jbi.2015.09.010},
    issn     = {1532-0464},
    journal  = {Journal of Biomedical Informatics},
    keywords = {Active learning, Machine learning, Clinical natural language processing, Clinical named entity recognition},
    pages    = {11-18},
    title    = {A study of active learning methods for named entity recognition in clinical text},
    volume   = {58},
    year     = {2015}
}
@inproceedings{chen2016supervised,
    abstract  = {Large pose variations remain to be a challenge that confronts real-word face detection. We propose a new cascaded Convolutional Neural Network, dubbed the name Supervised Transformer Network, to address this challenge. The first stage is a multi-task Region Proposal Network (RPN), which simultaneously predicts candidate face regions along with associated facial landmarks. The candidate regions are then warped by mapping the detected facial landmarks to their canonical positions to better normalize the face patterns. The second stage, which is a RCNN, then verifies if the warped candidate regions are valid faces or not. We conduct end-to-end learning of the cascaded network, including optimizing the canonical positions of the facial landmarks. This supervised learning of the transformations automatically selects the best scale to differentiate face/non-face patterns. By combining feature maps from both stages of the network, we achieve state-of-the-art detection accuracies on several public benchmarks. For real-time performance, we run the cascaded network only on regions of interests produced from a boosting cascade face detector. Our detector runs at 30 FPS on a single CPU core for a VGA-resolution image.},
    address   = {Cham},
    author    = {Chen, Dong
                 and Hua, Gang
                 and Wen, Fang
                 and Sun, Jian},
    booktitle = {Computer Vision -- ECCV 2016},
    doi       = {10.48550/arXiv.1607.05477},
    editor    = {Leibe, Bastian
                 and Matas, Jiri
                 and Sebe, Nicu
                 and Welling, Max},
    isbn      = {978-3-319-46454-1},
    pages     = {122--138},
    publisher = {Springer International Publishing},
    title     = {Supervised Transformer Network for Efficient Face Detection},
    year      = {2016}
}
@article{chen2017deeplab,
    author  = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
    doi     = {10.1109/TPAMI.2017.2699184},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    number  = {4},
    pages   = {834-848},
    title   = {DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs},
    volume  = {40},
    year    = {2018}
} 
@article{chen2017discriminative,
    abstract  = {This paper proposes a concise and effective approach termed discriminative feature representation (DFR) for low dose computerized tomography (LDCT) image processing, which is currently a challenging problem in medical imaging field. This DFR method assumes LDCT images as the superposition of desirable high dose CT (HDCT) 3D features and undesirable noise-artifact 3D features (the combined term of noise and artifact features induced by low dose scan protocols), and the decomposed HDCT features are used to provide the processed LDCT images with higher quality. The target HDCT features are solved via the DFR algorithm using a featured dictionary composed by atoms representing HDCT features and noise-artifact features. In this study, the featured dictionary is efficiently built using physical phantom images collected from the same CT scanner as the target clinical LDCT images to process. The proposed DFR method also has good robustness in parameter setting for different CT scanner types. This DFR method can be directly applied to process DICOM formatted LDCT images, and has good applicability to current CT systems. Comparative experiments with abdomen LDCT data validate the good performance of the proposed approach.},
    author    = {Yang Chen and Jin Liu and Yining Hu and Jian Yang and Luyao Shi and Huazhong Shu and Zhiguo Gui and Gouenou Coatrieux and Limin Luo},
    doi       = {10.1088/1361-6560/aa5c24},
    journal   = {Physics in Medicine and Biology},
    month     = {02},
    number    = {6},
    pages     = {2103},
    publisher = {IOP Publishing},
    title     = {Discriminative feature representation: an effective postprocessing solution to low dose CT imaging*},
    volume    = {62},
    year      = {2017}
}
@article{chen2017importance,
    author  = {Chen, Bike and Gong, Chen and Yang, Jian},
    doi     = {10.1109/TITS.2018.2801309},
    journal = {IEEE Transactions on Intelligent Transportation Systems},
    number  = {1},
    pages   = {137-148},
    title   = {Importance-Aware Semantic Segmentation for Autonomous Vehicles},
    volume  = {20},
    year    = {2019}
}

@article{chen2018rise,
    abstract = {Over the past decade, deep learning has achieved remarkable success in various artificial intelligence research areas. Evolved from the previous research on artificial neural networks, this technology has shown superior performance to other machine learning algorithms in areas such as image and voice recognition, natural language processing, among others. The first wave of applications of deep learning in pharmaceutical research has emerged in recent years, and its utility has gone beyond bioactivity predictions and has shown promise in addressing diverse problems in drug discovery. Examples will be discussed covering bioactivity prediction, de novo molecular design, synthesis prediction and biological image analysis.},
    author   = {Hongming Chen and Ola Engkvist and Yinhai Wang and Marcus Olivecrona and Thomas Blaschke},
    doi      = {10.1016/j.drudis.2018.01.039},
    issn     = {1359-6446},
    journal  = {Drug Discovery Today},
    number   = {6},
    pages    = {1241-1250},
    title    = {The rise of deep learning in drug discovery},
    volume   = {23},
    year     = {2018}
}
@inproceedings{chen2019multi,
    abstract  = {We propose a novel semi-supervised image segmentation method that simultaneously optimizes a supervised segmentation and an unsupervised reconstruction objectives. The reconstruction objective uses an attention mechanism that separates the reconstruction of image areas corresponding to different classes. The proposed approach was evaluated on two applications: brain tumor and white matter hyperintensities segmentation. Our method, trained on unlabeled and a small number of labeled images, outperformed supervised CNNs trained with the same number of images and CNNs pre-trained on unlabeled data. In ablation experiments, we observed that the proposed attention mechanism substantially improves segmentation performance. We explore two multi-task training strategies: joint training and alternating training. Alternating training requires fewer hyperparameters and achieves a better, more stable performance than joint training. Finally, we analyze the features learned by different methods and find that the attention mechanism helps to learn more discriminative features in the deeper layers of encoders.},
    address   = {Cham},
    author    = {Chen, Shuai
                 and Bortsova, Gerda
                 and Garc{\'i}a-Uceda Ju{\'a}rez, Antonio
                 and van Tulder, Gijs
                 and de Bruijne, Marleen},
    booktitle = {Medical Image Computing and Computer Assisted Intervention -- MICCAI 2019},
    doi       = {10.48550/arXiv.1907.12303},
    editor    = {Shen, Dinggang
                 and Liu, Tianming
                 and Peters, Terry M.
                 and Staib, Lawrence H.
                 and Essert, Caroline
                 and Zhou, Sean
                 and Yap, Pew-Thian
                 and Khan, Ali},
    isbn      = {978-3-030-32248-9},
    pages     = {457--465},
    publisher = {Springer International Publishing},
    title     = {Multi-task Attention-Based Semi-supervised Learning for Medical Image Segmentation},
    year      = {2019}
}

@inproceedings{Cho_2023_WACV,
    author    = {Cho, Wonwoo and Park, Jeonghoon and Choo, Jaegul},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    doi       = {10.1109/WACV56688.2023.00265},
    month     = {01},
    pages     = {2624-2633},
    title     = {Training Auxiliary Prototypical Classifiers for Explainable Anomaly Detection in Medical Image Segmentation},
    year      = {2023}
}
@inproceedings{chorowski2015attention,
    author    = {Chorowski, Jan K and Bahdanau, Dzmitry and Serdyuk, Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
    booktitle = {Advances in Neural Information Processing Systems},
    doi       = {10.48550/arXiv.1506.07503},
    editor    = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {Attention-Based Models for Speech Recognition},
    volume    = {28},
    year      = {2015}
}
} 
@article{chudasama2015image,
    author    = {Chudasama, Diya and Patel, Tanvi and Joshi, Shubham and Prajapati, Ghanshyam I},
    doi       = {10.5120/20654-3197},
    journal   = {International Journal of Computer Applications},
    number    = {18},
    publisher = {Citeseer},
    title     = {Image segmentation using morphological operations},
    volume    = {117},
    year      = {2015}
}

@article{cifar10dataset,
    abstract = {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 
                
                The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
    author   = {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
    journal  = {},
    keywords = {Dataset},
    terms    = {},
    title    = {CIFAR-10 (Canadian Institute for Advanced Research)},
    url      = {http://www.cs.toronto.edu/~kriz/cifar.html},
    year     = {}
}

@misc{ContributorstoWikimediaprojects2023Feb,
    author = {{Contributors to Wikimedia projects}},
    month  = feb,
    note   = {[Online; accessed 3. Mar. 2023]},
    title  = {{Reinforcement learning - Wikipedia}},
    url    = {https://en.wikipedia.org/w/index.php?title=Reinforcement_learning&oldid=1140672772},
    year   = {2023}
}

@inproceedings{cootes2012robust,
    abstract  = {A widely used approach for locating points on deformable objects is to generate feature response images for each point, then to fit a shape model to the response images. We demonstrate that Random Forest regression can be used to generate high quality response images quickly. Rather than using a generative or a discriminative model to evaluate each pixel, a regressor is used to cast votes for the optimal position. We show this leads to fast and accurate matching when combined with a statistical shape model. We evaluate the technique in detail, and compare with a range of commonly used alternatives on several different datasets. We show that the random forest regression method is significantly faster and more accurate than equivalent discriminative, or boosted regression based methods trained on the same data.},
    address   = {Berlin, Heidelberg},
    author    = {Cootes, Tim F.
                 and Ionita, Mircea C.
                 and Lindner, Claudia
                 and Sauer, Patrick},
    booktitle = {Computer Vision -- ECCV 2012},
    doi       = {10.1007/978-3-642-33786-4_21},
    editor    = {Fitzgibbon, Andrew
                 and Lazebnik, Svetlana
                 and Perona, Pietro
                 and Sato, Yoichi
                 and Schmid, Cordelia},
    isbn      = {978-3-642-33786-4},
    pages     = {278--291},
    publisher = {Springer Berlin Heidelberg},
    title     = {Robust and Accurate Shape Model Fitting Using Random Forest Regression Voting},
    year      = {2012}
}
@inproceedings{cordts2016cityscapes,
    author    = {Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
    booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
    doi       = {10.48550/arXiv.1604.01685},
    pages     = {3213--3223},
    title     = {The cityscapes dataset for semantic urban scene understanding},
    year      = {2016}
}

@article{cortes1995support,
    abstract = {Thesupport-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.},
    author   = {Cortes, Corinna
                and Vapnik, Vladimir},
    day      = {01},
    doi      = {10.1007/BF00994018},
    issn     = {1573-0565},
    journal  = {Machine Learning},
    month    = {09},
    number   = {3},
    pages    = {273-297},
    title    = {Support-vector networks},
    volume   = {20},
    year     = {1995}
}

@inbook{cutler2012random,
    abstract  = {Random Forests were introduced by Leo Breiman [6] who was inspired by earlier work by Amit and Geman [2]. Although not obvious from the description in [6], Random Forests are an extension of Breiman's bagging idea [5] and were developed as a competitor to boosting. Random Forests can be used for either a categorical response variable, referred to in [6] as ``classification,'' or a continuous response, referred to as ``regression.'' Similarly, the predictor variables can be either categorical or continuous.},
    address   = {Boston, MA},
    author    = {Cutler, Adele
                 and Cutler, D. Richard
                 and Stevens, John R.},
    booktitle = {Ensemble Machine Learning: Methods and Applications},
    doi       = {10.1007/978-1-4419-9326-7_5},
    editor    = {Zhang, Cha
                 and Ma, Yunqian},
    isbn      = {978-1-4419-9326-7},
    pages     = {157--175},
    publisher = {Springer US},
    title     = {Random Forests},
    year      = {2012}
}

@inproceedings{Dai_2016_CVPR,
    author    = {Dai, Jifeng and He, Kaiming and Sun, Jian},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {06},
    title     = {Instance-Aware Semantic Segmentation via Multi-Task Network Cascades},
    year      = {2016}
}
@article{dai2017scannet,
    author     = {Angela Dai and
                  Angel X. Chang and
                  Manolis Savva and
                  Maciej Halber and
                  Thomas A. Funkhouser and
                  Matthias Nie{\ss}ner},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/DaiCSHFN17.bib},
    doi        = {10.48550/arXiv.1512.04412},
    eprint     = {1702.04405},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:47:34 +0200},
    title      = {ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes},
    volume     = {abs/1702.04405},
    year       = {2017}
}
@proceedings{DBLP:conf/isbi/2015,
    bibsource = {dblp computer science bibliography, https://dblp.org},
    biburl    = {https://dblp.org/rec/conf/isbi/2015.bib},
    isbn      = {978-1-4799-2374-8},
    publisher = {{IEEE}},
    timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
    title     = {12th {IEEE} International Symposium on Biomedical Imaging, {ISBI}
                 2015, Brooklyn, NY, USA, April 16-19, 2015},
    url       = {https://ieeexplore.ieee.org/xpl/conhome/7150573/proceeding},
    year      = {2015}
}
@article{DBLP:journals/corr/abs-0907-1815,
    author     = {Hal Daum{\'{e}} III},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-0907-1815.bib},
    doi        = {10.48550/arXiv.0907.1815},
    eprint     = {0907.1815},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:46:20 +0200},
    title      = {Frustratingly Easy Domain Adaptation},
    volume     = {abs/0907.1815},
    year       = {2009}
}

@article{DBLP:journals/corr/abs-1212-5701,
    author     = {Matthew D. Zeiler},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1212-5701.bib},
    doi        = {10.48550/arXiv.1212.5701},
    eprint     = {1212.5701},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:45:57 +0200},
    title      = {{ADADELTA:} An Adaptive Learning Rate Method},
    volume     = {abs/1212.5701},
    year       = {2012}
}

@article{DBLP:journals/corr/abs-1708-02002,
    author     = {Tsung{-}Yi Lin and
                  Priya Goyal and
                  Ross B. Girshick and
                  Kaiming He and
                  Piotr Doll{\'{a}}r},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1708-02002.bib},
    doi        = {10.48550/arXiv.1708.02002},
    eprint     = {1708.02002},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:46:12 +0200},
    title      = {Focal Loss for Dense Object Detection},
    volume     = {abs/1708.02002},
    year       = {2017}
}



@article{DBLP:journals/corr/abs-1709-05932,
    author     = {Benjamin Bischke and
                  Patrick Helber and
                  Joachim Folz and
                  Damian Borth and
                  Andreas Dengel},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1709-05932.bib},
    doi        = {10.48550/arXiv.1709.05932},
    eprint     = {1709.05932},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Fri, 13 Sep 2019 15:47:17 +0200},
    title      = {Multi-Task Learning for Segmentation of Building Footprints with Deep Neural Networks},
    volume     = {abs/1709.05932},
    year       = {2017}
}
@article{DBLP:journals/corr/abs-1710-05006,
    author     = {Noel C. F. Codella and
                  David A. Gutman and
                  M. Emre Celebi and
                  Brian Helba and
                  Michael A. Marchetti and
                  Stephen W. Dusza and
                  Aadi Kalloo and
                  Konstantinos Liopyris and
                  Nabin K. Mishra and
                  Harald Kittler and
                  Allan Halpern},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1710-05006.bib},
    doi        = {10.48550/arXiv.1605.01397},
    eprint     = {1710.05006},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Tue, 29 Jun 2021 15:47:36 +0200},
    title      = {Skin Lesion Analysis Toward Melanoma Detection: {A} Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted
                  by the International Skin Imaging Collaboration {(ISIC)}},
    volume     = {abs/1710.05006},
    year       = {2017}
}

@article{DBLP:journals/corr/abs-1710-05381,
    author     = {Mateusz Buda and
                  Atsuto Maki and
                  Maciej A. Mazurowski},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1710-05381.bib},
    doi        = {10.1016/j.neunet.2018.07.011},
    eprint     = {1710.05381},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:47:52 +0200},
    title      = {A systematic study of the class imbalance problem in convolutional
                  neural networks},
    volume     = {abs/1710.05381},
    year       = {2017}
}
@article{DBLP:journals/corr/abs-1710-09412,
    author     = {Hongyi Zhang and
                  Moustapha Ciss{\'{e}} and
                  Yann N. Dauphin and
                  David Lopez{-}Paz},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1710-09412.bib},
    doi        = {10.48550/arXiv.1710.09412},
    eprint     = {1710.09412},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:47:14 +0200},
    title      = {mixup: Beyond Empirical Risk Minimization},
    volume     = {abs/1710.09412},
    year       = {2017}
}
@article{DBLP:journals/corr/abs-1711-09168,
    author     = {Marc Gorriz and
                  Axel Carlier and
                  Emmanuel Faure and
                  Xavier Gir{\'{o}}{-}i{-}Nieto},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1711-09168.bib},
    doi        = {10.48550/arXiv.1711.09168},
    eprint     = {1711.09168},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Thu, 30 Apr 2020 17:36:05 +0200},
    title      = {Cost-Effective Active Learning for Melanoma Segmentation},
    volume     = {abs/1711.09168},
    year       = {2017}
}
@article{DBLP:journals/corr/abs-1711-10449,
    author     = {Manu Goyal and
                  Moi Hoon Yap},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1711-10449.bib},
    doi        = {10.48550/arXiv.1711.10449},
    eprint     = {1711.10449},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:46:39 +0200},
    title      = {Multi-class Semantic Segmentation of Skin Lesions via Fully Convolutional
                  Networks},
    volume     = {abs/1711.10449},
    year       = {2017}
}
@article{DBLP:journals/corr/abs-1802-00285,
    author     = {Zhang{-}Wei Hong and
                  Yu{-}Ming Chen and
                  Shih{-}Yang Su and
                  Tzu{-}Yun Shann and
                  Yi{-}Hsiang Chang and
                  Hsuan{-}Kung Yang and
                  Brian Hsi{-}Lin Ho and
                  Chih{-}Chieh Tu and
                  Yueh{-}Chuan Chang and
                  Tsu{-}Ching Hsiao and
                  Hsin{-}Wei Hsiao and
                  Sih{-}Pin Lai and
                  Chun{-}Yi Lee},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1802-00285.bib},
    doi        = {10.48550/arXiv.1802.00285},
    eprint     = {1802.00285},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:49:08 +0200},
    title      = {Virtual-to-Real: Learning to Control in Visual Semantic Segmentation},
    volume     = {abs/1802.00285},
    year       = {2018}
}

@article{DBLP:journals/corr/abs-1802-09129,
    author     = {Weifeng Ge and
                  Sibei Yang and
                  Yizhou Yu},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1802-09129.bib},
    doi        = {10.48550/arXiv.1802.09129},
    eprint     = {1802.09129},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:47:26 +0200},
    title      = {Multi-Evidence Filtering and Fusion for Multi-Label Classification,
                  Object Detection and Semantic Segmentation Based on Weakly Supervised
                  Learning},
    volume     = {abs/1802.09129},
    year       = {2018}
}

@article{DBLP:journals/corr/abs-1805-02798,
    author     = {Saeid Asgari Taghanaki and
                  Yefeng Zheng and
                  Shaohua Kevin Zhou and
                  Bogdan Georgescu and
                  Puneet Sharma and
                  Daguang Xu and
                  Dorin Comaniciu and
                  Ghassan Hamarneh},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1805-02798.bib},
    doi        = {10.48550/arXiv.1805.02798},
    eprint     = {1805.02798},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Tue, 21 Dec 2021 17:19:23 +0100},
    title      = {Combo Loss: Handling Input and Output Imbalance in Multi-Organ Segmentation},
    volume     = {abs/1805.02798},
    year       = {2018}
}

@article{DBLP:journals/corr/abs-1805-04777,
    author     = {Marvin T. T. Teichmann and
                  Roberto Cipolla},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1805-04777.bib},
    doi        = {10.48550/arXiv.1805.04777},
    eprint     = {1805.04777},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:47:47 +0200},
    title      = {Convolutional CRFs for Semantic Segmentation},
    volume     = {abs/1805.04777},
    year       = {2018}
}
@article{DBLP:journals/corr/abs-1807-05511,
    author     = {Zhong{-}Qiu Zhao and
                  Peng Zheng and
                  Shou{-}tao Xu and
                  Xindong Wu},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1807-05511.bib},
    doi        = {10.48550/arXiv.1807.05511},
    eprint     = {1807.05511},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 07 Jan 2019 17:17:43 +0100},
    title      = {Object Detection with Deep Learning: {A} Review},
    volume     = {abs/1807.05511},
    year       = {2018}
}
@article{DBLP:journals/corr/abs-1807-09298,
    author     = {Zhewei Wang and
                  Charles D. Smith and
                  Jundong Liu},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1807-09298.bib},
    doi        = {10.48550/arXiv.1807.09298},
    eprint     = {1807.09298},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:48:14 +0200},
    title      = {Ensemble of Multi-sized FCNs to Improve White Matter Lesion Segmentation},
    volume     = {abs/1807.09298},
    year       = {2018}
}
@article{DBLP:journals/corr/abs-1808-07675,
    author     = {Michele Volpi and
                  Devis Tuia},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1808-07675.bib},
    doi        = {10.1016/j.isprsjprs.2018.06.007},
    eprint     = {1808.07675},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Sun, 02 Sep 2018 15:01:56 +0200},
    title      = {Deep multi-task learning for a geographically-regularized semantic
                  segmentation of aerial images},
    volume     = {abs/1808.07675},
    year       = {2018}
}
@article{DBLP:journals/corr/abs-1810-05732,
    author     = {Amir Gholami and
                  Shashank Subramanian and
                  Varun Shenoy and
                  Naveen Himthani and
                  Xiangyu Yue and
                  Sicheng Zhao and
                  Peter H. Jin and
                  George Biros and
                  Kurt Keutzer},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1810-05732.bib},
    doi        = {10.48550/arXiv.1810.05732},
    eprint     = {1810.05732},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Tue, 30 Oct 2018 20:39:56 +0100},
    title      = {A Novel Domain Adaptation Framework for Medical Image Segmentation},
    volume     = {abs/1810.05732},
    year       = {2018}
}

@article{DBLP:journals/corr/abs-1810-07842,
    author     = {Nabila Abraham and
                  Naimul Mefraz Khan},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1810-07842.bib},
    doi        = {10.48550/arXiv.1810.07842},
    eprint     = {1810.07842},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Tue, 30 Oct 2018 20:39:56 +0100},
    title      = {A Novel Focal Tversky loss function with improved Attention U-Net
                  for lesion segmentation},
    volume     = {abs/1810.07842},
    year       = {2018}
}

@article{DBLP:journals/corr/abs-1811-02629,
    author     = {Spyridon Bakas and
                  Mauricio Reyes and
                  Andr{\'{a}}s Jakab and
                  Stefan Bauer and
                  Markus Rempfler and
                  Alessandro Crimi and
                  Russell Takeshi Shinohara and
                  Christoph Berger and
                  Sung Min Ha and
                  Martin Rozycki and
                  Marcel Prastawa and
                  Esther Alberts and
                  Jana Lipkov{\'{a}} and
                  John B. Freymann and
                  Justin S. Kirby and
                  Michel Bilello and
                  Hassan M. Fathallah{-}Shaykh and
                  Roland Wiest and
                  Jan Kirschke and
                  Benedikt Wiestler and
                  Rivka R. Colen and
                  Aikaterini Kotrotsou and
                  Pamela LaMontagne and
                  Daniel S. Marcus and
                  Mikhail Milchenko and
                  Arash Nazeri and
                  Marc{-}Andr{\'{e}} Weber and
                  Abhishek Mahajan and
                  Ujjwal Baid and
                  Dongjin Kwon and
                  Manu Agarwal and
                  Mahbubul Alam and
                  Alberto Albiol and
                  Antonio Albiol and
                  Alex Varghese and
                  Tran Anh Tuan and
                  Tal Arbel and
                  Aaron Avery and
                  Pranjal B. and
                  Subhashis Banerjee and
                  Thomas Batchelder and
                  Kayhan N. Batmanghelich and
                  Enzo Battistella and
                  Martin Bendszus and
                  Eze Benson and
                  Jos{\'{e}} Bernal and
                  George Biros and
                  Mariano Cabezas and
                  Siddhartha Chandra and
                  Yi{-}Ju Chang and
                  et al.},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1811-02629.bib},
    doi        = {10.48550/arXiv.1811.02629},
    eprint     = {1811.02629},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Thu, 14 Oct 2021 09:16:35 +0200},
    title      = {Identifying the Best Machine Learning Algorithms for Brain Tumor Segmentation,
                  Progression Assessment, and Overall Survival Prediction in the {BRATS}
                  Challenge},
    volume     = {abs/1811.02629},
    year       = {2018}
}

@article{DBLP:journals/corr/abs-1811-03378,
    author     = {Chigozie Nwankpa and
                  Winifred Ijomah and
                  Anthony Gachagan and
                  Stephen Marshall},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1811-03378.bib},
    doi        = {10.48550/arXiv.1811.03378},
    eprint     = {1811.03378},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Fri, 23 Nov 2018 12:43:51 +0100},
    title      = {Activation Functions: Comparison of trends in Practice and Research
                  for Deep Learning},
    volume     = {abs/1811.03378},
    year       = {2018}
}

@article{DBLP:journals/corr/abs-1901-08394,
    author     = {Robin Chan and
                  Matthias Rottmann and
                  Fabian H{\"{u}}ger and
                  Peter Schlicht and
                  Hanno Gottschalk},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1901-08394.bib},
    doi        = {10.48550/arXiv.1901.08394},
    eprint     = {1901.08394},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Sat, 02 Feb 2019 16:56:00 +0100},
    title      = {Application of Decision Rules for Handling Class Imbalance in Semantic
                  Segmentation},
    volume     = {abs/1901.08394},
    year       = {2019}
}
@article{DBLP:journals/corr/abs-1904-00625,
    author     = {Sihong Chen and
                  Kai Ma and
                  Yefeng Zheng},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1904-00625.bib},
    doi        = {10.48550/arXiv.1904.00625},
    eprint     = {1904.00625},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Tue, 21 Dec 2021 17:19:23 +0100},
    title      = {Med3D: Transfer Learning for 3D Medical Image Analysis},
    volume     = {abs/1904.00625},
    year       = {2019}
}

@article{DBLP:journals/corr/abs-1904-02872,
    author     = {Boah Kim and
                  Jong Chul Ye},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1904-02872.bib},
    doi        = {10.1109/TIP.2019.2941265},
    eprint     = {1904.02872},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Wed, 24 Apr 2019 12:21:25 +0200},
    title      = {Multiphase Level-Set Loss for Semi-Supervised and Unsupervised Segmentation
                  with Deep Learning},
    volume     = {abs/1904.02872},
    year       = {2019}
}


@article{DBLP:journals/corr/abs-1910-02923,
    author     = {Samuel Budd and
                  Emma C. Robinson and
                  Bernhard Kainz},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1910-02923.bib},
    doi        = {10.1016/j.media.2021.102062},
    eprint     = {1910.02923},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Wed, 09 Oct 2019 14:07:58 +0200},
    title      = {A Survey on Active Learning and Human-in-the-Loop Deep Learning for
                  Medical Image Analysis},
    volume     = {abs/1910.02923},
    year       = {2019}
}

@article{DBLP:journals/corr/abs-1911-01685,
    author     = {Jeroen Bertels and
                  Tom Eelbode and
                  Maxim Berman and
                  Dirk Vandermeulen and
                  Frederik Maes and
                  Raf Bisschops and
                  Matthew B. Blaschko},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1911-01685.bib},
    doi        = {10.1007/978-3-030-32245-8_11},
    eprint     = {1911.01685},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 11 Nov 2019 18:38:09 +0100},
    title      = {Optimizing the Dice Score and Jaccard Index for Medical Image Segmentation:
                  Theory {\&} Practice},
    volume     = {abs/1911.01685},
    year       = {2019}
}

@article{DBLP:journals/corr/abs-1911-02685,
    author     = {Fuzhen Zhuang and
                  Zhiyuan Qi and
                  Keyu Duan and
                  Dongbo Xi and
                  Yongchun Zhu and
                  Hengshu Zhu and
                  Hui Xiong and
                  Qing He},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1911-02685.bib},
    doi        = {10.48550/arXiv.1911.02685},
    eprint     = {1911.02685},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Sat, 29 Aug 2020 18:19:14 +0200},
    title      = {A Comprehensive Survey on Transfer Learning},
    volume     = {abs/1911.02685},
    year       = {2019}
}

@article{DBLP:journals/corr/abs-1912-03849,
    author     = {Yuan Xue and
                  Hui Tang and
                  Zhi Qiao and
                  Guanzhong Gong and
                  Yong Yin and
                  Zhen Qian and
                  Chao Huang and
                  Wei Fan and
                  Xiaolei Huang},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1912-03849.bib},
    doi        = {10.48550/arXiv.1912.03849},
    eprint     = {1912.03849},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Thu, 01 Dec 2022 09:53:35 +0100},
    title      = {Shape-Aware Organ Segmentation by Predicting Signed Distance Maps},
    volume     = {abs/1912.03849},
    year       = {2019}
}
@article{DBLP:journals/corr/abs-1912-09121,
    author     = {Haifeng Li and
                  Kaijian Qiu and
                  Li Chen and
                  Xiaoming Mei and
                  Liang Hong and
                  Chao Tao},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1912-09121.bib},
    doi        = {10.1109/LGRS.2020.2988294},
    eprint     = {1912.09121},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Fri, 07 May 2021 08:05:50 +0200},
    title      = {SCAttNet: Semantic Segmentation Network with Spatial and Channel Attention
                  Mechanism for High-Resolution Remote Sensing Images},
    volume     = {abs/1912.09121},
    year       = {2019}
}

@article{DBLP:journals/corr/abs-2003-07311,
    author     = {Suprosanna Shit and
                  Johannes C. Paetzold and
                  Anjany Sekuboyina and
                  Andrey Zhylka and
                  Ivan Ezhov and
                  Alexander Unger and
                  Josien P. W. Pluim and
                  Giles Tetteh and
                  Bjoern H. Menze},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2003-07311.bib},
    doi        = {10.1109/CVPR46437.2021.01629},
    eprint     = {2003.07311},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Tue, 17 Mar 2020 14:18:27 +0100},
    title      = {clDice - a Topology-Preserving Loss Function for Tubular Structure
                  Segmentation},
    volume     = {abs/2003.07311},
    year       = {2020}
}

@article{DBLP:journals/corr/abs-2007-10732,
    author     = {Shuailin Li and
                  Chuyu Zhang and
                  Xuming He},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2007-10732.bib},
    doi        = {10.1007/978-3-030-59710-8_54},
    eprint     = {2007.10732},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Wed, 23 Dec 2020 08:54:04 +0100},
    title      = {Shape-aware Semi-supervised 3D Semantic Segmentation for Medical Images},
    volume     = {abs/2007.10732},
    year       = {2020}
}

@article{DBLP:journals/corr/abs-2008-04751,
    author     = {Xiaofeng Liu and
                  Yimeng Zhang and
                  Xiongchang Liu and
                  Song Bai and
                  Site Li and
                  Jane You},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2008-04751.bib},
    doi        = {10.48550/arXiv.2008.04751},
    eprint     = {2008.04751},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Sun, 16 Aug 2020 17:19:29 +0200},
    title      = {Reinforced Wasserstein Training for Severity-Aware Semantic Segmentation
                  in Autonomous Driving},
    volume     = {abs/2008.04751},
    year       = {2020}
}

@article{DBLP:journals/corr/abs-2101-09957,
    author     = {Johannes Lederer},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2101-09957.bib},
    doi        = {10.48550/arXiv.2101.09957},
    eprint     = {2101.09957},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Sat, 30 Jan 2021 18:02:51 +0100},
    title      = {Activation Functions in Artificial Neural Networks: {A} Systematic
                  Overview},
    volume     = {abs/2101.09957},
    year       = {2021}
}

﻿@article{DBLP:journals/corr/abs-2103-14051,
    author     = {Attila Szab{\'{o}} and
                  Hadi Jamali Rad and
                  Siva{-}Datta Mannava},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2103-14051.bib},
    doi        = {10.48550/arXiv.2103.14051},
    eprint     = {2103.14051},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Wed, 07 Apr 2021 15:31:46 +0200},
    title      = {Tilted Cross Entropy {(TCE):} Promoting Fairness in Semantic Segmentation},
    volume     = {abs/2103.14051},
    year       = {2021}
}
@article{DBLP:journals/corr/abs-2104-08717,
    author     = {Bingyuan Liu and
                  Jose Dolz and
                  Adrian Galdran and
                  Riadh Kobbi and
                  Ismail Ben Ayed},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2104-08717.bib},
    doi        = {10.48550/arXiv.2104.08717},
    eprint     = {2104.08717},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 26 Apr 2021 17:25:10 +0200},
    title      = {The hidden label-marginal biases of segmentation losses},
    volume     = {abs/2104.08717},
    year       = {2021}
}
@article{DBLP:journals/corr/abs-2105-09821,
    author     = {Noor H. Awad and
                  Neeratyoy Mallik and
                  Frank Hutter},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2105-09821.bib},
    doi        = {10.48550/arXiv.2105.09821},
    eprint     = {2105.09821},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 31 May 2021 16:16:57 +0200},
    title      = {{DEHB:} Evolutionary Hyberband for Scalable, Robust and Efficient
                  Hyperparameter Optimization},
    volume     = {abs/2105.09821},
    year       = {2021}
}
@article{DBLP:journals/corr/abs-2107-01153,
    author     = {Wenguan Wang and
                  Tianfei Zhou and
                  Fatih Porikli and
                  David J. Crandall and
                  Luc Van Gool},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2107-01153.bib},
    doi        = {10.48550/arXiv.2107.01153},
    eprint     = {2107.01153},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Wed, 07 Jul 2021 15:23:11 +0200},
    title      = {A Survey on Deep Learning Technique for Video Segmentation},
    volume     = {abs/2107.01153},
    year       = {2021}
}
@article{DBLP:journals/corr/abs-2109-14545,
    author     = {Shiv Ram Dubey and
                  Satish Kumar Singh and
                  Bidyut Baran Chaudhuri},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2109-14545.bib},
    doi        = {10.48550/arXiv.2109.14545},
    eprint     = {2109.14545},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 04 Oct 2021 17:22:25 +0200},
    title      = {A Comprehensive Survey and Performance Analysis of Activation Functions
                  in Deep Learning},
    volume     = {abs/2109.14545},
    year       = {2021}
}
@article{DBLP:journals/corr/AudebertSL16a,
    author     = {Nicolas Audebert and
                  Bertrand Le Saux and
                  S{\'{e}}bastien Lef{\`{e}}vre},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/AudebertSL16a.bib},
    doi        = {10.48550/arXiv.1609.06846},
    eprint     = {1609.06846},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 03 Jan 2022 22:03:27 +0100},
    title      = {Semantic Segmentation of Earth Observation Data Using Multimodal and
                  Multi-scale Deep Networks},
    volume     = {abs/1609.06846},
    year       = {2016}
}
@article{DBLP:journals/corr/Casas17,
    author     = {Noe Casas},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/Casas17.bib},
    doi        = {10.48550/arXiv.1703.09035},
    eprint     = {1703.09035},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:46:25 +0200},
    title      = {Deep Deterministic Policy Gradient for Urban Traffic Light Control},
    volume     = {abs/1703.09035},
    year       = {2017}
}
@article{DBLP:journals/corr/HayderHS16,
    author     = {Zeeshan Hayder and
                  Xuming He and
                  Mathieu Salzmann},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/HayderHS16.bib},
    doi        = {10.48550/arXiv.1612.03129},
    eprint     = {1612.03129},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Wed, 23 Dec 2020 08:54:04 +0100},
    title      = {Shape-aware Instance Segmentation},
    volume     = {abs/1612.03129},
    year       = {2016}
}
@article{DBLP:journals/corr/Li17b,
    author     = {Yuxi Li},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/Li17b.bib},
    doi        = {10.48550/arXiv.1701.07274},
    eprint     = {1701.07274},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:48:40 +0200},
    title      = {Deep Reinforcement Learning: An Overview},
    volume     = {abs/1701.07274},
    year       = {2017}
}
@article{DBLP:journals/corr/LiJDRT16,
    author     = {Lisha Li and
                  Kevin G. Jamieson and
                  Giulia DeSalvo and
                  Afshin Rostamizadeh and
                  Ameet Talwalkar},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/LiJDRT16.bib},
    doi        = {10.48550/arXiv.1603.06560},
    eprint     = {1603.06560},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:48:11 +0200},
    title      = {Efficient Hyperparameter Optimization and Infinitely Many Armed Bandits},
    volume     = {abs/1603.06560},
    year       = {2016}
}
@article{DBLP:journals/corr/RezaK16,
    author     = {Md. Alimoor Reza and
                  Jana Kosecka},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/RezaK16.bib},
    doi        = {10.48550/arXiv.1606.01178},
    eprint     = {1606.01178},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:46:19 +0200},
    title      = {Reinforcement Learning for Semantic Segmentation in Indoor Scenes},
    volume     = {abs/1606.01178},
    year       = {2016}
}
@article{DBLP:journals/corr/RonnebergerFB15,
    author     = {Olaf Ronneberger and
                  Philipp Fischer and
                  Thomas Brox},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/RonnebergerFB15.bib},
    doi        = {10.48550/arXiv.1505.04597},
    eprint     = {1505.04597},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:46:52 +0200},
    title      = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
    volume     = {abs/1505.04597},
    year       = {2015}
}
@article{DBLP:journals/corr/Ruder16,
    author     = {Sebastian Ruder},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/Ruder16.bib},
    doi        = {10.48550/arXiv.1609.04747},
    eprint     = {1609.04747},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:48:10 +0200},
    title      = {An overview of gradient descent optimization algorithms},
    volume     = {abs/1609.04747},
    year       = {2016}
}
@article{DBLP:journals/corr/Ruder17a,
    author     = {Sebastian Ruder},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/Ruder17a.bib},
    doi        = {10.48550/arXiv.1706.05098},
    eprint     = {1706.05098},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:48:50 +0200},
    title      = {An Overview of Multi-Task Learning in Deep Neural Networks},
    volume     = {abs/1706.05098},
    year       = {2017}
}
@article{DBLP:journals/corr/SalehiEG17a,
    author     = {Seyed Sadegh Mohseni Salehi and
                  Deniz Erdogmus and
                  Ali Gholipour},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/SalehiEG17a.bib},
    doi        = {10.48550/arXiv.1706.05721},
    eprint     = {1706.05721},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:48:37 +0200},
    title      = {Tversky loss function for image segmentation using 3D fully convolutional
                  deep networks},
    volume     = {abs/1706.05721},
    year       = {2017}
}
@article{DBLP:journals/corr/SchulmanWDRK17,
    author     = {John Schulman and
                  Filip Wolski and
                  Prafulla Dhariwal and
                  Alec Radford and
                  Oleg Klimov},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
    doi        = {10.48550/arXiv.1707.06347},
    eprint     = {1707.06347},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:47:34 +0200},
    title      = {Proximal Policy Optimization Algorithms},
    volume     = {abs/1707.06347},
    year       = {2017}
}
@article{DBLP:journals/corr/ZhengJRVSDHT15,
    author     = {Shuai Zheng and
                  Sadeep Jayasumana and
                  Bernardino Romera{-}Paredes and
                  Vibhav Vineet and
                  Zhizhong Su and
                  Dalong Du and
                  Chang Huang and
                  Philip H. S. Torr},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/ZhengJRVSDHT15.bib},
    doi        = {10.1109/ICCV.2015.179},
    eprint     = {1502.03240},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:48:59 +0200},
    title      = {Conditional Random Fields as Recurrent Neural Networks},
    volume     = {abs/1502.03240},
    year       = {2015}
}
@article{de2018new,
    abstract = {Decision trees and logistic regression are two very popular algorithms in customer churn prediction with strong predictive performance and good comprehensibility. Despite these strengths, decision trees tend to have problems to handle linear relations between variables and logistic regression has difficulties with interaction effects between variables. Therefore a new hybrid algorithm, the logit leaf model (LLM), is proposed to better classify data. The idea behind the LLM is that different models constructed on segments of the data rather than on the entire dataset lead to better predictive performance while maintaining the comprehensibility from the models constructed in the leaves. The LLM consists of two stages: a segmentation phase and a prediction phase. In the first stage customer segments are identified using decision rules and in the second stage a model is created for every leaf of this tree. This new hybrid approach is benchmarked against decision trees, logistic regression, random forests and logistic model trees with regards to the predictive performance and comprehensibility. The area under the receiver operating characteristics curve (AUC) and top decile lift (TDL) are used to measure the predictive performance for which LLM scores significantly better than its building blocks logistic regression and decision trees and performs at least as well as more advanced ensemble methods random forests and logistic model trees. Comprehensibility is addressed by a case study for which we observe some key benefits using the LLM compared to using decision trees or logistic regression.},
    author   = {Arno {De Caigny} and Kristof Coussement and Koen W. {De Bock}},
    doi      = {10.1016/j.ejor.2018.02.009},
    issn     = {0377-2217},
    journal  = {European Journal of Operational Research},
    keywords = {OR in marketing, Hybrid algorithm, Customer churn prediction, Logit leaf model, Predictive analytics},
    number   = {2},
    pages    = {760-772},
    title    = {A new hybrid classification algorithm for customer churn prediction based on logistic regression and decision trees},
    volume   = {269},
    year     = {2018}
}
@misc{decisionTreesAdvantages,
    author = {Sebastian Taylor},
    month  = nov,
    note   = {[Online; accessed 1. Mar. 2023]},
    title  = {{Decision Tree}},
    url    = {https://corporatefinanceinstitute.com/resources/data-science/decision-tree},
    year   = {2022}
}
@article{deng2014deep,
    author  = {Li Deng and Dong Yu},
    doi     = {10.1561/2000000039},
    issn    = {1932-8346},
    journal = {Foundations and Trends® in Signal Processing},
    number  = {3–4},
    pages   = {197-387},
    title   = {Deep Learning: Methods and Applications},
    volume  = {7},
    year    = {2014}
}
@article{deng2016deep,
    author  = {Deng, Yue and Bao, Feng and Kong, Youyong and Ren, Zhiquan and Dai, Qionghai},
    doi     = {10.1109/TNNLS.2016.2522401},
    journal = {IEEE Transactions on Neural Networks and Learning Systems},
    number  = {3},
    pages   = {653-664},
    title   = {Deep Direct Reinforcement Learning for Financial Signal Representation and Trading},
    volume  = {28},
    year    = {2017}
}
@misc{dewiki:195577036,
    author = {Wikipedia},
    note   = {[Online; Stand 20. März 2021]},
    title  = {Potenzmenge --- Wikipedia{,} Die freie Enzyklopädie},
    url    = {https://de.wikipedia.org/w/index.php?title=Potenzmenge&oldid=195577036},
    year   = {2020}
}
@inproceedings{dlr108960,
    abstract  = {This paper describes a deep learning approach to semantic segmentation of very high resolution (aerial) images. Deep neural architectures hold the promise of end-to-end learning from raw images, making heuristic feature design obsolete. Over the last decade this idea has seen a revival, and in recent years deep convolutional neural networks (CNNs) have emerged as the method of choice for a range of image interpretation tasks like visual recognition and object detection. Still, standard CNNs do not lend themselves to per-pixel semantic segmentation, mainly because one of their fundamental principles is to gradually aggregate information over larger and larger image regions, making it hard to disentangle contributions from different pixels. Very recently two extensions of the CNN framework have made it possible to trace the semantic information back to a precise pixel position: deconvolutional network layers undo the spatial downsampling, and Fully Convolution Networks (FCNs) modify the fully connected classification layers of the network in such a way that the location of individual activations remains explicit. We design a FCN which takes as input intensity and range data and, with the help of aggressive deconvolution and recycling of early network layers, converts them into a pixelwise classification at full resolution. We discuss design choices and intricacies of such a network, and demonstrate that an ensemble of several networks achieves excellent results on challenging data such as the ISPRS semantic labeling benchmark, using only the raw data as input.},
    author    = {Dimitrios Marmanis and Jan D. Wegner and Silvano Galliani and K. Schindler and Mihai Datcu and U. Stilla},
    booktitle = {ISPRS Congress},
    doi       = {10.5194/isprsannals-III-3-473-2016},
    editor    = {L. Halounova and K. Schindler and A. Limpouch and V. {\vS}af{\'a}{\vr} and T. Pajdla and H. Mayer and S. Oude Elberink and C. Mallet and F. Rottensteiner and J. Skaloud and U. Stilla and M. Br{\'e}dif},
    journal   = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2016},
    keywords  = {semantic segmentation},
    pages     = {473--480},
    publisher = {Copernicus Publications},
    title     = {Semantic Segmentation of Aerial Images with an Ensemble of CNSS},
    volume    = {III-3},
    year      = {2016}
}
@article{doi:10.1080/0266476042000214501,
    author    = { Silvia   Ferrari  and  Francisco   Cribari-Neto },
    doi       = {10.1080/0266476042000214501},
    eprint    = {https://doi.org/10.1080/0266476042000214501},
    journal   = {Journal of Applied Statistics},
    number    = {7},
    pages     = {799-815},
    publisher = {Taylor & Francis},
    title     = {Beta Regression for Modelling Rates and Proportions},
    volume    = {31},
    year      = {2004}
}
@article{doi:10.1080/08839514.2022.2032924,
    author    = {Irem Ulku and Erdem Akagündüz},
    doi       = {10.1080/08839514.2022.2032924},
    eprint    = {                  
                 https://doi.org/10.1080/08839514.2022.2032924
                 
                 },
    journal   = {Applied Artificial Intelligence},
    number    = {1},
    pages     = {2032924},
    publisher = {Taylor & Francis},
    title     = {A Survey on Deep Learning-based Architectures for Semantic Segmentation on 2D Images},
    volume    = {36},
    year      = {2022}
}
@article{doi:10.1126/science.aaa8415,
    abstract = {Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today’s most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.},
    author   = {M. I. Jordan  and T. M. Mitchell },
    doi      = {10.1126/science.aaa8415},
    eprint   = {https://www.science.org/doi/pdf/10.1126/science.aaa8415},
    journal  = {Science},
    number   = {6245},
    pages    = {255-260},
    title    = {Machine learning: Trends, perspectives, and prospects},
    volume   = {349},
    year     = {2015}
}
@article{doi:10.1142/S0218195905001622,
    abstract = { In the typical nonparametric approach to classification in instance-based learning and data mining, random data (the training set of patterns) are collected and used to design a decision rule (classifier). One of the most well known such rules is the k-nearest-neighbor decision rule (also known as lazy learning) in which an unknown pattern is classified into the majority class among its k nearest neighbors in the training set. Several questions related to this rule have received considerable attention over the years. Such questions include the following. How can the storage of the training set be reduced without degrading the performance of the decision rule? How should the reduced training set be selected to represent the different classes? How large should k be? How should the value of k be chosen? Should all k neighbors be equally weighted when used to decide the class of an unknown pattern? If not, how should the weights be chosen? Should all the features (attributes) we weighted equally and if not how should the feature weights be chosen? What distance metric should be used? How can the rule be made robust to overlapping classes or noise present in the training data? How can the rule be made invariant to scaling of the measurements? How can the nearest neighbors of a new point be computed efficiently? What is the smallest neural network that can implement nearest neighbor decision rules? Geometric proximity graphs such as Voronoi diagrams and their many relatives provide elegant solutions to these problems, as well as other related data mining problems such as outlier detection. After a non-exhaustive review of some of the classical canonical approaches to these problems, the methods that use proximity graphs are discussed, some new observations are made, and open problems are listed. },
    author   = {TOUSSAINT, GODFRIED},
    doi      = {10.1142/S0218195905001622},
    eprint   = {https://doi.org/10.1142/S0218195905001622},
    journal  = {International Journal of Computational Geometry \& Applications},
    number   = {02},
    pages    = {101-150},
    title    = {GEOMETRIC PROXIMITY GRAPHS FOR IMPROVING NEAREST NEIGHBOR METHODS IN INSTANCE-BASED LEARNING AND DATA MINING},
    volume   = {15},
    year     = {2005}
}
@article{donahue2018adversarial,
    author     = {Chris Donahue and
                  Julian J. McAuley and
                  Miller S. Puckette},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1802-04208.bib},
    doi        = {10.48550/arXiv.1802.04208},
    eprint     = {1802.04208},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 22 Jul 2019 19:17:32 +0200},
    title      = {Synthesizing Audio with Generative Adversarial Networks},
    volume     = {abs/1802.04208},
    year       = {2018}
}
@article{Dong2020,
    abstract = {Despite significant successes achieved in knowledge discovery, traditional machine learning methods may fail to obtain satisfactory performances when dealing with complex data, such as imbalanced, high-dimensional, noisy data, etc. The reason behind is that it is difficult for these methods to capture multiple characteristics and underlying structure of data. In this context, it becomes an important topic in the data mining field that how to effectively construct an efficient knowledge discovery and mining model. Ensemble learning, as one research hot spot, aims to integrate data fusion, data modeling, and data mining into a unified framework. Specifically, ensemble learning firstly extracts a set of features with a variety of transformations. Based on these learned features, multiple learning algorithms are utilized to produce weak predictive results. Finally, ensemble learning fuses the informative knowledge from the above results obtained to achieve knowledge discovery and better predictive performance via voting schemes in an adaptive way. In this paper, we review the research progress of the mainstream approaches of ensemble learning and classify them based on different characteristics. In addition, we present challenges and possible research directions for each mainstream approach of ensemble learning, and we also give an extra introduction for the combination of ensemble learning with other machine learning hot spots such as deep learning, reinforcement learning, etc.},
    author   = {Dong, Xibin
                and Yu, Zhiwen
                and Cao, Wenming
                and Shi, Yifan
                and Ma, Qianli},
    day      = {01},
    doi      = {10.1007/s11704-019-8208-z},
    issn     = {2095-2236},
    journal  = {Frontiers of Computer Science},
    month    = {04},
    number   = {2},
    pages    = {241-258},
    title    = {A survey on ensemble learning},
    volume   = {14},
    year     = {2020}
}
@inproceedings{donmez2007dual,
    abstract  = {Active Learning methods rely on static strategies for sampling unlabeled point(s). These strategies range from uncertainty sampling and density estimation to multi-factor methods with learn-once-use-always model parameters. This paper proposes a dynamic approach, called DUAL, where the strategy selection parameters are adaptively updated based on estimated future residual error reduction after each actively sampled point. The objective of dual is to outperform static strategies over a large operating range: from very few to very many labeled points. Empirical results over six datasets demonstrate that DUAL outperforms several state-of-the-art methods on most datasets.},
    address   = {Berlin, Heidelberg},
    author    = {Donmez, Pinar
                 and Carbonell, Jaime G.
                 and Bennett, Paul N.},
    booktitle = {Machine Learning: ECML 2007},
    doi       = {10.1007/978-3-540-74958-5_14},
    editor    = {Kok, Joost N.
                 and Koronacki, Jacek
                 and Mantaras, Raomon Lopez de
                 and Matwin, Stan
                 and Mladeni{\v{c}}, Dunja
                 and Skowron, Andrzej},
    isbn      = {978-3-540-74958-5},
    pages     = {116--127},
    publisher = {Springer Berlin Heidelberg},
    title     = {Dual Strategy Active Learning},
    year      = {2007}
}
@article{Doya2007ReinforcementLC,
    author    = { Kenji   Doya },
    doi       = {10.2976/1.2732246/10.2976/1},
    eprint    = {https://doi.org/10.2976/1.2732246/10.2976/1},
    journal   = {HFSP Journal},
    note      = {PMID: 19404458},
    number    = {1},
    pages     = {30-40},
    publisher = {Taylor & Francis},
    title     = {Reinforcement learning: Computational theory and biological mechanisms},
    volume    = {1},
    year      = {2007}
}
@article{DRAGUT2014119,
    abstract = {We introduce a new automated approach to parameterising multi-scale image segmentation of multiple layers, and we implemented it as a generic tool for the eCognition® software. This approach relies on the potential of the local variance (LV) to detect scale transitions in geospatial data. The tool detects the number of layers added to a project and segments them iteratively with a multiresolution segmentation algorithm in a bottom-up approach, where the scale factor in the segmentation, namely, the scale parameter (SP), increases with a constant increment. The average LV value of the objects in all of the layers is computed and serves as a condition for stopping the iterations: when a scale level records an LV value that is equal to or lower than the previous value, the iteration ends, and the objects segmented in the previous level are retained. Three orders of magnitude of SP lags produce a corresponding number of scale levels. Tests on very high resolution imagery provided satisfactory results for generic applicability. The tool has a significant potential for enabling objectivity and automation of GEOBIA analysis.},
    author   = {L. Drăguţ and O. Csillik and C. Eisank and D. Tiede},
    doi      = {10.1016/j.isprsjprs.2013.11.018},
    issn     = {0924-2716},
    journal  = {ISPRS Journal of Photogrammetry and Remote Sensing},
    keywords = {Automation, Imagery, Object, Representation, GEOBIA, MRS},
    pages    = {119-127},
    title    = {Automated parameterisation for multi-scale image segmentation on multiple layers},
    volume   = {88},
    year     = {2014}
}
@article{du2020medical,
    author  = {Du, Getao and Cao, Xu and Liang, Jimin and Chen, Xueli and Zhan, Yonghua},
    doi     = {10.2352/J.ImagingSci.Technol.2020.64.2.020508},
    journal = {Journal of Imaging Science and Technology},
    month   = {03},
    pages   = {},
    title   = {Medical Image Segmentation based on U-Net: A Review},
    volume  = {64},
    year    = {2020}
}

@article{EatonRosen2018ImprovingDA,
    author  = {Eaton-Rosen, Zach and Bragman, Felix and Ourselin, Sebastien and Cardoso, M. Jorge},
    journal = {OpenReview},
    month   = {06},
    title   = {{Improving Data Augmentation for Medical Image Segmentation}},
    url     = {https://openreview.net/forum?id=rkBBChjiG},
    year    = {2018}
}
@inproceedings{eitel2015multimodal,
    author    = {Eitel, Andreas and Springenberg, Jost Tobias and Spinello, Luciano and Riedmiller, Martin and Burgard, Wolfram},
    booktitle = {2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
    doi       = {10.1109/IROS.2015.7353446},
    number    = {},
    pages     = {681-687},
    title     = {Multimodal deep learning for robust RGB-D object recognition},
    volume    = {},
    year      = {2015}
}
@article{Elizar2022-ey,
    abstract = {In general, most of the existing convolutional neural network
                (CNN)-based deep-learning models suffer from spatial-information
                loss and inadequate feature-representation issues. This is due to
                their inability to capture multiscale-context information and the
                exclusion of semantic information throughout the pooling
                operations. In the early layers of a CNN, the network encodes
                simple semantic representations, such as edges and corners,
                while, in the latter part of the CNN, the network encodes more
                complex semantic features, such as complex geometric shapes.
                Theoretically, it is better for a CNN to extract features from
                different levels of semantic representation because tasks such as
                classification and segmentation work better when both simple and
                complex feature maps are utilized. Hence, it is also crucial to
                embed multiscale capability throughout the network so that the
                various scales of the features can be optimally captured to
                represent the intended task. Multiscale representation enables
                the network to fuse low-level and high-level features from a
                restricted receptive field to enhance the deep-model performance.
                The main novelty of this review is the comprehensive novel
                taxonomy of multiscale-deep-learning methods, which includes
                details of several architectures and their strengths that have
                been implemented in the existing works. Predominantly, multiscale
                approaches in deep-learning networks can be classed into two
                categories: multiscale feature learning and multiscale feature
                fusion. Multiscale feature learning refers to the method of
                deriving feature maps by examining kernels over several sizes to
                collect a larger range of relevant features and predict the input
                images' spatial mapping. Multiscale feature fusion uses features
                with different resolutions to find patterns over short and long
                distances, without a deep network. Additionally, several examples
                of the techniques are also discussed according to their
                applications in satellite imagery, medical imaging, agriculture,
                and industrial and manufacturing systems.},
    address  = {Switzerland},
    author   = {Elizar, Elizar and Zulkifley, Mohd Asyraf and Muharar, Rusdha and
                Zaman, Mohd Hairi Mohd and Mustaza, Seri Mastura},
    doi      = {10.3390/s22197384},
    journal  = {Sensors (Basel)},
    keywords = {artificial intelligence; convolutional neural network; deep
                learning; machine learning; multiscale features; neural network},
    language = {en},
    month    = {09},
    number   = 19,
    title    = {A Review on {Multiscale-Deep-Learning} Applications},
    volume   = 22,
    year     = 2022
}
@misc{enwiki:1007204420,
    author = {{Contributors to Wikimedia projects}},
    month  = feb,
    note   = {[Online; accessed 2. Jul. 2023]},
    title  = {{Cantor's diagonal argument - Wikipedia}},
    url    = {https://en.wikipedia.org/w/index.php?title=Cantor%27s_diagonal_argument&oldid=1007204420},
    year   = {2021}
}
@misc{enwiki:1119751219,
    author = {{Wikipedia contributors}},
    note   = {[Online; accessed 7-March-2023]},
    title  = {Ambiguous image --- {Wikipedia}{,} The Free Encyclopedia},
    url    = {https://en.wikipedia.org/w/index.php?title=Ambiguous_image&oldid=1119751219},
    year   = {2022}
}
@inproceedings{ess2009segmentation,
    author       = {Ess, Andreas and M{\"u}ller, Tobias and Grabner, Helmut and Van Gool, Luc},
    booktitle    = {BMVC},
    doi          = {10.5244/C.23.84},
    organization = {Citeseer},
    pages        = {2},
    title        = {Segmentation-Based Urban Traffic Scene Understanding.},
    volume       = {1},
    year         = {2009}
}
@article{everingham2015pascal,
    abstract = {The Pascal Visual Object Classes (VOC) challenge consists of two components: (i) a publicly available dataset of images together with ground truth annotation and standardised evaluation software; and (ii) an annual competition and workshop. There are five challenges: classification, detection, segmentation, action classification, and person layout. In this paper we provide a review of the challenge from 2008--2012. The paper is intended for two audiences: algorithm designers, researchers who want to see what the state of the art is, as measured by performance on the VOC datasets, along with the limitations and weak points of the current generation of algorithms; and, challenge designers, who want to see what we as organisers have learnt from the process and our recommendations for the organisation of future challenges. To analyse the performance of submitted algorithms on the VOC datasets we introduce a number of novel evaluation methods: a bootstrapping method for determining whether differences in the performance of two algorithms are significant or not; a normalised average precision so that performance can be compared across classes with different proportions of positive instances; a clustering method for visualising the performance across multiple algorithms so that the hard and easy images can be identified; and the use of a joint classifier over the submitted algorithms in order to measure their complementarity and combined performance. We also analyse the community's progress through time using the methods of Hoiem et al. (Proceedings of European Conference on Computer Vision, 2012) to identify the types of occurring errors. We conclude the paper with an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges.},
    author   = {Everingham, Mark
                and Eslami, S. M. Ali
                and Van Gool, Luc
                and Williams, Christopher K. I.
                and Winn, John
                and Zisserman, Andrew},
    day      = {01},
    doi      = {10.1007/s11263-014-0733-5},
    issn     = {1573-1405},
    journal  = {International Journal of Computer Vision},
    month    = {01},
    number   = {1},
    pages    = {98-136},
    title    = {The Pascal Visual Object Classes Challenge: A Retrospective},
    volume   = {111},
    year     = {2015}
}
@article{Falk2019,
    abstract = {U-Net is a generic deep-learning solution for frequently occurring quantification tasks such as cell detection and shape measurements in biomedical image data. We present an ImageJ plugin that enables non-machine-learning experts to analyze their data with U-Net on either a local computer or a remote server/cloud service. The plugin comes with pretrained models for single-cell segmentation and allows for U-Net to be adapted to new tasks on the basis of a few annotated samples.},
    author   = {Falk, Thorsten
                and Mai, Dominic
                and Bensch, Robert
                and {\c{C}}i{\c{c}}ek, {\"O}zg{\"u}n
                and Abdulkadir, Ahmed
                and Marrakchi, Yassine
                and B{\"o}hm, Anton
                and Deubner, Jan
                and J{\"a}ckel, Zoe
                and Seiwald, Katharina
                and Dovzhenko, Alexander
                and Tietz, Olaf
                and Dal Bosco, Cristina
                and Walsh, Sean
                and Saltukoglu, Deniz
                and Tay, Tuan Leng
                and Prinz, Marco
                and Palme, Klaus
                and Simons, Matias
                and Diester, Ilka
                and Brox, Thomas
                and Ronneberger, Olaf},
    day      = {01},
    doi      = {10.1038/s41592-018-0261-2},
    issn     = {1548-7105},
    journal  = {Nature Methods},
    month    = {01},
    number   = {1},
    pages    = {67-70},
    title    = {U-Net: deep learning for cell counting, detection, and morphometry},
    volume   = {16},
    year     = {2019}
}
@article{feng2020deep,
    author  = {Feng, Di and Haase-Schütz, Christian and Rosenbaum, Lars and Hertlein, Heinz and Gläser, Claudius and Timm, Fabian and Wiesbeck, Werner and Dietmayer, Klaus},
    doi     = {10.1109/TITS.2020.2972974},
    journal = {IEEE Transactions on Intelligent Transportation Systems},
    number  = {3},
    pages   = {1341-1360},
    title   = {Deep Multi-Modal Object Detection and Semantic Segmentation for Autonomous Driving: Datasets, Methods, and Challenges},
    volume  = {22},
    year    = {2021}
}
@article{fevry2018unsupervised,
    author     = {Thibault F{\'{e}}vry and
                  Jason Phang},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1809-02669.bib},
    doi        = {10.48550/arXiv.1809.02669},
    eprint     = {1809.02669},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Fri, 05 Oct 2018 11:34:52 +0200},
    title      = {Unsupervised Sentence Compression using Denoising Auto-Encoders},
    volume     = {abs/1809.02669},
    year       = {2018}
}

@article{gaikwad2010review,
    author    = {Gaikwad, Santosh K and Gawali, Bharti W and Yannawar, Pravin},
    doi       = {10.5120/1462-1976},
    journal   = {International Journal of Computer Applications},
    number    = {3},
    pages     = {16--24},
    publisher = {International Journal of Computer Applications, 244 5 th Avenue,\# 1526},
    title     = {A review on speech recognition technique},
    volume    = {10},
    year      = {2010}
}

@inproceedings{gal2016dropout,
    abstract  = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs – extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout’s uncertainty in deep reinforcement learning.},
    address   = {New York, New York, USA},
    author    = {Gal, Yarin and Ghahramani, Zoubin},
    booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
    editor    = {Balcan, Maria Florina and Weinberger, Kilian Q.},
    month     = {06},
    pages     = {1050--1059},
    pdf       = {http://proceedings.mlr.press/v48/gal16.pdf},
    publisher = {PMLR},
    series    = {Proceedings of Machine Learning Research},
    title     = {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
    url       = {https://proceedings.mlr.press/v48/gal16.html},
    volume    = {48},
    year      = {2016}
}
@article{GARCIAGARCIA201841,
    abstract = {Image semantic segmentation is more and more being of interest for computer vision and machine learning researchers. Many applications on the rise need accurate and efficient segmentation mechanisms: autonomous driving, indoor navigation, and even virtual or augmented reality systems to name a few. This demand coincides with the rise of deep learning approaches in almost every field or application target related to computer vision, including semantic segmentation or scene understanding. This paper provides a review on deep learning methods for semantic segmentation applied to various application areas. Firstly, we formulate the semantic segmentation problem and define the terminology of this field as well as interesting background concepts. Next, the main datasets and challenges are exposed to help researchers decide which are the ones that best suit their needs and goals. Then, existing methods are reviewed, highlighting their contributions and their significance in the field. We also devote a part of the paper to review common loss functions and error metrics for this problem. Finally, quantitative results are given for the described methods and the datasets in which they were evaluated, following up with a discussion of the results. At last, we point out a set of promising future works and draw our own conclusions about the state of the art of semantic segmentation using deep learning techniques.},
    author   = {Alberto Garcia-Garcia and Sergio Orts-Escolano and Sergiu Oprea and Victor Villena-Martinez and Pablo Martinez-Gonzalez and Jose Garcia-Rodriguez},
    doi      = {10.1016/j.asoc.2018.05.018},
    issn     = {1568-4946},
    journal  = {Applied Soft Computing},
    keywords = {Semantic segmentation, Deep learning, Scene labeling},
    pages    = {41-65},
    title    = {A survey on deep learning techniques for image and video semantic segmentation},
    volume   = {70},
    year     = {2018}
}
@misc{gelman2013bayesian,
    month = jul,
    note  = {[Online; accessed 2. Jul. 2023]},
    title = {{Home page for the book, "Bayesian Data Analysis"}},
    url   = {http://www.stat.columbia.edu/~gelman/book},
    year  = {2020}
}
@incollection{Gerl_2020,
    author    = {Stefan Gerl and Johannes C. Paetzold and Hailong He and Ivan Ezhov and Suprosanna Shit and Florian Kofler and Amirhossein Bayat and Giles Tetteh and Vasilis Ntziachristos and Bjoern Menze},
    booktitle = {Medical Image Computing and Computer Assisted Intervention {\textendash} {MICCAI} 2020},
    doi       = {10.1007/978-3-030-59725-2_30},
    pages     = {309--319},
    publisher = {Springer International Publishing},
    title     = {A Distance-Based Loss for Smooth and Continuous Skin Layer Segmentation in Optoacoustic Images},
    year      = 2020
}
@book{goodfellow2016deep,
    author    = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
    publisher = {MIT press},
    title     = {Deep learning},
    url       = {https://mitpress.mit.edu/9780262035613/deep-learning},
    year      = {2016}
}
@misc{gottesman2018evaluating,
    author    = {Gottesman, Omer and Johansson, Fredrik and Meier, Joshua and Dent, Jack and Lee, Donghun and Srinivasan, Srivatsan and Zhang, Linying and Ding, Yi and Wihl, David and Peng, Xuefeng and Yao, Jiayu and Lage, Isaac and Mosch, Christopher and Lehman, Li-wei H. and Komorowski, Matthieu and Komorowski, Matthieu and Faisal, Aldo and Celi, Leo Anthony and Sontag, David and Doshi-Velez, Finale},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1805.12298},
    keywords  = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Evaluating Reinforcement Learning Algorithms in Observational Health Settings},
    year      = {2018}
}
% Start
@article{grady2006random,
    author  = {Grady, L.},
    doi     = {10.1109/TPAMI.2006.233},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    number  = {11},
    pages   = {1768-1783},
    title   = {Random Walks for Image Segmentation},
    volume  = {28},
    year    = {2006}
}
@book{grimson1991object,
    address   = {Cambridge, MA, USA},
    isbn      = {978-026207130},
    journal   = {Guide books},
    publisher = {MIT Press},
    title     = {{Object recognition by computer {$\vert$} Guide books}},
    url       = {https://dl.acm.org/doi/abs/10.5555/102900}
}
@article{Guo2020,
    abstract = {Feature representation is generally applied to reducing the dimensions of high-dimensional data to accelerate the process of data handling and enhance the performance of pattern recognition. However, the dimensionality of data nowadays appears to be a rapidly increasing trend. Existing unsupervised feature representation methods are susceptible to the rapidly increasing dimensionality of data, which may result in learning a meaningless feature that in turn affect their performance in other applications. In this paper, an unsupervised adversarial auto-encoder network is studied. This network is a probability model that combines generative adversarial networks and variational auto-encoder to perform variational inference and aims to generate reconstructed data similar to original data as much as possible. Due to its adversarial training, this model is relatively robust in feature learning compared with other methods. First, the architecture and training strategy of adversarial auto-encoder are presented. We attempt to learn a discriminative feature representation for high-dimensional image data via adversarial auto-encoder and take its advantage into image clustering, which has become a difficult computer vision task recently. Then amounts of comparative experiments are carried out. The comparison contains eight feature representation methods and two recently proposed deep clustering methods performed on eight different publicly available image data sets. Finally, to evaluate their performance, we utilize a K-means clustering on the low-dimensional feature learned from each feature representation algorithm, and select three evaluation metrics including clustering accuracy, adjusted rand index and normalized mutual information, to provide a comparison. Comprehensive experiments prove the usefulness of the learned discriminative feature via adversarial auto-encoder in the tested data sets.},
    author   = {Guo, Wenzhong
                and Cai, Jinyu
                and Wang, Shiping},
    day      = {01},
    doi      = {10.1007/s10489-019-01581-7},
    issn     = {1573-7497},
    journal  = {Applied Intelligence},
    month    = {04},
    number   = {4},
    pages    = {1155-1171},
    title    = {Unsupervised discriminative feature representation via adversarial auto-encoder},
    volume   = {50},
    year     = {2020}
}
@online{h25w9818,
    author    = {Porwal, Prasanna and Pachade, Samiksha and Kamble, Ravi and Kokare, Manesh and Deshmukh, Girish and Sahasrabuddhe, Vivek and Meriaudeau, Fabrice},
    doi       = {10.21227/H25W98},
    publisher = {IEEE Dataport},
    title     = {Indian Diabetic Retinopathy Image Dataset (IDRiD)},
    year      = {2018}
}
@article{hadden2008churn,
    author  = {Hadden, John and Tiwari, Ashutosh and Roy, Rajkumar and Ruta, Dymitr},
    journal = {International Journal of Industrial and Manufacturing Engineering},
    number  = {4},
    pages   = {524--536},
    title   = {Churn prediction: Does technology matter?},
    url     = {https://www.researchgate.net/publication/283992554_Churn_Prediction_Does_Technology_Matter},
    volume  = {2},
    year    = {2008}
}
@article{hafiz2020survey,
    abstract = {Object detection or localization is an incremental step in progression from coarse to fine digital image inference. It not only provides the classes of the image objects, but also provides the location of the image objects which have been classified. The location is given in the form of bounding boxes or centroids. Semantic segmentation gives fine inference by predicting labels for every pixel in the input image. Each pixel is labelled according to the object class within which it is enclosed. Furthering this evolution, instance segmentation gives different labels for separate instances of objects belonging to the same class. Hence, instance segmentation may be defined as the technique of simultaneously solving the problem of object detection as well as that of semantic segmentation. In this survey paper on instance segmentation, its background, issues, techniques, evolution, popular datasets, related work up to the state of the art and future scope have been discussed. The paper provides valuable information for those who want to do research in the field of instance segmentation.},
    author   = {Hafiz, Abdul Mueed
                and Bhat, Ghulam Mohiuddin},
    day      = {01},
    doi      = {10.1007/s13735-020-00195-x},
    issn     = {2192-662X},
    journal  = {International Journal of Multimedia Information Retrieval},
    month    = {09},
    number   = {3},
    pages    = {171-189},
    title    = {A survey on instance segmentation: state of the art},
    volume   = {9},
    year     = {2020}
}
@book{hammersley2013monte,
    address   = {London, England, UK},
    author    = {Hammersley, John Michael and Handscomb, David Christopher},
    isbn      = {978-0-41652340-9},
    publisher = {Methuen},
    title     = {{Monte Carlo Methods}},
    url       = {https://books.google.de/books/about/Monte_Carlo_Methods.html?id=Kk4OAAAAQAAJ&redir_esc=y},
    year      = {1964}
}
@article{hardoon2004canonical,
    author  = {Hardoon, David R. and Szedmak, Sandor and Shawe-Taylor, John},
    doi     = {10.1162/0899766042321814},
    journal = {Neural Computation},
    number  = {12},
    pages   = {2639-2664},
    title   = {Canonical Correlation Analysis: An Overview with Application to Learning Methods},
    volume  = {16},
    year    = {2004}
}

﻿@article{Hashemi_2019,
    author    = {Seyed Raein Hashemi and Seyed Sadegh Mohseni Salehi and Deniz Erdogmus and Sanjay P. Prabhu and Simon K. Warfield and Ali Gholipour},
    doi       = {10.1109/access.2018.2886371},
    journal   = {{IEEE} Access},
    pages     = {1721--1735},
    publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
    title     = {Asymmetric Loss Functions and Deep Densely-Connected Networks for Highly-Imbalanced Medical Image Segmentation: Application to Multiple Sclerosis Lesion Detection},
    volume    = {7},
    year      = 2019
}

@book{hastie2009elements,
    address   = {New York, NY, USA},
    author    = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
    isbn      = {978-0-387-84858-7},
    journal   = {SpringerLink},
    publisher = {Springer},
    title     = {{The Elements of Statistical Learning}},
    url       = {https://link.springer.com/book/10.1007/978-0-387-84858-7}
}
@article{haucke2021exploiting,
    author     = {Timm Haucke and
                  Volker Steinhage},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2102-05607.bib},
    doi        = {10.48550/arXiv.2102.05607},
    eprint     = {2102.05607},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Thu, 18 Feb 2021 15:26:00 +0100},
    title      = {Exploiting Depth Information for Wildlife Monitoring},
    volume     = {abs/2102.05607},
    year       = {2021}
}
@book{hausdorff1914grundzuge,
    author    = {Hausdorff, Felix},
    doi       = {10.1007/BF01999507},
    publisher = {von Veit},
    title     = {Grundz{\"u}ge der mengenlehre},
    volume    = {7},
    year      = {1914}
}

@inproceedings{He_2019_ICCV,
    author    = {He, Junjun and Deng, Zhongying and Qiao, Yu},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    doi       = {10.1109/ICCV.2019.00366},
    month     = {10},
    title     = {Dynamic Multi-Scale Filters for Semantic Segmentation},
    year      = {2019}
}

@article{Hearst1998TrendsC,
    author  = {Marti A. Hearst},
    journal = {IEEE Intell. Syst.},
    pages   = {18-28},
    title   = {Trends \& Controversies: Support Vector Machines},
    url     = {https://www.semanticscholar.org/paper/Trends-%26-Controversies%3A-Support-Vector-Machines-Hearst/455d9a4ff96561d543acbcb2aa81d6cd8fcd20df},
    volume  = {13},
    year    = {1998}
}
@article{heinrich2016deep,
    author     = {Johannes Heinrich and
                  David Silver},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/HeinrichS16.bib},
    doi        = {10.48550/arXiv.1603.01121},
    eprint     = {1603.01121},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:47:19 +0200},
    title      = {Deep Reinforcement Learning from Self-Play in Imperfect-Information
                  Games},
    volume     = {abs/1603.01121},
    year       = {2016}
}
@article{Henson2021,
    abstract = {The integration of technology in clinical care is growing rapidly and has become especially relevant during the global COVID-19 pandemic. Smartphone-based digital phenotyping, or the use of integrated sensors to identify patterns in behavior and symptomatology, has shown potential in detecting subtle moment-to-moment changes. These changes, often referred to as anomalies, represent significant deviations from an individual's baseline, may be useful in informing the risk of relapse in serious mental illness. Our investigation of smartphone-based anomaly detection resulted in 89{\%} sensitivity and 75{\%} specificity for predicting relapse in schizophrenia. These results demonstrate the potential of longitudinal collection of real-time behavior and symptomatology via smartphones and the clinical utility of individualized analysis. Future studies are necessary to explore how specificity can be improved, just-in-time adaptive interventions utilized, and clinical integration achieved.},
    author   = {Henson, Philip
                and D'Mello, Ryan
                and Vaidyam, Aditya
                and Keshavan, Matcheri
                and Torous, John},
    day      = {11},
    doi      = {10.1038/s41398-020-01123-7},
    issn     = {2158-3188},
    journal  = {Translational Psychiatry},
    month    = {01},
    number   = {1},
    pages    = {28},
    title    = {Anomaly detection to predict relapse risk in schizophrenia},
    volume   = {11},
    year     = {2021}
}
@article{hijazi2015using,
    author  = {Hijazi, Samer and Kumar, Rishi and Rowen, Chris and others},
    journal = {Cadence Design Systems Inc.: San Jose, CA, USA},
    title   = {Using convolutional neural networks for image recognition},
    url     = {https://www.semanticscholar.org/paper/Using-Convolutional-Neural-Networks-for-Image-By-Hijazi-Kumar/bbf7b5bdc39f9b8849c639c11f4726e36915a0da},
    volume  = {9},
    year    = {2015}
}
@article{hinton2012improving,
    author     = {Geoffrey E. Hinton and
                  Nitish Srivastava and
                  Alex Krizhevsky and
                  Ilya Sutskever and
                  Ruslan Salakhutdinov},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1207-0580.bib},
    doi        = {10.48550/arXiv.1207.0580},
    eprint     = {1207.0580},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:46:10 +0200},
    title      = {Improving neural networks by preventing co-adaptation of feature detectors},
    volume     = {abs/1207.0580},
    year       = {2012}
}
@article{hoiem2009pascal,
    author    = {Hoiem, Derek and Divvala, Santosh K and Hays, James H},
    journal   = {World Literature Today},
    publisher = {Citeseer},
    title     = {Pascal VOC 2008 challenge},
    url       = {http://host.robots.ox.ac.uk/pascal/VOC/voc2008/index.html},
    volume    = {24},
    year      = {2009}
}
@article{hopper1996analysis,
    author  = {Hopper, K D and Kasales, C J and Van Slyke, M A and Schwartz, T A and TenHave, T R and Jozefiak, J A},
    doi     = {10.2214/ajr.167.4.8819370},
    eprint  = {https://doi.org/10.2214/ajr.167.4.8819370},
    journal = {American Journal of Roentgenology},
    note    = {PMID: 8819370},
    number  = {4},
    pages   = {851-854},
    title   = {Analysis of interobserver and intraobserver variability in CT tumor measurements.},
    volume  = {167},
    year    = {1996}
}
@inproceedings{horn1990hadamard,
    author    = {Horn, Roger A},
    booktitle = {Proc. Symp. Appl. Math},
    pages     = {87--169},
    title     = {The hadamard product},
    url       = {https://scholar.google.com/citations?view_op=view_citation&hl=en&user=tLr2dXsAAAAJ&citation_for_view=tLr2dXsAAAAJ:qjMakFHDy7sC},
    volume    = {40},
    year      = {1990}
}
@misc{https://doi.org/10.48550/arxiv.1412.7062,
    author    = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1412.7062},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs},
    year      = {2014}
}
@misc{https://doi.org/10.48550/arxiv.1511.05644,
    author    = {Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian and Frey, Brendan},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1511.05644},
    keywords  = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Adversarial Autoencoders},
    year      = {2015}
}
@article{https://doi.org/10.48550/arxiv.1603.06560,
    author    = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1603.06560},
    keywords  = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization},
    year      = {2016}
}
@misc{https://doi.org/10.48550/arxiv.1702.08502,
    author    = {Wang, Panqu and Chen, Pengfei and Yuan, Ye and Liu, Ding and Huang, Zehua and Hou, Xiaodi and Cottrell, Garrison},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1702.08502},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Understanding Convolution for Semantic Segmentation},
    year      = {2017}
}
@misc{https://doi.org/10.48550/arxiv.1704.00805,
    author    = {Gao, Bolin and Pavel, Lacra},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1704.00805},
    keywords  = {Optimization and Control (math.OC), Machine Learning (cs.LG), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {On the Properties of the Softmax Function with Application in Game Theory and Reinforcement Learning},
    year      = {2017}
}
@misc{https://doi.org/10.48550/arxiv.1704.06857,
    author    = {Garcia-Garcia, Alberto and Orts-Escolano, Sergio and Oprea, Sergiu and Villena-Martinez, Victor and Garcia-Rodriguez, Jose},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1704.06857},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {A Review on Deep Learning Techniques Applied to Semantic Segmentation},
    year      = {2017}
}
@misc{https://doi.org/10.48550/arxiv.1708.02551,
    author    = {De Brabandere, Bert and Neven, Davy and Van Gool, Luc},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1708.02551},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Semantic Instance Segmentation with a Discriminative Loss Function},
    year      = {2017}
}
@misc{https://doi.org/10.48550/arxiv.1803.08904,
    author    = {Zhang, Hang and Dana, Kristin and Shi, Jianping and Zhang, Zhongyue and Wang, Xiaogang and Tyagi, Ambrish and Agrawal, Amit},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1803.08904},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Context Encoding for Semantic Segmentation},
    year      = {2018}
}
@misc{https://doi.org/10.48550/arxiv.1807.01232,
    author    = {Van Etten, Adam and Lindenbaum, Dave and Bacastow, Todd M.},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1807.01232},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {SpaceNet: A Remote Sensing Dataset and Challenge Series},
    year      = {2018}
} 
@misc{https://doi.org/10.48550/arxiv.1904.12534,
    author    = {Stekovic, Sinisa and Fraundorfer, Friedrich and Lepetit, Vincent},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1904.12534},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Casting Geometric Constraints in Semantic Segmentation as Semi-Supervised Learning},
    year      = {2019}
}
@misc{https://doi.org/10.48550/arxiv.1906.02343,
    author    = {Larrazabal, Agostina J. and Martinez, Cesar and Ferrante, Enzo},
    copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
    doi       = {10.48550/ARXIV.1906.02343},
    keywords  = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Anatomical Priors for Image Segmentation via Post-Processing with Denoising Autoencoders},
    year      = {2019}
}
@misc{https://doi.org/10.48550/arxiv.1910.08711,
    author    = {Zhao, Shuai and Wu, Boxi and Chu, Wenqing and Hu, Yao and Cai, Deng},
    copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
    doi       = {10.48550/ARXIV.1910.08711},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Correlation Maximized Structural Similarity Loss for Semantic Segmentation},
    year      = {2019}
}
@misc{https://doi.org/10.48550/arxiv.1912.03849,
    author    = {Xue, Yuan and Tang, Hui and Qiao, Zhi and Gong, Guanzhong and Yin, Yong and Qian, Zhen and Huang, Chao and Fan, Wei and Huang, Xiaolei},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1912.03849},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Shape-Aware Organ Segmentation by Predicting Signed Distance Maps},
    year      = {2019}
}
@misc{https://doi.org/10.48550/arxiv.2005.13449,
    author    = {Ma, Jun},
    copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
    doi       = {10.48550/ARXIV.2005.13449},
    keywords  = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Segmentation Loss Odyssey},
    year      = {2020}
}
@misc{https://doi.org/10.48550/arxiv.2007.03868,
    author    = {Shi, Gonglei and Xiao, Li and Chen, Yang and Zhou, S. Kevin},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2007.03868},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Marginal loss and exclusion loss for partially supervised multi-organ segmentation},
    year      = {2020}
}
@misc{https://doi.org/10.48550/arxiv.2007.10033,
    author    = {Shirokikh, Boris and Shevtsov, Alexey and Kurmukov, Anvar and Dalechina, Alexandra and Krivov, Egor and Kostjuchenko, Valery and Golanov, Andrey and Belyaev, Mikhail},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2007.10033},
    keywords  = {Image and Video Processing (eess.IV), Machine Learning (cs.LG), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Universal Loss Reweighting to Balance Lesion Size Inequality in 3D Medical Image Segmentation},
    year      = {2020}
}

@misc{https://doi.org/10.48550/arxiv.2007.12668,
    author    = {Kochanov, Deyvid and Nejadasl, Fatemeh Karimi and Booij, Olaf},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2007.12668},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {KPRNet: Improving projection-based LiDAR semantic segmentation},
    year      = {2020}
}
%Todo
@misc{https://doi.org/10.48550/arxiv.2008.05700,
    author    = {Wang, Rui and Mahajan, Dhruv and Ramanathan, Vignesh},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2008.05700},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {What leads to generalization of object proposals?},
    year      = {2020}
}
@misc{https://doi.org/10.48550/arxiv.2008.09585,
    author    = {Byrne, Nick and Clough, James R. and Montana, Giovanni and King, Andrew P.},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2008.09585},
    keywords  = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {A persistent homology-based topological loss function for multi-class CNN segmentation of cardiac MRI},
    year      = {2020}
}
@misc{https://doi.org/10.48550/arxiv.2011.09607,
    author    = {Liu, Xiao-Yang and Yang, Hongyang and Chen, Qian and Zhang, Runjia and Yang, Liuqing and Xiao, Bowen and Wang, Christina Dan},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2011.09607},
    keywords  = {Trading and Market Microstructure (q-fin.TR), Machine Learning (cs.LG), FOS: Economics and business, FOS: Economics and business, FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance},
    year      = {2020}
}
@misc{https://doi.org/10.48550/arxiv.2012.10952,
    author    = {Cai, Yutong and Wang, Yong},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2012.10952},
    keywords  = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {MA-Unet: An improved version of Unet based on multi-scale and attention mechanism for medical image segmentation},
    year      = {2020}
}
@article{https://doi.org/10.48550/arxiv.2103.14749,
    author    = {Northcutt, Curtis G. and Athalye, Anish and Mueller, Jonas},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2103.14749},
    keywords  = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks},
    year      = {2021}
}
@misc{https://doi.org/10.48550/arxiv.2111.15430,
    author    = {Liu, Bingyuan and Ayed, Ismail Ben and Galdran, Adrian and Dolz, Jose},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2111.15430},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {The Devil is in the Margin: Margin-based Label Smoothing for Network Calibration},
    year      = {2021}
}
﻿@misc{https://doi.org/10.48550/arxiv.2201.06696,
    author    = {Shi, Hengcan and Hayat, Munawar and Wu, Yicheng and Cai, Jianfei},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2201.06696},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {ProposalCLIP: Unsupervised Open-Category Object Proposal Generation via Exploiting CLIP Cues},
    year      = {2022}
}
@misc{https://doi.org/10.48550/arxiv.2205.08209,
    author    = {Kofler, Florian and Shit, Suprosanna and Ezhov, Ivan and Fidon, Lucas and Horvath, Izabela and Al-Maskari, Rami and Li, Hongwei and Bhatia, Harsharan and Loehr, Timo and Piraud, Marie and Erturk, Ali and Kirschke, Jan and Peeken, Jan and Vercauteren, Tom and Zimmer, Claus and Wiestler, Benedikt and Menze, Bjoern},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2205.08209},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Image and Video Processing (eess.IV), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
    publisher = {arXiv},
    title     = {blob loss: instance imbalance aware loss functions for semantic segmentation},
    year      = {2022}
}
@article{hu2021topologyaware,
    author     = {Xiaoling Hu and
                  Yusu Wang and
                  Fuxin Li and
                  Dimitris Samaras and
                  Chao Chen},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2103-09992.bib},
    doi        = {10.48550/arXiv.2103.09992},
    eprint     = {2103.09992},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 02 Jan 2023 09:02:11 +0100},
    title      = {Topology-Aware Segmentation Using Discrete Morse Theory},
    volume     = {abs/2103.09992},
    year       = {2021}
}
@inproceedings{huang2019attention,
    author    = {Huang, Lun and Wang, Wenmin and Chen, Jie and Wei, Xiao-Yong},
    booktitle = {Proceedings of the IEEE/CVF international conference on computer vision},
    doi       = {10.48550/arXiv.1908.06954},
    pages     = {4634--4643},
    title     = {Attention on attention for image captioning},
    year      = {2019}
}
@article{HUANG2021103677,
    abstract = {The architecture, engineering and construction (AEC) industry is experiencing a technological revolution driven by booming digitisation and automation. Advances in research fields of information technology and computer science, such as building information modelling (BIM), machine learning and computer vision have attracted growing attention owing to their useful applications. At the same time, population-driven underground development has been accelerated with digital transformation as a strategic imperative. Urban underground infrastructures are valuable assets and thus demanding effective planning, construction and maintenance. While enabling greater visibility and reliability into the processes and subsystems of underground construction, applications of BIM, machine learning and computer vision in underground construction represent different sets of opportunities and challenges from their use in above-ground construction. Therefore, this paper aims to present the state-of-the-art development and future trends of BIM, machine learning, computer vision and their related technologies in facilitating the digital transition of tunnelling and underground construction. Section 1 presents the global demand for adopting these technologies. Section 2 introduces the related terminologies, standardisations and fundamentals. Section 3 reviews BIM in traditional and mechanised tunnelling and highlights the importance of integrating 3D geological modelling and geographic information system (GIS) databases with BIM. Section 4 examines the key applications of machine learning and computer vision at different stages of underground construction. Section 5 discusses the challenges and perspectives of existing research on leveraging these emerging technologies for escalating digitisation, automation and information integration throughout underground project lifecycle. Section 6 summarises the current state of development, identified gaps and future directions.},
    author   = {M.Q. Huang and J. Ninić and Q.B. Zhang},
    doi      = {https://doi.org/10.1016/j.tust.2020.103677},
    issn     = {0886-7798},
    journal  = {Tunnelling and Underground Space Technology},
    keywords = {Building information modelling, Computer vision, Machine learning, Tunnelling, Underground construction},
    pages    = {103677},
    title    = {BIM, machine learning and computer vision techniques in underground construction: Current status and future perspectives},
    volume   = {108},
    year     = {2021}
}
@inproceedings{inproceedings,
    author  = {Bentaieb, Aicha and Hamarneh, Ghassan},
    doi     = {10.1007/978-3-319-46723-8_53},
    isbn    = {978-3-319-46722-1},
    journal = {LNCS},
    month   = {10},
    pages   = {?-?},
    title   = {Topology Aware Fully Convolutional Networks For Histology Gland Segmentation},
    volume  = {9901},
    year    = {2016}
}
@inproceedings{ioffe2015batch,
    abstract  = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82{\%} top-5 test error, exceeding the accuracy of human raters.},
    address   = {Lille, France},
    author    = {Ioffe, Sergey and Szegedy, Christian},
    booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
    editor    = {Bach, Francis and Blei, David},
    month     = {07},
    pages     = {448--456},
    pdf       = {http://proceedings.mlr.press/v37/ioffe15.pdf},
    publisher = {PMLR},
    series    = {Proceedings of Machine Learning Research},
    title     = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
    url       = {https://proceedings.mlr.press/v37/ioffe15.html},
    volume    = {37},
    year      = {2015}
}
@inproceedings{Jadon_2020,
    author    = {Shruti Jadon},
    booktitle = {2020 {IEEE} Conference on Computational Intelligence in Bioinformatics and Computational Biology ({CIBCB})},
    doi       = {10.1109/cibcb48159.2020.9277638},
    month     = {10},
    publisher = {{IEEE}
                 },
    title     = {A survey of loss functions for semantic segmentation},
    year      = 2020
}
@inproceedings{Jia2020ReviewOR,
    author    = {Jia, Jingkai and Wang, Wenlin},
    booktitle = {2020 35th Youth Academic Annual Conference of Chinese Association of Automation (YAC)},
    doi       = {10.1109/YAC51587.2020.9337653},
    number    = {},
    pages     = {186-191},
    title     = {Review of reinforcement learning research},
    volume    = {},
    year      = {2020}
}
@misc{jiang2017deep,
    author    = {Jiang, Zhengyao and Xu, Dixing and Liang, Jinjun},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1706.10059},
    keywords  = {Computational Finance (q-fin.CP), Artificial Intelligence (cs.AI), Portfolio Management (q-fin.PM), FOS: Economics and business, FOS: Economics and business, FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem},
    year      = {2017}
}
@book{johnson1994beta,
    address   = {Hoboken, NJ, USA},
    author    = {Johnson, Norman L. and Kotz, Samuel and Balakrishnan, Narayanaswamy},
    isbn      = {978-0-471-58494-0},
    month     = apr,
    publisher = {Wiley},
    title     = {{Continuous Univariate Distributions, Volume 2, 2nd Edition}},
    url       = {https://www.wiley.com/en-cn/Continuous+Univariate+Distributions,+Volume+2,+2nd+Edition-p-9780471584940},
    year      = {1995}
}
@inproceedings{joshi2020robotic,
    author    = {Joshi, Shirin and Kumra, Sulabh and Sahin, Ferat},
    booktitle = {2020 IEEE 16th International Conference on Automation Science and Engineering (CASE)},
    doi       = {10.1109/CASE48305.2020.9216986},
    number    = {},
    pages     = {1461-1466},
    title     = {Robotic Grasping using Deep Reinforcement Learning},
    volume    = {},
    year      = {2020}
}
@article{jpm12020309,
    abstract       = {Currently, most mask extraction techniques are based on convolutional neural networks (CNNs). However, there are still numerous problems that mask extraction techniques need to solve. Thus, the most advanced methods to deploy artificial intelligence (AI) techniques are necessary. The use of cooperative agents in mask extraction increases the efficiency of automatic image segmentation. Hence, we introduce a new mask extraction method that is based on multi-agent deep reinforcement learning (DRL) to minimize the long-term manual mask extraction and to enhance medical image segmentation frameworks. A DRL-based method is introduced to deal with mask extraction issues. This new method utilizes a modified version of the Deep Q-Network to enable the mask detector to select masks from the image studied. Based on COVID-19 computed tomography (CT) images, we used DRL mask extraction-based techniques to extract visual features of COVID-19 infected areas and provide an accurate clinical diagnosis while optimizing the pathogenic diagnostic test and saving time. We collected CT images of different cases (normal chest CT, pneumonia, typical viral cases, and cases of COVID-19). Experimental validation achieved a precision of 97.12{\%} with a Dice of 80.81{\%}, a sensitivity of 79.97{\%}, a specificity of 99.48{\%}, a precision of 85.21{\%}, an F1 score of 83.01{\%}, a structural metric of 84.38{\%}, and a mean absolute error of 0.86{\%}. Additionally, the results of the visual segmentation clearly reflected the ground truth. The results reveal the proof of principle for using DRL to extract CT masks for an effective diagnosis of COVID-19.},
    article-number = {309},
    author         = {Allioui, Hanane and Mohammed, Mazin Abed and Benameur, Narjes and Al-Khateeb, Belal and Abdulkareem, Karrar Hameed and Garcia-Zapirain, Begonya and Damaševičius, Robertas and Maskeliūnas, Rytis},
    doi            = {10.3390/jpm12020309},
    issn           = {2075-4426},
    journal        = {Journal of Personalized Medicine},
    number         = {2},
    pubmedid       = {35207796},
    title          = {A Multi-Agent Deep Reinforcement Learning Approach for Enhancement of COVID-19 CT Image Segmentation},
    volume         = {12},
    year           = {2022}
}
@article{jung2001content,
    author  = {Young-Kee Jung and Kyu-Won Lee and Yo-Sung Ho},
    doi     = {10.1109/6979.954548},
    journal = {IEEE Transactions on Intelligent Transportation Systems},
    number  = {3},
    pages   = {151-163},
    title   = {Content-based event retrieval using semantic scene interpretation for automated traffic surveillance},
    volume  = {2},
    year    = {2001}
}
@inproceedings{jurdi2021a,
    abstract  = {Deep convolutional networks recently made many breakthroughs in medical image segmentation. Still, some anatomical artefacts may be observed in the segmentation results, with holes or inaccuracies near the object boundaries. To address these issues, loss functions that incorporate constraints, such as spatial information or prior knowledge, have been introduced. An example of such prior losses are the contour-based losses, which exploit distance maps to conduct point-by-point optimization between ground-truth and predicted contours. However, such losses may be computationally expensive or susceptible to trivial local solutions and vanishing gradient problems. Moreover, they depend on distance maps which tend to underestimate the contour-to-contour distances. We propose a novel loss constraint that optimizes the perimeter length of the segmented object relative to the ground-truth segmentation. The novelty lies in computing the perimeter with a soft approximation of the contour of the probability map via specialized non-trainable layers in the network. Moreover, we optimize the mean squared error between the predicted perimeter length and ground-truth perimeter length. This soft optimization of contour boundaries allows the network to take into consideration border irregularities within organs while still being efficient. Our experiments on three public datasets (spleen, hippocampus and cardiac structures) show that the proposed method outperforms state-of-the-art boundary losses for both single and multi-organ segmentation.},
    author    = {{EL Jurdi}, Rosana and Petitjean, Caroline and Honeine, Paul and Cheplygina, Veronika and Abdallah, Fahed},
    booktitle = {Proceedings of the Fourth Conference on Medical Imaging with Deep Learning},
    editor    = {Heinrich, Mattias and Dou, Qi and de Bruijne, Marleen and Lellmann, Jan and Schläfer, Alexander and Ernst, Floris},
    month     = {07--09 Jul},
    pages     = {158--167},
    pdf       = {https://proceedings.mlr.press/v143/el-jurdi21a/el-jurdi21a.pdf},
    publisher = {PMLR},
    series    = {Proceedings of Machine Learning Research},
    title     = {A Surprisingly Effective Perimeter-based Loss for Medical Image Segmentation},
    url       = {https://proceedings.mlr.press/v143/el-jurdi21a.html},
    volume    = {143},
    year      = {2021}
}
@article{Kaelbling1996May,
    author  = {Kaelbling, L. P. and Littman, M. L. and Moore, A. W.},
    doi     = {10.1613/jair.301},
    issn    = {1076-9757},
    journal = {J. Artif. Intell. Res.},
    month   = may,
    pages   = {237--285},
    title   = {{Reinforcement Learning: A Survey}},
    volume  = {4},
    year    = {1996}
}
﻿@article{kanizsa1976subjective,
    author    = {Kanizsa, Gaetano},
    journal   = {Scientific American},
    number    = {4},
    pages     = {48--53},
    publisher = {JSTOR},
    title     = {Subjective contours},
    url       = {https://www.jstor.org/stable/24950327},
    volume    = {234},
    year      = {1976}
}
@article{kao2018context,
    abstractnote = { &lt;p&gt; Online symptom checkers have been deployed by sites such as WebMD and Mayo Clinic to identify possible causes and treatments for diseases based on a patient’s symptoms. Symptom checking first assesses a patient by asking a series of questions about their symptoms, then attempts to predict potential diseases. The two design goals of a symptom checker are to achieve high accuracy and intuitive interactions. In this paper we present our context-aware hierarchical reinforcement learning scheme, which significantly improves accuracy of symptom checking over traditional systems while also making a limited number of inquiries. &lt;/p&gt; },
    author       = {Kao, Hao-Cheng and Tang, Kai-Fu and Chang, Edward},
    doi          = {10.1609/aaai.v32i1.11902},
    journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
    month        = {04},
    number       = {1},
    title        = {Context-Aware Symptom Checking for Disease Diagnosis Using Hierarchical Reinforcement Learning},
    volume       = {32},
    year         = {2018}
}
@inproceedings{ke2017lightgbm,
    author    = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
    booktitle = {Advances in Neural Information Processing Systems},
    editor    = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {LightGBM: A Highly Efficient Gradient Boosting Decision Tree},
    url       = {https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
    volume    = {30},
    year      = {2017}
}
@article{kee2018query,
    abstract = {Active learning has gained attention as a method to expedite the learning curve of classifiers. To this end, uncertainty sampling is a widely adopted strategy that selects instances closer to the decision boundary. However, uncertainty sampling alone may not be sufficient in batch active learning due to the redundancy of instances and its susceptibility to outliers. In this study, we utilize query-by-committee (QBC) for uncertainty and demonstrate that its performance can be improved by introducing diversity and density in instance utility. Test results show that uncertainty sampling by QBC can be significantly improved with diversity and density incorporated in instance selection. Furthermore, we investigate several distance measures for use in diversity and density and show that random forest dissimilarity can be an effective distance measure in batch active learning. The effects of the characteristics of the data on the results are also analyzed.},
    author   = {Seho Kee and Enrique {del Castillo} and George Runger},
    doi      = {10.1016/j.ins.2018.05.014},
    issn     = {0020-0255},
    journal  = {Information Sciences},
    keywords = {Batch active learning, Density, Diversity, Query-by-committee, Random forest},
    pages    = {401-418},
    title    = {Query-by-committee improvement with diversity and density in batch active learning},
    volume   = {454-455},
    year     = {2018}
}
@article{keim2013big,
    author  = {Keim, Daniel and Qu, Huamin and Ma, Kwan-Liu},
    doi     = {10.1109/MCG.2013.54},
    journal = {IEEE Computer Graphics and Applications},
    number  = {4},
    pages   = {20-21},
    title   = {Big-Data Visualization},
    volume  = {33},
    year    = {2013}
}
@article{Kervadec_2021,
    author    = {Hoel Kervadec and Jihene Bouchtiba and Christian Desrosiers and Eric Granger and Jose Dolz and Ismail Ben Ayed},
    doi       = {10.1016/j.media.2020.101851},
    journal   = {Medical Image Analysis},
    month     = {01},
    pages     = {101851},
    publisher = {Elsevier {BV}
                 },
    title     = {Boundary loss for highly unbalanced segmentation},
    volume    = {67},
    year      = 2021
}
@inproceedings{kervadec2021beyond,
    author    = {Hoel Kervadec and Houda Bahig and Laurent Letourneau-Guillon and Jose Dolz and Ismail Ben Ayed},
    booktitle = {Medical Imaging with Deep Learning},
    title     = {Beyond pixel-wise supervision: semantic segmentation with higher-order shape descriptors},
    url       = {https://openreview.net/forum?id=nqe6e0oJ_fL},
    year      = {2021}
}
@inproceedings{khan2015multi,
    author    = {Khan, Khalil and Mauro, Massimo and Leonardi, Riccardo},
    booktitle = {2015 IEEE International Conference on Image Processing (ICIP)},
    doi       = {10.1109/ICIP.2015.7350915},
    number    = {},
    pages     = {827-831},
    title     = {Multi-class semantic segmentation of faces},
    volume    = {},
    year      = {2015}
}
@article{khan2021deep,
    author  = {Khan, Muhammad Zubair and Gajendran, Mohan Kumar and Lee, Yugyung and Khan, Muazzam A.},
    doi     = {10.1109/ACCESS.2021.3086530},
    journal = {IEEE Access},
    number  = {},
    pages   = {83002-83024},
    title   = {Deep Neural Architectures for Medical Image Semantic Segmentation: Review},
    volume  = {9},
    year    = {2021}
}
@article{kingsford2008decision,
    abstract = {Decision trees have been applied to problems such as assigning protein function and predicting splice sites. How do these classifiers work, what types of problems can they solve and what are their advantages over alternatives?},
    author   = {Kingsford, Carl
                and Salzberg, Steven L.},
    day      = {01},
    doi      = {10.1038/nbt0908-1011},
    issn     = {1546-1696},
    journal  = {Nature Biotechnology},
    month    = {09},
    number   = {9},
    pages    = {1011-1013},
    title    = {What are decision trees?},
    volume   = {26},
    year     = {2008}
}
@inproceedings{Klingner_2020_CVPR_Workshops,
    author    = {Klingner, Marvin and Bar, Andreas and Fingscheidt, Tim},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    doi       = {10.48550/arXiv.2004.11072},
    month     = {06},
    title     = {Improved Noise and Attack Robustness for Semantic Segmentation by Using Multi-Task Training With Self-Supervised Depth Estimation},
    year      = {2020}
}


@article{ko2020novel,
    abstract       = {This paper proposes a novel method of semantic segmentation, consisting of modified dilated residual network, atrous pyramid pooling module, and backpropagation, that is applicable to augmented reality (AR). In the proposed method, the modified dilated residual network extracts a feature map from the original images and maintains spatial information. The atrous pyramid pooling module places convolutions in parallel and layers feature maps in a pyramid shape to extract objects occupying small areas in the image; these are converted into one channel using a 1 &times; 1 convolution. Backpropagation compares the semantic segmentation obtained through convolution from the final feature map with the ground truth provided by a database. Losses can be reduced by applying backpropagation to the modified dilated residual network to change the weighting. The proposed method was compared with other methods on the Cityscapes and PASCAL VOC 2012 databases. The proposed method achieved accuracies of 82.8 and 89.8 mean intersection over union (mIOU) and frame rates of 61 and 64.3 frames per second (fps) for the Cityscapes and PASCAL VOC 2012 databases, respectively. These results prove the applicability of the proposed method for implementing natural AR applications at actual speeds because the frame rate is greater than 60 fps.},
    article-number = {1737},
    author         = {Ko, Tae-young and Lee, Seung-ho},
    doi            = {10.3390/s20061737},
    issn           = {1424-8220},
    journal        = {Sensors},
    number         = {6},
    pubmedid       = {32245002},
    title          = {Novel Method of Semantic Segmentation Applicable to Augmented Reality},
    volume         = {20},
    year           = {2020}
}
@inproceedings{kouiroukidis2011effects,
    author    = {Kouiroukidis, Nikolaos and Evangelidis, Georgios},
    booktitle = {2011 15th Panhellenic Conference on Informatics},
    doi       = {10.1109/PCI.2011.45},
    number    = {},
    pages     = {41-45},
    title     = {The Effects of Dimensionality Curse in High Dimensional kNN Search},
    volume    = {},
    year      = {2011}
}
@article{krizhevsky2017imagenet,
    abstract   = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%}, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
    address    = {New York, NY, USA},
    author     = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
    doi        = {10.1145/3065386},
    issn       = {0001-0782},
    issue_date = {June 2017},
    journal    = {Commun. ACM},
    month      = {may},
    number     = {6},
    numpages   = {7},
    pages      = {84–90},
    publisher  = {Association for Computing Machinery},
    title      = {ImageNet Classification with Deep Convolutional Neural Networks},
    volume     = {60},
    year       = {2017}
}
@article{Lample_Chaplot_2017,
    abstractnote = { &lt;p&gt; Advances in deep reinforcement learning have allowed autonomous agents to perform well on Atari games, often outperforming humans, using only raw pixels to make their decisions. However, most of these games take place in 2D environments that are fully observable to the agent. In this paper, we present the first architecture to tackle 3D environments in first-person shooter games, that involve partially observable states. Typically, deep reinforcement learning methods only utilize visual input for training. We present a method to augment these models to exploit game feature information such as the presence of enemies or items, during the training phase. Our model is trained to simultaneously learn these features along with minimizing a Q-learning objective, which is shown to dramatically improve the training speed and performance of our agent. Our architecture is also modularized to allow different models to be independently trained for different phases of the game. We show that the proposed architecture substantially outperforms built-in AI agents of the game as well as average humans in deathmatch scenarios. &lt;/p&gt; },
    author       = {Lample, Guillaume and Chaplot, Devendra Singh},
    doi          = {10.1609/aaai.v31i1.10827},
    journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
    month        = {02},
    number       = {1},
    title        = {Playing FPS Games with Deep Reinforcement Learning},
    volume       = {31},
    year         = {2017}
}
@incollection{Lan_2020,
    author    = {Yuan Lan and Yang Xiang and Luchan Zhang},
    booktitle = {Medical Image Computing and Computer Assisted Intervention {\textendash} {MICCAI} 2020},
    doi       = {10.1007/978-3-030-59722-1_73},
    pages     = {755--764},
    publisher = {Springer International Publishing},
    title     = {An Elastic Interaction-Based Loss Function for Medical Image Segmentation},
    year      = 2020
}
@article{LeCun2015,
    abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
    author   = {LeCun, Yann
                and Bengio, Yoshua
                and Hinton, Geoffrey},
    day      = {01},
    doi      = {10.1038/nature14539},
    issn     = {1476-4687},
    journal  = {Nature},
    month    = {05},
    number   = {7553},
    pages    = {436-444},
    title    = {Deep learning},
    volume   = {521},
    year     = {2015}
}
@inproceedings{leng2022polyloss,
    author    = {Zhaoqi Leng and Mingxing Tan and Chenxi Liu and Ekin Dogus Cubuk and Jay Shi and Shuyang Cheng and Dragomir Anguelov},
    booktitle = {International Conference on Learning Representations},
    title     = {PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions},
    url       = {https://openreview.net/forum?id=gSdSJoenupI},
    year      = {2022}
}
@inproceedings{letarte2018importance,
    abstract  = {Despite their superior performance, deep learning models often lack interpretability. In this paper, we explore the modeling of insightful relations between words, in order to understand and enhance predictions. To this effect, we propose the Self-Attention Network (SANet), a flexible and interpretable architecture for text classification. Experiments indicate that gains obtained by self-attention is task-dependent. For instance, experiments on sentiment analysis tasks showed an improvement of around 2{\%} when using self-attention compared to a baseline without attention, while topic classification showed no gain. Interpretability brought forward by our architecture highlighted the importance of neighboring word interactions to extract sentiment.},
    address   = {Brussels, Belgium},
    author    = {Letarte, Ga{\"e}l  and
                 Paradis, Fr{\'e}d{\'e}rik  and
                 Gigu{\`e}re, Philippe  and
                 Laviolette, Fran{\c{c}}ois},
    booktitle = {Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}},
    doi       = {10.18653/v1/W18-5429},
    month     = nov,
    pages     = {267--275},
    publisher = {Association for Computational Linguistics},
    title     = {Importance of Self-Attention for Sentiment Analysis},
    year      = {2018}
}

@article{lewis2007regression,
    author    = {Lewis, Steff},
    doi       = {10.1136/jnnp.2007.120055},
    journal   = {Practical neurology},
    number    = {4},
    pages     = {259--264},
    publisher = {BMJ Publishing Group Ltd},
    title     = {Regression analysis},
    volume    = {7},
    year      = {2007}
}
@article{li2020tilted,
    author     = {Tian Li and
                  Ahmad Beirami and
                  Maziar Sanjabi and
                  Virginia Smith},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2007-01162.bib},
    doi        = {10.48550/arXiv.2007.01162},
    eprint     = {2007.01162},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Wed, 23 Dec 2020 09:35:18 +0100},
    title      = {Tilted Empirical Risk Minimization},
    volume     = {abs/2007.01162},
    year       = {2020}
}
@inproceedings{liang2016semantic,
    abstract  = {By taking the semantic object parsing task as an exemplar application scenario, we propose the Graph Long Short-Term Memory (Graph LSTM) network, which is the generalization of LSTM from sequential data or multi-dimensional data to general graph-structured data. Particularly, instead of evenly and fixedly dividing an image to pixels or patches in existing multi-dimensional LSTM structures (e.g., Row, Grid and Diagonal LSTMs), we take each arbitrary-shaped superpixel as a semantically consistent node, and adaptively construct an undirected graph for each image, where the spatial relations of the superpixels are naturally used as edges. Constructed on such an adaptive graph topology, the Graph LSTM is more naturally aligned with the visual patterns in the image (e.g., object boundaries or appearance similarities) and provides a more economical information propagation route. Furthermore, for each optimization step over Graph LSTM, we propose to use a confidence-driven scheme to update the hidden and memory states of nodes progressively till all nodes are updated. In addition, for each node, the forgets gates are adaptively learned to capture different degrees of semantic correlation with neighboring nodes. Comprehensive evaluations on four diverse semantic object parsing datasets well demonstrate the significant superiority of our Graph LSTM over other state-of-the-art solutions.},
    address   = {Cham},
    author    = {Liang, Xiaodan
                 and Shen, Xiaohui
                 and Feng, Jiashi
                 and Lin, Liang
                 and Yan, Shuicheng},
    booktitle = {Computer Vision -- ECCV 2016},
    doi       = {10.48550/arXiv.1603.07063},
    editor    = {Leibe, Bastian
                 and Matas, Jiri
                 and Sebe, Nicu
                 and Welling, Max},
    isbn      = {978-3-319-46448-0},
    pages     = {125--143},
    publisher = {Springer International Publishing},
    title     = {Semantic Object Parsing with Graph LSTM},
    year      = {2016}
}
@misc{lightning-kitti,
    author       = {Dayma, Boris},
    howpublished = {\url{https://github.com/borisdayma/lightning-kitti}},
    note         = {GitHub repository},
    title        = {lightning-kitti},
    year         = {2021}
}
@inproceedings{Lin_2018_ECCV,
    author    = {Lin, Di and Ji, Yuanfeng and Lischinski, Dani and Cohen-Or, Daniel and Huang, Hui},
    booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
    month     = {09},
    title     = {Multi-Scale Context Intertwining for Semantic Segmentation},
    url       = {https://openaccess.thecvf.com/content_ECCV_2018/html/Di_Lin_Multi-Scale_Context_Intertwining_ECCV_2018_paper.html},
    year      = {2018}
}
@inproceedings{lin2017focal,
    author    = {Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
    booktitle = {Proceedings of the IEEE international conference on computer vision},
    doi       = {10.48550/arXiv.1708.02002},
    pages     = {2980--2988},
    title     = {Focal loss for dense object detection},
    year      = {2017}
}
@inproceedings{Liu_2019_CVPR,
    author    = {Liu, Shikun and Johns, Edward and Davison, Andrew J.},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    doi       = {10.48550/arXiv.1803.10704},
    month     = {06},
    title     = {End-To-End Multi-Task Learning With Attention},
    year      = {2019}
}
@inproceedings{liu2015semantic,
    author    = {Liu, Ziwei and Li, Xiaoxiao and Luo, Ping and Loy, Chen-Change and Tang, Xiaoou},
    booktitle = {Proceedings of the IEEE international conference on computer vision},
    doi       = {10.48550/arXiv.1509.02634},
    pages     = {1377--1385},
    title     = {Semantic image segmentation via deep parsing network},
    year      = {2015}
}
@article{liu2019bidirectional,
    abstract = {Neural network models have been widely used in the field of natural language processing (NLP). Recurrent neural networks (RNNs), which have the ability to process sequences of arbitrary length, are common methods for sequence modeling tasks. Long short-term memory (LSTM) is one kind of RNNs and has achieved remarkable performance in text classification. However, due to the high dimensionality and sparsity of text data, and to the complex semantics of the natural language, text classification presents difficult challenges. In order to solve the above problems, a novel and unified architecture which contains a bidirectional LSTM (BiLSTM), attention mechanism and the convolutional layer is proposed in this paper. The proposed architecture is called attention-based bidirectional long short-term memory with convolution layer (AC-BiLSTM). In AC-BiLSTM, the convolutional layer extracts the higher-level phrase representations from the word embedding vectors and BiLSTM is used to access both the preceding and succeeding context representations. Attention mechanism is employed to give different focus to the information outputted from the hidden layers of BiLSTM. Finally, the softmax classifier is used to classify the processed context information. AC-BiLSTM is able to capture both the local feature of phrases as well as global sentence semantics. Experimental verifications are conducted on six sentiment classification datasets and a question classification dataset, including detailed analysis for AC-BiLSTM. The results clearly show that AC-BiLSTM outperforms other state-of-the-art text classification methods in terms of the classification accuracy.},
    author   = {Gang Liu and Jiabao Guo},
    doi      = {10.1016/j.neucom.2019.01.078},
    issn     = {0925-2312},
    journal  = {Neurocomputing},
    keywords = {Long short-term memory, Attention mechanism, Natural language processing, Text classification},
    pages    = {325-338},
    title    = {Bidirectional LSTM with attention mechanism and convolutional layer for text classification},
    volume   = {337},
    year     = {2019}
}
@inproceedings{liu2020robot,
    author    = {Liu, Lucia and Dugas, Daniel and Cesari, Gianluca and Siegwart, Roland and Dubé, Renaud},
    booktitle = {2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
    doi       = {10.1109/IROS45743.2020.9341540},
    number    = {},
    pages     = {5671-5677},
    title     = {Robot Navigation in Crowded Environments Using Deep Reinforcement Learning},
    volume    = {},
    year      = {2020}
}
@inproceedings{long2015fully,
    author    = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
    booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
    doi       = {10.48550/arXiv.1411.4038},
    pages     = {3431--3440},
    title     = {Fully convolutional networks for semantic segmentation},
    year      = {2015}
}
@article{lu2012recommender,
    abstract = {The ongoing rapid expansion of the Internet greatly increases the necessity of effective recommender systems for filtering the abundant information. Extensive research for recommender systems is conducted by a broad range of communities including social and computer scientists, physicists, and interdisciplinary researchers. Despite substantial theoretical and practical achievements, unification and comparison of different approaches are lacking, which impedes further advances. In this article, we review recent developments in recommender systems and discuss the major challenges. We compare and evaluate available algorithms and examine their roles in the future developments. In addition to algorithms, physical aspects are described to illustrate macroscopic behavior of recommender systems. Potential impacts and future directions are discussed. We emphasize that recommendation has great scientific depth and combines diverse research fields which makes it interesting for physicists as well as interdisciplinary researchers.},
    author   = {Linyuan Lü and Matúš Medo and Chi Ho Yeung and Yi-Cheng Zhang and Zi-Ke Zhang and Tao Zhou},
    doi      = {10.1016/j.physrep.2012.02.006},
    issn     = {0370-1573},
    journal  = {Physics Reports},
    keywords = {Recommender systems, Information filtering, Networks},
    note     = {Recommender Systems},
    number   = {1},
    pages    = {1-49},
    title    = {Recommender systems},
    volume   = {519},
    year     = {2012}
}
@article{madani2020artificial,
    author  = {Madani, Amin and Namazi, Babak and Altieri, Maria and Hashimoto, Daniel and Rivera, Angela and Pucher, Philip and Navarrete-Welton, Allison and Sankaranarayanan, Ganesh and Brunt, L Michael and Okrainec, Allan and Alseidi, Adnan},
    doi     = {10.1097/SLA.0000000000004594},
    journal = {Annals of Surgery},
    month   = {11},
    pages   = {},
    title   = {Artificial Intelligence for Intraoperative Guidance: Using Semantic Segmentation to Identify Surgical Anatomy During Laparoscopic Cholecystectomy},
    volume  = {Publish Ahead of Print},
    year    = {2020}
}
@article{make3020026,
    abstract = {Medical image annotation is a major hurdle for developing precise and robust machine-learning models. Annotation is expensive, time-consuming, and often requires expert knowledge, particularly in the medical field. Here, we suggest using minimal user interaction in the form of extreme point clicks to train a segmentation model which, in effect, can be used to speed up medical image annotation. An initial segmentation is generated based on the extreme points using the random walker algorithm. This initial segmentation is then used as a noisy supervision signal to train a fully convolutional network that can segment the organ of interest, based on the provided user clicks. Through experimentation on several medical imaging datasets, we show that the predictions of the network can be refined using several rounds of training with the prediction from the same weakly annotated data. Further improvements are shown using the clicked points within a custom-designed loss and attention mechanism. Our approach has the potential to speed up the process of generating new training datasets for the development of new machine-learning and deep-learning-based models for, but not exclusively, medical image analysis.},
    author   = {Roth, Holger R. and Yang, Dong and Xu, Ziyue and Wang, Xiaosong and Xu, Daguang},
    doi      = {10.3390/make3020026},
    issn     = {2504-4990},
    journal  = {Machine Learning and Knowledge Extraction},
    number   = {2},
    pages    = {507--524},
    title    = {Going to Extremes: Weakly Supervised Medical Image Segmentation},
    volume   = {3},
    year     = {2021}
}
@article{malthouse2005can,
    abstract = {Abstract Relationship marketing assumes that firms can be more profitable if they identify the most profitable customers and invest disproportionate marketing resources in them. While intuitive, such strategies presume that a firm can accurately predict the future profitability of customers. In particular, we argue that the feasibility of such strategies depends on the probabilities and costs of misclassifying customers. This paper presents a detailed empirical evaluation of how accurately the future profitability of customers can be estimated. We evaluate a firm's ability to estimate the future value of customers using four data sets from different industries. Out-of-sample estimates of predictive accuracy are provided. We examine (1) the accuracy of predictions, (2) how accuracy depends on the length of time over which estimates are made, and (3) the predictors of the firm's best customers. We propose the 20–55 and 80–15 rules. Of the top 20{\%}, approximately 55{\%} will be misclassified (and not receive special treatment). Of the future bottom 80{\%}, approximately 15{\%} will be misclassified (and receive special treatment). Thus, a firm cannot assume that high-profit customers in the past will be profitable in the future nor can they assume that historically low-profit will be low-profit customers in the future.},
    author   = {Malthouse, Edward C. and Blattberg, Robert C.},
    doi      = {https://doi.org/10.1002/dir.20027},
    eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/dir.20027},
    journal  = {Journal of Interactive Marketing},
    number   = {1},
    pages    = {2-16},
    title    = {Can we predict customer lifetime value?},
    volume   = {19},
    year     = {2005}
}

@inbook{mataric1997reinforcement,
    abstract  = {This paper describes a formulation of reinforcement learning that enables learning in noisy, dynamic environments such as in the complex concurrent multi-robot learning domain. The methodology involves minimizing the learning space through the use of behaviors and conditions, and dealing with the credit assignment problem through shaped reinforcement in the form of heterogeneous reinforcement functions and progress estimators. We experimentally validate the approach on a group of four mobile robots learning a foraging task.},
    address   = {Boston, MA},
    author    = {Matari{\'{c}}, Maja J.},
    booktitle = {Robot Colonies},
    doi       = {10.1007/978-1-4757-6451-2_4},
    editor    = {Arkin, Ronald C.
                 and Bekey, George A.},
    isbn      = {978-1-4757-6451-2},
    pages     = {73--83},
    publisher = {Springer US},
    title     = {Reinforcement Learning in the Multi-Robot Domain},
    year      = {1997}
}
@article{matplotlib2007,
    address   = {Los Alamitos, CA, USA},
    author    = {Hunter, J. D.},
    doi       = {10.1109/MCSE.2007.55},
    issn      = {1558-366X},
    journal   = {Computing in Science \& Engineering},
    keywords  = {python;scripting languages;application development;scientific programming},
    month     = {05},
    number    = {3},
    pages     = {90--95},
    publisher = {IEEE Computer Society},
    title     = {Matplotlib: A 2D Graphics Environment},
    volume    = {9},
    year      = {2007}
}
@article{Matterport3D,
    author     = {Angel X. Chang and
                  Angela Dai and
                  Thomas A. Funkhouser and
                  Maciej Halber and
                  Matthias Nie{\ss}ner and
                  Manolis Savva and
                  Shuran Song and
                  Andy Zeng and
                  Yinda Zhang},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1709-06158.bib},
    doi        = {10.48550/arXiv.1709.06158},
    eprint     = {1709.06158},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Thu, 19 Aug 2021 19:45:39 +0200},
    title      = {Matterport3D: Learning from {RGB-D} Data in Indoor Environments},
    volume     = {abs/1709.06158},
    year       = {2017}
}
@article{maulud2020review,
    author  = {Maulud, Dastan and Abdulazeez, Adnan M},
    doi     = {10.38094/jastt1457},
    journal = {Journal of Applied Science and Technology Trends},
    number  = {4},
    pages   = {140--147},
    title   = {A review on linear regression comprehensive in machine learning},
    volume  = {1},
    year    = {2020}
}
@inproceedings{mayer2020adversarial,
    author    = {Mayer, Christoph and Timofte, Radu},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
    doi       = {10.48550/arXiv.1808.06671},
    pages     = {3071--3079},
    title     = {Adversarial sampling for active learning},
    year      = {2020}
}
@incollection{mccloskey1989catastrophic,
    abstract  = {Publisher Summary
                 Connectionist networks in which information is stored in weights on connections among simple processing units have attracted considerable interest in cognitive science. Much of the interest centers around two characteristics of these networks. First, the weights on connections between units need not be prewired by the model builder but rather may be established through training in which items to be learned are presented repeatedly to the network and the connection weights are adjusted in small increments according to a learning algorithm. Second, the networks may represent information in a distributed fashion. This chapter discusses the catastrophic interference in connectionist networks. Distributed representations established through the application of learning algorithms have several properties that are claimed to be desirable from the standpoint of modeling human cognition. These properties include content-addressable memory and so-called automatic generalization in which a network trained on a set of items responds correctly to other untrained items within the same domain. New learning may interfere catastrophically with old learning when networks are trained sequentially. The analysis of the causes of interference implies that at least some interference will occur whenever new learning may alter weights involved in representing old learning, and the simulation results demonstrate only that interference is catastrophic in some specific networks.},
    author    = {Michael McCloskey and Neal J. Cohen},
    doi       = {10.1016/S0079-7421(08)60536-8},
    editor    = {Gordon H. Bower},
    issn      = {0079-7421},
    pages     = {109-165},
    publisher = {Academic Press},
    series    = {Psychology of Learning and Motivation},
    title     = {Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem},
    volume    = {24},
    year      = {1989}
}
@article{McCormac:etal:arXiv2016,
    author     = {John McCormac and
                  Ankur Handa and
                  Stefan Leutenegger and
                  Andrew J. Davison},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/McCormacHLD16.bib},
    doi        = {10.48550/arXiv.1612.05079},
    eprint     = {1612.05079},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:48:55 +0200},
    title      = {SceneNet {RGB-D:} 5M Photorealistic Images of Synthetic Indoor Trajectories
                  with Ground Truth},
    volume     = {abs/1612.05079},
    year       = {2016}
}
@article{McCormac:etal:ICCV2017,
    author    = {John McCormac and
                 Ankur Handa and
                 Stefan Leutenegger and
                 Andrew J.Davison},
    booktitle = {ICCV},
    doi       = {10.1109/ICCV.2017.292},
    title     = {SceneNet RGB-D: Can 5M Synthetic Images Beat Generic ImageNet Pre-training on Indoor Segmentation?},
    year      = {2017}
}
@inproceedings{mcgregor2004flow,
    abstract  = {Packet header traces are widely used in network analysis. Header traces are the aggregate of traffic from many concurrent applications. We present a methodology, based on machine learning, that can break the trace down into clusters of traffic where each cluster has different traffic characteristics. Typical clusters include bulk transfer, single and multiple transactions and interactive traffic, amongst others. The paper includes a description of the methodology, a visualisation of the attribute statistics that aids in recognising cluster types and a discussion of the stability and effectiveness of the methodology.},
    address   = {Berlin, Heidelberg},
    author    = {McGregor, Anthony
                 and Hall, Mark
                 and Lorier, Perry
                 and Brunskill, James},
    booktitle = {Passive and Active Network Measurement},
    doi       = {10.1007/978-3-540-24668-8_21},
    editor    = {Barakat, Chadi
                 and Pratt, Ian},
    isbn      = {978-3-540-24668-8},
    pages     = {205--214},
    publisher = {Springer Berlin Heidelberg},
    title     = {Flow Clustering Using Machine Learning Techniques},
    year      = {2004}
}
@inproceedings{meenpal2019facial,
    author    = {Meenpal, Toshanlal and Balakrishnan, Ashutosh and Verma, Amit},
    booktitle = {2019 4th International Conference on Computing, Communications and Security (ICCCS)},
    doi       = {10.1109/CCCS.2019.8888092},
    number    = {},
    pages     = {1-5},
    title     = {Facial Mask Detection using Semantic Segmentation},
    volume    = {},
    year      = {2019}
}
@article{Menze2014-gj,
    abstract = {In this paper we report the set-up and results of the Multimodal
                Brain Tumor Image Segmentation Benchmark (BRATS) organized in
                conjunction with the MICCAI 2012 and 2013 conferences. Twenty
                state-of-the-art tumor segmentation algorithms were applied to a
                set of 65 multi-contrast MR scans of low- and high-grade glioma
                patients-manually annotated by up to four raters-and to 65
                comparable scans generated using tumor image simulation software.
                Quantitative evaluations revealed considerable disagreement
                between the human raters in segmenting various tumor sub-regions
                (Dice scores in the range 74{\%}-85{\%}), illustrating the difficulty
                of this task. We found that different algorithms worked best for
                different sub-regions (reaching performance comparable to human
                inter-rater variability), but that no single algorithm ranked in
                the top for all sub-regions simultaneously. Fusing several good
                algorithms using a hierarchical majority vote yielded
                segmentations that consistently ranked above all individual
                algorithms, indicating remaining opportunities for further
                methodological improvements. The BRATS image data and manual
                annotations continue to be publicly available through an online
                evaluation system as an ongoing benchmarking resource.},
    address  = {United States},
    author   = {Menze, Bjoern H and Jakab, Andras and Bauer, Stefan and
                Kalpathy-Cramer, Jayashree and Farahani, Keyvan and Kirby, Justin
                and Burren, Yuliya and Porz, Nicole and Slotboom, Johannes and
                Wiest, Roland and Lanczi, Levente and Gerstner, Elizabeth and
                Weber, Marc-Andr{\'e} and Arbel, Tal and Avants, Brian B and
                Ayache, Nicholas and Buendia, Patricia and Collins, D Louis and
                Cordier, Nicolas and Corso, Jason J and Criminisi, Antonio and
                Das, Tilak and Delingette, Herv{\'e} and Demiralp, {\c C}a{\u
                g}atay and Durst, Christopher R and Dojat, Michel and Doyle,
                Senan and Festa, Joana and Forbes, Florence and Geremia, Ezequiel
                and Glocker, Ben and Golland, Polina and Guo, Xiaotao and
                Hamamci, Andac and Iftekharuddin, Khan M and Jena, Raj and John,
                Nigel M and Konukoglu, Ender and Lashkari, Danial and Mariz,
                Jos{\'e} Antoni{\'o} and Meier, Raphael and Pereira, S{\'e}rgio
                and Precup, Doina and Price, Stephen J and Raviv, Tammy Riklin
                and Reza, Syed M S and Ryan, Michael and Sarikaya, Duygu and
                Schwartz, Lawrence and Shin, Hoo-Chang and Shotton, Jamie and
                Silva, Carlos A and Sousa, Nuno and Subbanna, Nagesh K and
                Szekely, Gabor and Taylor, Thomas J and Thomas, Owen M and
                Tustison, Nicholas J and Unal, Gozde and Vasseur, Flor and
                Wintermark, Max and Ye, Dong Hye and Zhao, Liang and Zhao,
                Binsheng and Zikic, Darko and Prastawa, Marcel and Reyes,
                Mauricio and Van Leemput, Koen},
    doi      = {10.1109/TMI.2014.2377694},
    journal  = {IEEE Trans Med Imaging},
    language = {en},
    month    = dec,
    number   = 10,
    pages    = {1993--2024},
    title    = {The Multimodal Brain Tumor Image Segmentation Benchmark ({BRATS})},
    volume   = 34,
    year     = 2014
}
@inproceedings{milioto2018real,
    author    = {Milioto, Andres and Lottes, Philipp and Stachniss, Cyrill},
    booktitle = {2018 IEEE International Conference on Robotics and Automation (ICRA)},
    doi       = {10.1109/ICRA.2018.8460962},
    number    = {},
    pages     = {2229-2235},
    title     = {Real-Time Semantic Segmentation of Crop and Weed for Precision Agriculture Robots Leveraging Background Knowledge in CNNs},
    volume    = {},
    year      = {2018}
}
@inproceedings{milioto2019bonnet,
    author    = {Milioto, Andres and Stachniss, Cyrill},
    booktitle = {2019 International Conference on Robotics and Automation (ICRA)},
    doi       = {10.1109/ICRA.2019.8793510},
    number    = {},
    pages     = {7094-7100},
    title     = {Bonnet: An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs},
    volume    = {},
    year      = {2019}
}
@article{musk2019integrated,
    author    = {Musk, Elon and others},
    doi       = {10.2196/16194},
    journal   = {Journal of medical Internet research},
    number    = {10},
    pages     = {e16194},
    publisher = {JMIR Publications Inc., Toronto, Canada},
    title     = {An integrated brain-machine interface platform with thousands of channels},
    volume    = {21},
    year      = {2019}
}
@article{naoum2004orographic,
    abstract = { A multiple linear regression (MLR) model, in conjunction with Geographic Information Systems technology, was used to derive the relationship between annual precipitation and elevation, longitude, and latitude. The island of Crete, in Greece, was used as the case study. A multiscale precipitation analysis was performed on areas ranging from large areas (the whole island and the northern, southern, and eastern parts of the island), to medium areas (watersheds), to small areas (sub-basins). While the MLR annual precipitation estimates (which used elevation, latitude, and longitude information) were found to be more reasonable than estimates obtained using elevation only when applied to the whole island, the difference between the MLR estimates and the elevation-only estimates was smaller when applied to individual watersheds. The MLR provides realistic estimates for mean areal precipitation for the island of Crete: 700±100, 950±150, and 1,300±200 mm for dry, average, and wet years, respectively. Elevation-rainfall gradients are: 0.45–0.6, 0.6–0.9, and 0.9–1.3 mm/m for dry, average, and wet years, respectively. Of this, 44{\%} falls on the northern, 33{\%} on the southern, and 23{\%} on the eastern parts of the island for a typical average year.  },
    author   = {S. Naoum  and I. K. Tsanis },
    doi      = {10.1061/(ASCE)1084-0699(2004)9:2(79)},
    eprint   = {https://ascelibrary.org/doi/pdf/10.1061/},
    journal  = {Journal of Hydrologic Engineering},
    number   = {2},
    pages    = {79-102},
    title    = {Orographic Precipitation Modeling with Multiple Linear Regression},
    volume   = {9},
    year     = {2004}
}
@inproceedings{NEURIPS2018_36072923,
    author    = {Bjorck, Nils and Gomes, Carla P and Selman, Bart and Weinberger, Kilian Q},
    booktitle = {Advances in Neural Information Processing Systems},
    doi       = {10.48550/arXiv.1806.02375},
    editor    = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {Understanding Batch Normalization},
    volume    = {31},
    year      = {2018}
}
@inproceedings{NEURIPS2018_a41b3bb3,
    author    = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
    booktitle = {Advances in Neural Information Processing Systems},
    doi       = {10.48550/arXiv.1806.02375},
    editor    = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {Visualizing the Loss Landscape of Neural Nets},
    volume    = {31},
    year      = {2018}
}
@inproceedings{NEURIPS2019_2d95666e,
    author    = {Hu, Xiaoling and Li, Fuxin and Samaras, Dimitris and Chen, Chao},
    booktitle = {Advances in Neural Information Processing Systems},
    doi       = {10.48550/arXiv.1906.05404},
    editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {Topology-Preserving Deep Image Segmentation},
    volume    = {32},
    year      = {2019}
}
@inproceedings{NEURIPS2019_a67c8c9a,
    author    = {Zhao, Shuai and Wang, Yang and Yang, Zheng and Cai, Deng},
    booktitle = {Advances in Neural Information Processing Systems},
    doi       = {10.48550/arXiv.1910.12037},
    editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {Region Mutual Information Loss for Semantic Segmentation},
    volume    = {32},
    year      = {2019}
}
@inproceedings{NEURIPS2019_bdbca288,
    author    = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
    booktitle = {Advances in Neural Information Processing Systems},
    doi       = {10.48550/arXiv.1912.01703},
    editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
    volume    = {32},
    year      = {2019}
}
@inproceedings{NIPS1991_ff4d5fbb,
    author    = {Vapnik, V.},
    booktitle = {Advances in Neural Information Processing Systems},
    editor    = {J. Moody and S. Hanson and R.P. Lippmann},
    pages     = {},
    publisher = {Morgan-Kaufmann},
    title     = {Principles of Risk Minimization for Learning Theory},
    url       = {https://proceedings.neurips.cc/paper/1991/file/ff4d5fbbafdf976cfdc032e3bde78de5-Paper.pdf},
    volume    = {4},
    year      = {1991}
}
@inproceedings{NIPS2013_e034fb6b,
    author    = {Griffith, Shane and Subramanian, Kaushik and Scholz, Jonathan and Isbell, Charles L and Thomaz, Andrea L},
    booktitle = {Advances in Neural Information Processing Systems},
    editor    = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {Policy Shaping: Integrating Human Feedback with Reinforcement Learning},
    url       = {https://proceedings.neurips.cc/paper_files/paper/2013/file/e034fb6b66aacc1d48f445ddfb08da98-Paper.pdf},
    volume    = {26},
    year      = {2013}
}
@inproceedings{NIPS2015_14bfa6bb,
    author    = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
    booktitle = {Advances in Neural Information Processing Systems},
    editor    = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
    url       = {https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf},
    volume    = {28},
    year      = {2015}
}
@inproceedings{NIPS2017_453fadbd,
    author    = {Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
    booktitle = {Advances in Neural Information Processing Systems},
    editor    = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {Hindsight Experience Replay},
    url       = {https://proceedings.neurips.cc/paper/2017/file/453fadbd8a1a3af50a9df4df899537b5-Paper.pdf},
    volume    = {30},
    year      = {2017}
}
@article{NIU202148,
    abstract = {Attention has arguably become one of the most important concepts in the deep learning field. It is inspired by the biological systems of humans that tend to focus on the distinctive parts when processing large amounts of information. With the development of deep neural networks, attention mechanism has been widely used in diverse application domains. This paper aims to give an overview of the state-of-the-art attention models proposed in recent years. Toward a better general understanding of attention mechanisms, we define a unified model that is suitable for most attention structures. Each step of the attention mechanism implemented in the model is described in detail. Furthermore, we classify existing attention models according to four criteria: the softness of attention, forms of input feature, input representation, and output representation. Besides, we summarize network architectures used in conjunction with the attention mechanism and describe some typical applications of attention mechanism. Finally, we discuss the interpretability that attention brings to deep learning and present its potential future trends.},
    author   = {Zhaoyang Niu and Guoqiang Zhong and Hui Yu},
    doi      = {10.1016/j.neucom.2021.03.091},
    issn     = {0925-2312},
    journal  = {Neurocomputing},
    keywords = {Attention mechanism, Deep learning, Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), Encoder-decoder, Unified attention model, Computer vision applications, Natural language processing applications},
    pages    = {48-62},
    title    = {A review on the attention mechanism of deep learning},
    volume   = {452},
    year     = {2021}
}
@inproceedings{o2015learning,
    author    = {O. Pinheiro, Pedro O and Collobert, Ronan and Dollar, Piotr},
    booktitle = {Advances in Neural Information Processing Systems},
    doi       = {10.48550/arXiv.1506.06204},
    editor    = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {Learning to Segment Object Candidates},
    volume    = {28},
    year      = {2015}
}
@article{oberweger2015hands,
    author     = {Markus Oberweger and
                  Paul Wohlhart and
                  Vincent Lepetit},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/OberwegerWL15.bib},
    doi        = {10.48550/arXiv.1502.06807},
    eprint     = {1502.06807},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:46:52 +0200},
    title      = {Hands Deep in Deep Learning for Hand Pose Estimation},
    volume     = {abs/1502.06807},
    year       = {2015}
}
@article{objectProposalGeneration2021,
    abstract       = {The objectness measure is a significant and effective method used for generic object detection. However, several object detection methods can achieve accurate results by using more than 1000 candidate object proposals. In addition, the weight of each proposal is weak and also cannot distinguish object proposals. These weak proposals have brought difficulties to the subsequent analysis. To significantly reduce the number of proposals, this paper presents an improved generic object detection approach, which predicts candidate object proposals from more than 10,000 proposals. All candidate proposals can be divided, rather than preclassified, into three categories: entire object, partial object, and nonobject. These partial object proposals also display fragmentary information of the objectness feature, which can be used to reconstruct the object boundary. By using partial objectness to enhance the weight of the entire object proposals, we removed a huge number of useless proposals and reduced the space occupied by the true positive object proposals. We designed a neural network with lightweight computation to cluster the most possible object proposals with rerank and box regression. Through joint training, the lightweight network can share the features with other subsequent tasks. The proposed method was validated using experiments with the PASCAL VOC2007 dataset. The results showed that the proposed approach was significantly improved compared with the existing methods and can accurately detect 92.3{\%} of the objects by using less than 200 proposals.},
    article-number = {794},
    author         = {Deng, Yao and Liang, Huawei and Yi, Zhiyan},
    doi            = {10.3390/electronics10070794},
    issn           = {2079-9292},
    journal        = {Electronics},
    number         = {7},
    title          = {An Improved Approach for Object Proposals Generation},
    volume         = {10},
    year           = {2021}
}
@inproceedings{osuna1997training,
    author    = {Osuna, E. and Freund, R. and Girosit, F.},
    booktitle = {Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
    doi       = {10.1109/CVPR.1997.609310},
    number    = {},
    pages     = {130-136},
    title     = {Training support vector machines: an application to face detection},
    volume    = {},
    year      = {1997}
}
@misc{ouali2020semi,
    author    = {Ouali, Yassine and Hudelot, Céline and Tami, Myriam},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2003.09005},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Semi-Supervised Semantic Segmentation with Cross-Consistency Training},
    year      = {2020}
}

@article{paletta2000active,
    abstract = {A mobile agent with the task to classify its sensor pattern has to cope with ambiguous information. Active recognition of three-dimensional objects involves the observer in a search for discriminative evidence, e.g., by change of its viewpoint. This paper defines the recognition process as a sequential decision problem with the objective to disambiguate initial object hypotheses. Reinforcement learning provides then an efficient method to autonomously develop near-optimal decision strategies in terms of sensorimotor mappings. The proposed system learns object models from visual appearance and uses a radial basis function (RBF) network for a probabilistic interpretation of the two-dimensional views. The information gain in fusing successive object hypotheses provides a utility measure to reinforce actions leading to discriminative viewpoints. The system is verified in experiments with 16 objects and two degrees of freedom in sensor motion. Crucial improvements in performance are gained using the learned in contrast to random camera placements.},
    author   = {Lucas Paletta and Axel Pinz},
    doi      = {10.1016/S0921-8890(99)00079-2},
    issn     = {0921-8890},
    journal  = {Robotics and Autonomous Systems},
    keywords = {Active recognition, Reinforcement learning, Information fusion, Viewpoint planning},
    number   = {1},
    pages    = {71-86},
    title    = {Active object recognition by view integration and reinforcement learning},

    volume   = {31},
    year     = {2000}
}
@article{Parikh2008-bd,
    abstract = {In this article, we have discussed the basic knowledge to
                calculate sensitivity, specificity, positive predictive value and
                negative predictive value. We have discussed the advantage and
                limitations of these measures and have provided how we should use
                these measures in our day-to-day clinical practice. We also have
                illustrated how to calculate sensitivity and specificity while
                combining two tests and how to use these results for our patients
                in day-to-day practice.},
    address  = {India},
    author   = {Parikh, Rajul and Mathai, Annie and Parikh, Shefali and Chandra
                Sekhar, G and Thomas, Ravi},
    doi      = {10.4103/0301-4738.37595},
    journal  = {Indian J Ophthalmol},
    language = {en},
    month    = jan,
    number   = 1,
    pages    = {45--50},
    title    = {Understanding and using sensitivity, specificity and predictive
                values},
    volume   = 56,
    year     = 2008
}

@misc{pascal-voc-2012,
    author       = {Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.},
    howpublished = {http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html},
    title        = {The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2012 {(VOC2012)} {R}esults},
    url          = {http://host.robots.ox.ac.uk/pascal/VOC/voc2012}
}
@article{Paszke2017Oct,
    author  = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
    journal = {OpenReview},
    month   = oct,
    title   = {{Automatic differentiation in PyTorch}},
    url     = {https://openreview.net/forum?id=BJJsrmfCZ},
    year    = {2017}
}
@article{patil2013medical,
    author  = {Patil, Dinesh D and Deore, Sonal G},
    journal = {International Journal of Computer Science and Mobile Computing},
    number  = {1},
    pages   = {22--27},
    title   = {Medical image segmentation: a review},
    url     = {https://www.semanticscholar.org/paper/Medical-Image-Segmentation%3A-A-Review-Patil-Deore/ae68948d2f0d2b4e9eb107f6af1d67066c0c6fdf},
    volume  = {2},
    year    = {2013}
}
@article{perlich2014machine,
    abstract = {This paper presents the design of a fully deployed multistage transfer learning system for targeted display advertising, highlighting the important role of problem formulation and the sampling of data from distributions different from that of the target environment. Notably, the machine learning system itself is deployed and has been in continual use for years for thousands of advertising campaigns---in contrast to the more common case where predictive models are built outside the system, curated, and then deployed. In this domain, acquiring sufficient data for training from the ideal sampling distribution is prohibitively expensive. Instead, data are drawn from surrogate distributions and learning tasks, and then transferred to the target task. We present the design of the transfer learning system We then present a detailed experimental evaluation, showing that the different transfer stages indeed each add value. We also present production results across a variety of advertising clients from a variety of industries, illustrating the performance of the system in use. We close the paper with a collection of lessons learned from over half a decade of research and development on this complex, deployed, and intensely used machine learning system.},
    author   = {Perlich, C.
                and Dalessandro, B.
                and Raeder, T.
                and Stitelman, O.
                and Provost, F.},
    day      = {01},
    doi      = {10.1007/s10994-013-5375-2},
    issn     = {1573-0565},
    journal  = {Machine Learning},
    month    = {04},
    number   = {1},
    pages    = {103-127},
    title    = {Machine learning for targeted display advertising: transfer learning in action},
    volume   = {95},
    year     = {2014}
}

@inproceedings{pinheiro2016learning,
    author       = {Pinheiro, Pedro O and Lin, Tsung-Yi and Collobert, Ronan and Doll{\'a}r, Piotr},
    booktitle    = {European conference on computer vision},
    doi          = {10.48550/arXiv.1603.08695},
    organization = {Springer},
    pages        = {75--91},
    title        = {Learning to refine object segments},
    year         = {2016}
}
@article{pisarchik2019novel,
    author    = {Pisarchik, Alexander N and Maksimenko, Vladimir A and Hramov, Alexander E},
    doi       = {10.2196/16356},
    journal   = {Journal of medical Internet research},
    number    = {10},
    pages     = {e16356},
    publisher = {JMIR Publications Inc., Toronto, Canada},
    title     = {From novel technology to novel applications: Comment on “An integrated brain-machine interface platform with thousands of channels” by Elon Musk and Neuralink},
    volume    = {21},
    year      = {2019}
}
  @incollection{PISNER2020101,
    abstract  = {In this chapter, we explore Support Vector Machine (SVM)—a machine learning method that has become exceedingly popular for neuroimaging analysis in recent years. Because of their relative simplicity and flexibility for addressing a range of classification problems, SVMs distinctively afford balanced predictive performance, even in studies where sample sizes may be limited. In brain disorders research, SVMs are typically employed using multivoxel pattern analysis (MVPA) because their relative simplicity carries a lower risk of overfitting even using high-dimensional imaging data. More recently, SVMs have been used in the context of precision psychiatry, particularly for applications that involve predicting diagnosis and prognosis of brain diseases such as Alzheimer's disease, schizophrenia, and depression. In the last section of this chapter, we review a number of recent studies that use SVM for such applications.},
    author    = {Derek A. Pisner and David M. Schnyer},
    booktitle = {Machine Learning},
    doi       = {10.1016/B978-0-12-815739-8.00006-7},
    editor    = {Andrea Mechelli and Sandra Vieira},
    isbn      = {978-0-12-815739-8},
    keywords  = {Classification, Depression, Diagnosis, Hyperplane, Mild cognitive impairment, Multivoxel pattern analysis, Prognosis, Schizophrenia, Searchlight, Support Vector Machine},
    pages     = {101-121},
    publisher = {Academic Press},
    title     = {Chapter 6 - Support vector machine},
    year      = {2020}
}
@incollection{pisner2020support,
    abstract  = {In this chapter, we explore Support Vector Machine (SVM)—a machine learning method that has become exceedingly popular for neuroimaging analysis in recent years. Because of their relative simplicity and flexibility for addressing a range of classification problems, SVMs distinctively afford balanced predictive performance, even in studies where sample sizes may be limited. In brain disorders research, SVMs are typically employed using multivoxel pattern analysis (MVPA) because their relative simplicity carries a lower risk of overfitting even using high-dimensional imaging data. More recently, SVMs have been used in the context of precision psychiatry, particularly for applications that involve predicting diagnosis and prognosis of brain diseases such as Alzheimer's disease, schizophrenia, and depression. In the last section of this chapter, we review a number of recent studies that use SVM for such applications.},
    author    = {Derek A. Pisner and David M. Schnyer},
    booktitle = {Machine Learning},
    doi       = {10.1016/B978-0-12-815739-8.00006-7},
    editor    = {Andrea Mechelli and Sandra Vieira},
    isbn      = {978-0-12-815739-8},
    keywords  = {Classification, Depression, Diagnosis, Hyperplane, Mild cognitive impairment, Multivoxel pattern analysis, Prognosis, Schizophrenia, Searchlight, Support Vector Machine},
    pages     = {101-121},
    publisher = {Academic Press},
    title     = {Chapter 6 - Support vector machine},
    year      = {2020}
}
@inproceedings{pmlr-v120-yang20a,
    abstract  = {Despite the great empirical success of deep reinforcement learning, its theoretical foundation is less well understood. In this work, we make the first attempt to theoretically understand the deep Q-network (DQN) algorithm (Mnih et al., 2015) from both algorithmic and statistical perspectives. In specific, we focus on the fitted Q iteration (FQI) algorithm with deep neural networks, which is a slight simplification of DQN that captures the tricks of experience replay and target network used in DQN. Under mild assumptions, we establish the algorithmic and statistical rates of convergence for the action-value functions of the iterative policy sequence obtained by FQI. In particular, the statistical error characterizes the bias and variance that arise from approximating the action-value function using deep neural network, while the algorithmic error converges to zero at a geometric rate. As a byproduct, our analysis provides justifications for the techniques of experience replay and target network, which are crucial to the empirical success of DQN. Furthermore, as a simple extension of DQN, we propose the Minimax-DQN algorithm for zero-sum Markov game with two players, which is deferred to the appendix due to space limitations.},
    author    = {Fan, Jianqing and Wang, Zhaoran and Xie, Yuchen and Yang, Zhuoran},
    booktitle = {Proceedings of the 2nd Conference on Learning for Dynamics and Control},
    editor    = {Bayen, Alexandre M. and Jadbabaie, Ali and Pappas, George and Parrilo, Pablo A. and Recht, Benjamin and Tomlin, Claire and Zeilinger, Melanie},
    month     = {06},
    pages     = {486--489},
    pdf       = {http://proceedings.mlr.press/v120/yang20a/yang20a.pdf},
    publisher = {PMLR},
    series    = {Proceedings of Machine Learning Research},
    title     = {A Theoretical Analysis of Deep Q-Learning},
    url       = {https://proceedings.mlr.press/v120/yang20a.html},
    volume    = {120},
    year      = {2020}
}	
@inproceedings{pmlr-v37-schulman15,
    abstract  = {In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified scheme, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.},
    address   = {Lille, France},
    author    = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
    booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
    editor    = {Bach, Francis and Blei, David},
    month     = {07},
    pages     = {1889--1897},
    pdf       = {http://proceedings.mlr.press/v37/schulman15.pdf},
    publisher = {PMLR},
    series    = {Proceedings of Machine Learning Research},
    title     = {Trust Region Policy Optimization},
    url       = {https://proceedings.mlr.press/v37/schulman15.html},
    volume    = {37},
    year      = {2015}
}
@inproceedings{pmlr-v48-wangf16,
    abstract  = {In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional networks, LSTMs, or auto-encoders. In this paper, we present a new neural network architecture for model-free reinforcement learning. Our dueling network represents two separate estimators: one for the state value function and one for the state-dependent action advantage function. The main benefit of this factoring is to generalize learning across actions without imposing any change to the underlying reinforcement learning algorithm. Our results show that this architecture leads to better policy evaluation in the presence of many similar-valued actions. Moreover, the dueling architecture enables our RL agent to outperform the state-of-the-art on the Atari 2600 domain.},
    address   = {New York, New York, USA},
    author    = {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
    booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
    editor    = {Balcan, Maria Florina and Weinberger, Kilian Q.},
    month     = {06},
    pages     = {1995--2003},
    pdf       = {http://proceedings.mlr.press/v48/wangf16.pdf},
    publisher = {PMLR},
    series    = {Proceedings of Machine Learning Research},
    title     = {Dueling Network Architectures for Deep Reinforcement Learning},
    url       = {https://proceedings.mlr.press/v48/wangf16.html},
    volume    = {48},
    year      = {2016}
}


@inproceedings{pmlr-v78-zuo17a,
    abstract  = {In recent times, Convolutional Neural Network (CNN) based approaches have performed exceptionally well in many computer vision related tasks, including classification and segmentation. These approaches have shown that given enough training data and time, they can often perform at a level significantly higher than the alternative methods. However, in the context of robotic learning, it is commonly the case that both time and training data are limited. In this work, we propose a learning approach that is more suitable for robotic learning; it substantially reduces the time required to learn and provides much higher performance when training data is limited. Our method combines random forests with deep convolution networks, leveraging the strengths of both frameworks. We develop a method for generating derivatives from our highly non-linear forest classifier which in turn enables training of the CNN. Furthermore, our method allows leaf distributions in the ensemble classifier to be trained jointly with one another using Stochastic Gradient Descent (SGD), allowing for parallel training of a large number of tree classifiers at once. This results in a drastic increase in training speed. Our model demonstrates significant performance improvements over pure deep learning methods, notably on datasets with limited training data. We apply our method to the outdoor and indoor segmentation datasets of KITTI and NYUv2-40, outperforming multiple pure deep learning methods whilst using a fraction of training time normally required.},
    author    = {Zuo, Yan and Drummond, Tom},
    booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
    editor    = {Levine, Sergey and Vanhoucke, Vincent and Goldberg, Ken},
    month     = {11},
    pages     = {27--36},
    pdf       = {http://proceedings.mlr.press/v78/zuo17a/zuo17a.pdf},
    publisher = {PMLR},
    series    = {Proceedings of Machine Learning Research},
    title     = {Fast Residual Forests: Rapid Ensemble Learning for Semantic Segmentation},
    url       = {https://proceedings.mlr.press/v78/zuo17a.html},
    volume    = {78},
    year      = {2017}
}
@misc{powers2020evaluation,
    archiveprefix = {arXiv},
    author        = {David M. W. Powers},
    doi           = {10.48550/arXiv.2010.16061},
    eprint        = {2010.16061},
    primaryclass  = {cs.LG},
    title         = {Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation},
    year          = {2020}
}
@article{provost2013data,
    author    = {Provost, Foster and Fawcett, Tom},
    doi       = {10.1089/big.2013.1508},
    journal   = {Big data},
    number    = {1},
    pages     = {51--59},
    publisher = {Mary Ann Liebert, Inc. 140 Huguenot Street 3rd Floor New Rochelle NY 10801 USA},
    title     = {Data science and its relationship to big data and data-driven decision making},
    volume    = {1},
    year      = {2013}
}
@misc{PytorchLightning,
    month = mar,
    note  = {[Online; accessed 6. Apr. 2023]},
    title = {{Lightning in 15 minutes {\ifmmode---\else\textemdash\fi} PyTorch Lightning 2.0.1 documentation}},
    url   = {https://lightning.ai/docs/pytorch/stable/starter/introduction.html},
    year  = {2023}
}
@article{radhika2009atmospheric,
    author  = {Yalavarthi, Radhika and Shashi, M.},
    doi     = {10.7763/IJCTE.2009.V1.9},
    journal = {International Journal of Computer Theory and Engineering},
    month   = {01},
    pages   = {55-58},
    title   = {Atmospheric Temperature Prediction using Support Vector Machines},
    volume  = {1},
    year    = {2009}
}
@article{Rajaraman2022-fy,
    abstract = {Automated segmentation of tuberculosis (TB)-consistent lesions in
                chest X-rays (CXRs) using deep learning (DL) methods can help
                reduce radiologist effort, supplement clinical decision-making,
                and potentially result in improved patient treatment. The
                majority of works in the literature discuss training automatic
                segmentation models using coarse bounding box annotations.
                However, the granularity of the bounding box annotation could
                result in the inclusion of a considerable fraction of false
                positives and negatives at the pixel level that may adversely
                impact overall semantic segmentation performance. This study
                evaluates the benefits of using fine-grained annotations of
                TB-consistent lesions toward training the variants of U-Net
                models and constructing their ensembles for semantically
                segmenting TB-consistent lesions in both original and
                bone-suppressed frontal CXRs. The segmentation performance is
                evaluated using several ensemble methods such as bitwise- AND,
                bitwise-OR, bitwise-MAX, and stacking. Extensive empirical
                evaluations showcased that the stacking ensemble demonstrated
                superior segmentation performance (Dice score: 0.5743, 95{\%}
                confidence interval: (0.4055, 0.7431)) compared to the individual
                constituent models and other ensemble methods. To the best of our
                knowledge, this is the first study to apply ensemble learning to
                improve fine-grained TB-consistent lesion segmentation
                performance.},
    address  = {Switzerland},
    author   = {Rajaraman, Sivaramakrishnan and Yang, Feng and Zamzmi, Ghada and
                Xue, Zhiyun and Antani, Sameer K},
    doi      = {10.3390/bioengineering9090413},
    journal  = {Bioengineering (Basel)},
    keywords = {bone suppression; chest X-rays; deep learning; ensemble;
                segmentation; stacking; tuberculosis},
    language = {en},
    month    = {08},
    number   = 9,
    title    = {A Systematic Evaluation of Ensemble Learning Methods for
                {Fine-Grained} Semantic Segmentation of {Tuberculosis-Consistent}
                Lesions in Chest Radiographs},
    volume   = 9,
    year     = 2022
}
@inproceedings{ramadhan2017sentiment,
    author       = {Ramadhan, WP and Novianty, STMT Astri and Setianingsih, STMT Casi},
    booktitle    = {2017 International Conference on Control, Electronics, Renewable Energy and Communications (ICCREC)},
    doi          = {10.1109/ICCEREC.2017.8226700},
    organization = {IEEE},
    pages        = {46--49},
    title        = {Sentiment analysis using multinomial logistic regression},
    year         = {2017}
}
@inproceedings{rapson2018reducing,
    author    = {Rapson, Christopher J. and Seet, Boon-Chong and Naeem, M. Asif and Lee, Jeong Eun and Al-Sarayreh, Mahmoud and Klette, Reinhard},
    booktitle = {2018 International Conference on Image and Vision Computing New Zealand (IVCNZ)},
    doi       = {10.1109/IVCNZ.2018.8634750},
    number    = {},
    pages     = {1-9},
    title     = {Reducing the Pain: A Novel Tool for Efficient Ground-Truth Labelling in Images},
    volume    = {},
    year      = {2018}
}
@inproceedings{rezaei2018conditional,
    abstract  = {Automated brain lesion detection is an important and very challenging clinical diagnostic task, due to the lesions'different sizes, shapes, contrasts, and locations. Recently deep learning has shown promising progresses in many application fields, thereby motivating us to apply this technique for such an important problem. In this paper, we propose an automatic end-to-end trainable architecture for heterogeneous brain tumor segmentation through adversarial training for the BraTS-2017 challenge. Inspired by classical generative adversarial network, the proposed network has two components: the ``Discriminator'' and the ``Generator''. We use a patient-wise fully convolutional neural networks (FCNs) as the segmentor network to generate segmentation label maps. The discriminator network is patient-wise fully convolutional neural networks (FCNs) with L1 loss that discriminates segmentation maps coming from the ground truth or from the segmentor network. We propose an end-to-end trainable CNNs for survival day prediction based on deep learning techniques. The experimental results demonstrate the ability of the propose approaches for both tasks of BraTS-2017 challenge. Our patient-wise cGAN achieved competitive results in the BraTS-2017 challenges.},
    address   = {Cham},
    author    = {Rezaei, Mina
                 and Harmuth, Konstantin
                 and Gierke, Willi
                 and Kellermeier, Thomas
                 and Fischer, Martin
                 and Yang, Haojin
                 and Meinel, Christoph},
    booktitle = {Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries},
    doi       = {10.48550/arXiv.1708.05227},
    editor    = {Crimi, Alessandro
                 and Bakas, Spyridon
                 and Kuijf, Hugo
                 and Menze, Bjoern
                 and Reyes, Mauricio},
    isbn      = {978-3-319-75238-9},
    pages     = {241--252},
    publisher = {Springer International Publishing},
    title     = {A Conditional Adversarial Network for Semantic Segmentation of Brain Tumor},
    year      = {2018}
}
@article{richter2019open,
    author     = {Florian Richter and
                  Ryan K. Orosco and
                  Michael C. Yip},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1903-02090.bib},
    doi        = {10.48550/arXiv.1903.02090},
    eprint     = {1903.02090},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Fri, 17 Dec 2021 07:48:20 +0100},
    title      = {Open-Sourced Reinforcement Learning Environments for Surgical Robotics},
    volume     = {abs/1903.02090},
    year       = {2019}
}
@book{rockafellar2009variational,
    author    = {Rockafellar, R Tyrrell and Wets, Roger J-B},
    publisher = {Springer Science \& Business Media},
    title     = {Variational analysis},
    url       = {https://link.springer.com/book/10.1007/978-3-642-02431-3},
    volume    = {317},
    year      = {2009}
}
@article{rosenblatt1958perceptron,
    author    = {Rosenblatt, Frank},
    doi       = {10.1037/h0042519},
    journal   = {Psychological review},
    number    = {6},
    pages     = {386},
    publisher = {American Psychological Association},
    title     = {The perceptron: a probabilistic model for information storage and organization in the brain.},
    volume    = {65},
    year      = {1958}
}

@article{rs12040701,
    abstract       = {The semantic segmentation of remote sensing images (RSIs) is important in a variety of applications. Conventional encoder-decoder-based convolutional neural networks (CNNs) use cascade pooling operations to aggregate the semantic information, which results in a loss of localization accuracy and in the preservation of spatial details. To overcome these limitations, we introduce the use of the high-resolution network (HRNet) to produce high-resolution features without the decoding stage. Moreover, we enhance the low-to-high features extracted from different branches separately to strengthen the embedding of scale-related contextual information. The low-resolution features contain more semantic information and have a small spatial size; thus, they are utilized to model the long-term spatial correlations. The high-resolution branches are enhanced by introducing an adaptive spatial pooling (ASP) module to aggregate more local contexts. By combining these context aggregation designs across different levels, the resulting architecture is capable of exploiting spatial context at both global and local levels. The experimental results obtained on two RSI datasets show that our approach significantly improves the accuracy with respect to the commonly used CNNs and achieves state-of-the-art performance.},
    article-number = {701},
    author         = {Zhang, Jing and Lin, Shaofu and Ding, Lei and Bruzzone, Lorenzo},
    doi            = {10.3390/rs12040701},
    issn           = {2072-4292},
    journal        = {Remote Sensing},
    number         = {4},
    title          = {Multi-Scale Context Aggregation for Semantic Segmentation of Remote Sensing Images},
    volume         = {12},
    year           = {2020}
}
@book{russel2010,
    added-at  = {2020-02-01T18:23:11.000+0100},
    author    = {Russell, Stuart and Norvig, Peter},
    biburl    = {https://www.bibsonomy.org/bibtex/20533b732950d1c5ab4ac12d4f32fe637/mialhoma},
    edition   = 3,
    interhash = {53908a52dd4c6c8e39f93f4ffc8341be},
    intrahash = {0533b732950d1c5ab4ac12d4f32fe637},
    keywords  = {ties4530},
    publisher = {Prentice Hall},
    timestamp = {2020-02-01T18:23:11.000+0100},
    title     = {Artificial Intelligence: A Modern Approach},
    url       = {https://aima.cs.berkeley.edu},
    year      = 2010
}
@article{sager2021survey,
    author    = {Christoph Sager and Christian Janiesch and Patrick Zschech},
    doi       = {10.1080/2573234X.2021.1908861},
    eprint    = {https://doi.org/10.1080/2573234X.2021.1908861},
    journal   = {Journal of Business Analytics},
    number    = {2},
    pages     = {91-110},
    publisher = {Taylor & Francis},
    title     = {A survey of image labelling for computer vision applications},
    volume    = {4},
    year      = {2021}
}
@inproceedings{sahba2006reinforcement,
    author    = {Sahba, F. and Tizhoosh, H.R. and Salama, M.M.A.},
    booktitle = {The 2006 IEEE International Joint Conference on Neural Network Proceedings},
    doi       = {10.1109/IJCNN.2006.246725},
    number    = {},
    pages     = {511-517},
    title     = {A Reinforcement Learning Framework for Medical Image Segmentation},
    volume    = {},
    year      = {2006}
}
@inproceedings{sahin2011detecting,
    author    = {Sahin, Y. and Duman, E.},
    booktitle = {2011 International Symposium on Innovations in Intelligent Systems and Applications},
    doi       = {10.1109/INISTA.2011.5946108},
    number    = {},
    pages     = {315-319},
    title     = {Detecting credit card fraud by ANN and logistic regression},
    volume    = {},
    year      = {2011}
}
@article{Seo2021-mt,
    abstract = {Deep learning is becoming an indispensable tool for various tasks
                in science and engineering. A critical step in constructing a
                reliable deep learning model is the selection of a loss function,
                which measures the discrepancy between the network prediction and
                the ground truth. While a variety of loss functions have been
                proposed in the literature, a truly optimal loss function that
                maximally utilizes the capacity of neural networks for deep
                learning-based decision-making has yet to be established. Here,
                we devise a generalized loss function with functional parameters
                determined adaptively during model training to provide a
                versatile framework for optimal neural network-based
                decision-making in small target segmentation. The method is
                showcased by more accurate detection and segmentation of lung and
                liver cancer tumors as compared with the current
                state-of-the-art. The proposed formalism opens new opportunities
                for numerous practical applications such as disease diagnosis,
                treatment planning, and prognosis.},
    address  = {United States},
    author   = {Seo, Hyunseok and Bassenne, Maxime and Xing, Lei},
    doi      = {10.1109/TMI.2020.3031913},
    journal  = {IEEE Trans Med Imaging},
    language = {en},
    month    = {02},
    number   = 2,
    pages    = {585--593},
    title    = {Closing the Gap Between Deep Neural Network Modeling and
                Biomedical {Decision-Making} Metrics in Segmentation via Adaptive
                Loss Functions},
    volume   = 40,
    year     = 2021
}
@article{settles2009active,
    author    = {Settles, Burr},
    journal   = {University of Wisconsin-Madison Department of Computer Sciences},
    publisher = {University of Wisconsin-Madison Department of Computer Sciences},
    title     = {{Active Learning Literature Survey}},
    url       = {https://minds.wisconsin.edu/handle/1793/60660},
    year      = {2009}
}
@article{shakya2021big,
    author  = {Shakya, Subarna and Smys, Smys},
    doi     = {10.36548/jismac.2021.3.005},
    journal = {Journal of ISMAC},
    number  = {3},
    pages   = {235--249},
    title   = {Big data analytics for improved risk management and customer segregation in banking applications},
    volume  = {3},
    year    = {2021}
}
@article{shao2019survey,
    author     = {Kun Shao and
                  Zhentao Tang and
                  Yuanheng Zhu and
                  Nannan Li and
                  Dongbin Zhao},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1912-10944.bib},
    doi        = {10.48550/arXiv.1912.10944},
    eprint     = {1912.10944},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Tue, 01 Sep 2020 23:31:48 +0200},
    title      = {A Survey of Deep Reinforcement Learning in Video Games},
    volume     = {abs/1912.10944},
    year       = {2019}
}
@book{shapiro2001computer,
    author    = {Shapiro, Linda G and Stockman, George C and others},
    publisher = {Prentice Hall New Jersey},
    title     = {Computer vision},
    url       = {https://books.google.de/books/about/Computer_Vision.html?id=INYCnwEACAAJ&redir_esc=y},
    volume    = {3},
    year      = {2001}
}
@article{sharma2017evidence,
    abstract = {Active learning methods select informative instances to effectively learn a suitable classifier. Uncertainty sampling, a frequently utilized active learning strategy, selects instances about which the model is uncertain but it does not consider the reasons for why the model is uncertain. In this article, we present an evidence-based framework that can uncover the reasons for why a model is uncertain on a given instance. Using the evidence-based framework, we discuss two reasons for uncertainty of a model: a model can be uncertain about an instance because it has strong, but conflicting evidence for both classes or it can be uncertain because it does not have enough evidence for either class. Our empirical evaluations on several real-world datasets show that distinguishing between these two types of uncertainties has a drastic impact on the learning efficiency. We further provide empirical and analytical justifications as to why distinguishing between the two uncertainties matters.},
    author   = {Sharma, Manali
                and Bilgic, Mustafa},
    day      = {01},
    doi      = {10.1007/s10618-016-0460-3},
    issn     = {1573-756X},
    journal  = {Data Mining and Knowledge Discovery},
    month    = {01},
    number   = {1},
    pages    = {164-202},
    title    = {Evidence-based uncertainty sampling for active learning},
    volume   = {31},
    year     = {2017}
}
@article{Sharma2020,
    author  = {Sharma, Siddharth and Sharma, Simone and Athaiya, Anidhya},
    doi     = {10.33564/IJEAST.2020.v04i12.054},
    journal = {International Journal of Engineering Applied Sciences and Technology},
    month   = {05},
    pages   = {310-316},
    title   = {ACTIVATION FUNCTIONS IN NEURAL NETWORKS},
    volume  = {04},
    year    = {2020}
}
@article{shen2015precipitation,
    abstract = {Abstract The ongoing changes in vegetation spring phenology in temperate/cold regions are widely attributed to temperature. However, in arid/semiarid ecosystems, the correlation between spring temperature and phenology is much less clear. We test the hypothesis that precipitation plays an important role in the temperature dependency of phenology in arid/semiarid regions. We therefore investigated the influence of preseason precipitation on satellite-derived estimates of starting date of vegetation growing season (SOS) across the Tibetan Plateau (TP). We observed two clear patterns linking precipitation to SOS. First, SOS is more sensitive to interannual variations in preseason precipitation in more arid than in wetter areas. Spatially, an increase in long-term averaged preseason precipitation of 10 mm corresponds to a decrease in the precipitation sensitivity of SOS by about 0.01 day mm−1. Second, SOS is more sensitive to variations in preseason temperature in wetter than in dryer areas of the plateau. A spatial increase in precipitation of 10 mm corresponds to an increase in temperature sensitivity of SOS of 0.25 day °C−1 (0.25 day SOS advance per 1 °C temperature increase). Those two patterns indicate both direct and indirect impacts of precipitation on SOS on TP. This study suggests a balance between maximizing benefit from the limiting climatic resource and minimizing the risk imposed by other factors. In wetter areas, the lower risk of drought allows greater temperature sensitivity of SOS to maximize the thermal benefit, which is further supported by the weaker interannual partial correlation between growing degree days and preseason precipitation. In more arid areas, maximizing the benefit of water requires greater sensitivity of SOS to precipitation, with reduced sensitivity to temperature. This study highlights the impacts of precipitation on SOS in a large cold and arid/semiarid region and suggests that influences of water should be included in SOS module of terrestrial ecosystem models for drylands.},
    author   = {Shen, Miaogen and Piao, Shilong and Cong, Nan and Zhang, Gengxin and Jassens, Ivan A},
    doi      = {10.1111/gcb.12961},
    eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/gcb.12961},
    journal  = {Global Change Biology},
    keywords = {climate change, precipitation, sensitivity, temperature, Tibetan Plateau, vegetation spring phenology},
    number   = {10},
    pages    = {3647-3656},
    title    = {Precipitation impacts on vegetation spring phenology on the Tibetan Plateau},
    volume   = {21},
    year     = {2015}
}
@article{shorten2019survey,
    abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
    author   = {Shorten, Connor
                and Khoshgoftaar, Taghi M.},
    day      = {06},
    doi      = {10.1186/s40537-019-0197-0},
    issn     = {2196-1115},
    journal  = {Journal of Big Data},
    month    = {07},
    number   = {1},
    pages    = {60},
    title    = {A survey on Image Data Augmentation for Deep Learning},
    volume   = {6},
    year     = {2019}
}
@article{shrivakshan2012comparison,
    author    = {Shrivakshan, GT and Chandrasekar, Chandramouli},
    journal   = {International Journal of Computer Science Issues (IJCSI)},
    number    = {5},
    pages     = {269},
    publisher = {Citeseer},
    title     = {A comparison of various edge detection techniques used in image processing},
    url       = {https://www.researchgate.net/publication/303142762_A_Comparison_of_various_Edge_Detection_Techniques_used_in_Image_Processing},
    volume    = {9},
    year      = {2012}
}
@inproceedings{shuai2016dag,
    author    = {Shuai, Bing and Zuo, Zhen and Wang, Bing and Wang, Gang},
    booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
    doi       = {10.48550/arXiv.1509.00552},
    pages     = {3620--3629},
    title     = {Dag-recurrent neural networks for scene labeling},
    year      = {2016}
}
@inproceedings{siam2018comparative,
    author    = {Siam, Mennatullah and Gamal, Mostafa and Abdel-Razek, Moemen and Yogamani, Senthil and Jagersand, Martin and Zhang, Hong},
    booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
    doi       = {10.1109/CVPRW.2018.00101},
    pages     = {587--597},
    title     = {A comparative study of real-time semantic segmentation for autonomous driving},
    year      = {2018}
}
@misc{Siddiqui_2020_CVPR,
    author    = {Siddiqui, Yawar and Valentin, Julien and Nießner, Matthias},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1911.11789},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {ViewAL: Active Learning with Viewpoint Entropy for Semantic Segmentation},
    year      = {2019}
}
@article{silver2009reinforcement,
    author  = {Silver, David},
    doi     = {10.7939/R39D8T},
    journal = {ERA},
    title   = {{Reinforcement Learning and Simulation-Based Search in Computer Go}},
    year    = {2009}
}
@article{silver2018general,
    abstract = {Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system. Science, this issue p. 1140; see also pp. 1087 and 1118 AlphaZero teaches itself to play three different board games and beats state-of-the-art programs in each. The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
    author   = {David Silver  and Thomas Hubert  and Julian Schrittwieser  and Ioannis Antonoglou  and Matthew Lai  and Arthur Guez  and Marc Lanctot  and Laurent Sifre  and Dharshan Kumaran  and Thore Graepel  and Timothy Lillicrap  and Karen Simonyan  and Demis Hassabis },
    doi      = {10.1126/science.aar6404},
    eprint   = {https://www.science.org/doi/pdf/10.1126/science.aar6404},
    journal  = {Science},
    number   = {6419},
    pages    = {1140-1144},
    title    = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
    volume   = {362},
    year     = {2018}
}
@inproceedings{song2015sun,
    author    = {Song, Shuran and Lichtenberg, Samuel P and Xiao, Jianxiong},
    booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
    pages     = {567--576},
    title     = {Sun rgb-d: A rgb-d scene understanding benchmark suite},
    url       = {https://rgbd.cs.princeton.edu},
    year      = {2015}
}
@misc{sorzano2014survey,
    author    = {Sorzano, C. O. S. and Vargas, J. and Montano, A. Pascual},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1403.2877},
    keywords  = {Machine Learning (stat.ML), Machine Learning (cs.LG), Quantitative Methods (q-bio.QM), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Biological sciences, FOS: Biological sciences},
    publisher = {arXiv},
    title     = {A survey of dimensionality reduction techniques},
    year      = {2014}
}
﻿@article{soyiri2013overview,
    abstract = {Health forecasting is a novel area of forecasting, and a valuable tool for predicting future health events or situations such as demands for health services and healthcare needs. It facilitates preventive medicine and health care intervention strategies, by pre-informing health service providers to take appropriate mitigating actions to minimize risks and manage demand. Health forecasting requires reliable data, information and appropriate analytical tools for the prediction of specific health conditions or situations. There is no single approach to health forecasting, and so various methods have often been adopted to forecast aggregate or specific health conditions. Meanwhile, there are no defined health forecasting horizons (time frames) to match the choices of health forecasting methods/approaches that are often applied. The key principles of health forecasting have not also been adequately described to guide the process. This paper provides a brief introduction and theoretical analysis of health forecasting. It describes the key issues that are important for health forecasting, including: definitions, principles of health forecasting, and the properties of health data, which influence the choices of health forecasting methods. Other matters related to the value of health forecasting, and  the general challenges associated with developing and using health forecasting services are discussed. This overview is a stimulus for further discussions on standardizing health forecasting approaches and methods that will facilitate health care and health services delivery.},
    author   = {Soyiri, Ireneous N.
                and Reidpath, Daniel D.},
    day      = {01},
    doi      = {10.1007/s12199-012-0294-6},
    issn     = {1347-4715},
    journal  = {Environmental Health and Preventive Medicine},
    month    = {01},
    number   = {1},
    pages    = {1-9},
    title    = {An overview of health forecasting},
    volume   = {18},
    year     = {2013}
}
@article{st1989analysis,
    abstract = {Univariate ANOVA is reviewed from a user point-of-view with emphasis on understanding the model building and the assumptions underlying the method. Illustrative examples are taken from organic chemistry and analytical chemistry. The use of graphical techniques to visualize the ANOVA model as well as to analyse residuals is recommended. The main models of ANOVA are developed in some detail including one-factor ANOVA, crossed designs, nested designs, repeated measures ANOVA and variance components estimation. Hypothesis testing by F-tests-and follow up by pairwise comparison methods is shown. The distinction between random effects and fixed effects is explained. Methods to handle non-linearities by transformations or by using response surface methodology are mentioned. Throughout the paper the importance of experimental design is emphasized. References are given to ANOVA methods for more complicated models.},
    author   = {Lars St»hle and Svante Wold},
    doi      = {https://doi.org/10.1016/0169-7439(89)80095-4},
    issn     = {0169-7439},
    journal  = {Chemometrics and Intelligent Laboratory Systems},
    number   = {4},
    pages    = {259-272},
    title    = {Analysis of variance (ANOVA)},
    volume   = {6},
    year     = {1989}
}
@article{STITT2016156,
    abstract = {Diabetic retinopathy is the most frequently occurring complication of diabetes mellitus and remains a leading cause of vision loss globally. Its aetiology and pathology have been extensively studied for half a century, yet there are disappointingly few therapeutic options. Although some new treatments have been introduced for diabetic macular oedema (DMO) (e.g. intravitreal vascular endothelial growth factor inhibitors (anti-VEGFs) and new steroids), up to 50{\%} of patients fail to respond. Furthermore, for people with proliferative diabetic retinopathy (PDR), laser photocoagulation remains a mainstay therapy, even though it is an inherently destructive procedure. This review summarises the clinical features of diabetic retinopathy and its risk factors. It describes details of retinal pathology and how advances in our understanding of pathogenesis have led to identification of new therapeutic targets. We emphasise that although there have been significant advances, there is still a pressing need for a better understanding basic mechanisms enable development of reliable and robust means to identify patients at highest risk, and to intervene effectively before vision loss occurs.},
    author   = {Alan W. Stitt and Timothy M. Curtis and Mei Chen and Reinhold J. Medina and Gareth J. McKay and Alicia Jenkins and Thomas A. Gardiner and Timothy J. Lyons and Hans-Peter Hammes and Rafael Simó and Noemi Lois},
    doi      = {10.1016/j.preteyeres.2015.08.001},
    issn     = {1350-9462},
    journal  = {Progress in Retinal and Eye Research},
    keywords = {Diabetic retinopathy, Diabetic macular oedema, Diabetes, Retina, Pathogenesis},
    pages    = {156-186},
    title    = {The progress in understanding and treatment of diabetic retinopathy},
    volume   = {51},
    year     = {2016}
}
@article{su2012linear,
    author    = {Su, Xiaogang and Yan, Xin and Tsai, Chih-Ling},
    doi       = {10.1002/wics.1198},
    journal   = {Wiley Interdisciplinary Reviews: Computational Statistics},
    number    = {3},
    pages     = {275--294},
    publisher = {Wiley Online Library},
    title     = {Linear regression},
    volume    = {4},
    year      = {2012}
}
@article{SU2021106418,
    abstract = {Deep learning methods such as convolutional neural networks (CNN) have become popular for addressing crops and weeds classification problems in agricultural robotics. However, to have satisfactory performance and avoid overfitting, training deep neural nets typically requires thousands of labeled images. This leads to tedious pixelwise labeling for semantic segmentation. In this paper, we hinge on the recent development in data augmentation and utilize the concept further for semantic segmentation and classification of crops and weeds. To be specific, we propose a novel data augmentation framework, based on the random image cropping and patching (RICAP) method, which is originally designed to augment data for generic image classification. The proposed framework introduces novel enhancements to the original RICAP so that it can be effectively used for data augmentation of semantic segmentation tasks. We evaluate the proposed methodology on two datasets from different farms. Comprehensive experimental evaluations and ablation studies show that the proposed framework can effectively improve segmentation accuracies, and the enhancements made over the original RICAP actually contribute to the performance gain. On average, the proposed method increases the mean accuracy and mean intersection over union (IOU) of the deep neural net with the conventional data augmentation (random flipping, rotation and colour jitter) from 91.01 to 94.02 and from 63.59 to 70.77 respectively for Narrabri dataset, and from 97.99 to 98.51 and from 74.26 to 77.09 respectively for Bonn dataset. The limitation of the proposed method, especially when a large number of training data is available, has also been discussed.},
    author   = {Daobilige Su and He Kong and Yongliang Qiao and Salah Sukkarieh},
    doi      = {10.1016/j.compag.2021.106418},
    issn     = {0168-1699},
    journal  = {Computers and Electronics in Agriculture},
    keywords = {Data augmentation, Deep learning, Semantic segmentation, Agricultural robot, Crop weed classification},
    pages    = {106418},
    title    = {Data augmentation for deep learning based semantic segmentation and crop-weed classification in agricultural robotics},
    volume   = {190},
    year     = {2021}
}
@article{subramanian2019simulation,
    abstract = {In this article, we present a multispecies reaction--advection--diffusion partial differential equation coupled with linear elasticity for modeling tumor growth. The model aims to capture the phenomenological features of glioblastoma multiforme observed in magnetic resonance imaging (MRI) scans. These include enhancing and necrotic tumor structures, brain edema and the so-called ``mass effect'', a term-of-art that refers to the deformation of brain tissue due to the presence of the tumor. The multispecies model accounts for proliferating, invasive and necrotic tumor cells as well as a simple model for nutrition consumption and tumor-induced brain edema. The coupling of the model with linear elasticity equations with variable coefficients allows us to capture the mechanical deformations due to the tumor growth on surrounding tissues. We present the overall formulation along with a novel operator-splitting scheme with components that include linearly-implicit preconditioned elliptic solvers, and a semi-Lagrangian method for advection. We also present results showing simulated MRI images which highlight the capability of our method to capture the overall structure of glioblastomas in MRIs.},
    author   = {Subramanian, Shashank
                and Gholami, Amir
                and Biros, George},
    day      = {01},
    doi      = {10.1007/s00285-019-01383-y},
    issn     = {1432-1416},
    journal  = {Journal of Mathematical Biology},
    month    = {08},
    number   = {3},
    pages    = {941-967},
    title    = {Simulation of glioblastoma growth using a 3D multispecies tumor model with mass effect},
    volume   = {79},
    year     = {2019}
}
@incollection{Sudre_2017,
    author    = {Carole H. Sudre and Wenqi Li and Tom Vercauteren and Sebastien Ourselin and M. Jorge Cardoso},
    booktitle = {Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support},
    doi       = {10.1007/978-3-319-67558-9_28},
    pages     = {240--248},
    publisher = {Springer International Publishing},
    title     = {Generalised Dice Overlap as a Deep Learning Loss Function for Highly Unbalanced Segmentations},
    year      = 2017
}
@inproceedings{Sun_2019_CVPR,
    author    = {Sun, Ruoqi and Zhu, Xinge and Wu, Chongruo and Huang, Chen and Shi, Jianping and Ma, Lizhuang},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {06},
    title     = {Not All Areas Are Equal: Transfer Learning for Semantic Segmentation via Hierarchical Region Selection},
    url       = {https://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Not_All_Areas_Are_Equal_Transfer_Learning_for_Semantic_Segmentation_CVPR_2019_paper.html},
    year      = {2019}
}

@article{Sun_Feng_Saenko_2016,
    abstractnote = { &lt;p&gt; Unlike human learning, machine learning often fails to handle changes between training (source) and test (target) input distributions. Such domain shifts, common in practical scenarios, severely damage the performance of conventional machine learning methods. Supervised domain adaptation methods have been proposed for the case when the target data have labels, including some that perform very well despite being ``frustratingly easy’’ to implement. However, in practice, the target domain is often unlabeled, requiring unsupervised adaptation. We propose a simple, effective, and efficient method for unsupervised domain adaptation called CORrelation ALignment (CORAL). CORAL minimizes domain shift by aligning the second-order statistics of source and target distributions, without requiring any target labels. Even though it is extraordinarily simple--it can be implemented in four lines of Matlab code--CORAL performs remarkably well in extensive evaluations on standard benchmark datasets. &lt;/p&gt; },
    author       = {Sun, Baochen and Feng, Jiashi and Saenko, Kate},
    doi          = {10.1609/aaai.v30i1.10306},
    journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
    month        = {03},
    number       = {1},
    title        = {Return of Frustratingly Easy Domain Adaptation},
    volume       = {30},
    year         = {2016}
}
@book{szeliski2022computer,
    author    = {Szeliski, Richard},
    publisher = {Springer Nature},
    title     = {Computer vision: algorithms and applications},
    year      = {2022}
}
@article{Taha2015-ok,
    abstract = {BACKGROUND: Medical Image segmentation is an important image
                processing step. Comparing images to evaluate the quality of
                segmentation is an essential part of measuring progress in this
                research area. Some of the challenges in evaluating medical
                segmentation are: metric selection, the use in the literature of
                multiple definitions for certain metrics, inefficiency of the
                metric calculation implementations leading to difficulties with
                large volumes, and lack of support for fuzzy segmentation by
                existing metrics. RESULT: First we present an overview of 20
                evaluation metrics selected based on a comprehensive literature
                review. For fuzzy segmentation, which shows the level of
                membership of each voxel to multiple classes, fuzzy definitions
                of all metrics are provided. We present a discussion about metric
                properties to provide a guide for selecting evaluation metrics.
                Finally, we propose an efficient evaluation tool implementing the
                20 selected metrics. The tool is optimized to perform efficiently
                in terms of speed and required memory, also if the image size is
                extremely large as in the case of whole body MRI or CT volume
                segmentation. An implementation of this tool is available as an
                open source project. CONCLUSION: We propose an efficient
                evaluation tool for 3D medical image segmentation using 20
                evaluation metrics and provide guidelines for selecting a subset
                of these metrics that is suitable for the data and the
                segmentation task.},
    address  = {England},
    author   = {Taha, Abdel Aziz and Hanbury, Allan},
    doi      = {10.1186/s12880-015-0068-x},
    journal  = {BMC Med Imaging},
    language = {en},
    month    = aug,
    pages    = {29},
    title    = {Metrics for evaluating {3D} medical image segmentation: analysis,
                selection, and tool},
    volume   = 15,
    year     = 2015
}
@article{tanzi2021real,
    abstract = {The current study aimed to propose a Deep Learning (DL) and Augmented Reality (AR) based solution for a in-vivo robot-assisted radical prostatectomy (RARP), to improve the precision of a published work from our group. We implemented a two-steps automatic system to align a 3D virtual ad-hoc model of a patient's organ with its 2D endoscopic image, to assist surgeons during the procedure.},
    author   = {Tanzi, Leonardo
                and Piazzolla, Pietro
                and Porpiglia, Francesco
                and Vezzetti, Enrico},
    day      = {01},
    doi      = {10.1007/s11548-021-02432-y},
    issn     = {1861-6429},
    journal  = {International Journal of Computer Assisted Radiology and Surgery},
    month    = {09},
    number   = {9},
    pages    = {1435-1445},
    title    = {Real-time deep learning semantic segmentation during intra-operative surgery for 3D augmented reality assistance},
    volume   = {16},
    year     = {2021}
}
@inproceedings{taylor2018improving,
    author    = {Taylor, Luke and Nitschke, Geoff},
    booktitle = {2018 IEEE Symposium Series on Computational Intelligence (SSCI)},
    doi       = {10.1109/SSCI.2018.8628742},
    number    = {},
    pages     = {1542-1547},
    title     = {Improving Deep Learning with Generic Data Augmentation},
    volume    = {},
    year      = {2018}
}
@article{thanoon2015robust,
    author    = {Thanoon, Firas H.},
    doi       = {10.5923/j.statistics.20150503.02},
    issn      = {2168-5215},
    journal   = {International Journal of Statistics and Applications},
    number    = {3},
    pages     = {109--112},
    publisher = {Scientific {\&} Academic Publishing},
    title     = {{Robust Regression by Least Absolute Deviations Method}},
    volume    = {5},
    year      = {2015}
}

@article{todua2013multiple,
    author  = {Todua, Nugzar and Babilua, Petre and Dochviri, Teona},
    journal = {Bull. Georg. Natl. Acad. Sci},
    number  = {3},
    pages   = {135--139},
    title   = {On the multiple linear regression in marketing research},
    url     = {https://www.researchgate.net/publication/260361577_On_the_Multiple_Linear_Regression_in_Marketing_Research},
    volume  = {7},
    year    = {2013}
}
@inbook{tommasi2017deeper,
    abstract  = {The presence of a bias in each image data collection has recently attracted a lot of attention in the computer vision community showing the limits in generalization of any learning method trained on a specific dataset. At the same time, with the rapid development of deep learning architectures, the activation values of Convolutional Neural Networks (CNN) are emerging as reliable and robust image descriptors. In this chapter we propose to verify the potential of the CNN features when facing the dataset biasDataset biasproblem. With this purpose we introduce a large testbed for cross-dataset analysis and we discuss the challenges faced to create two comprehensive experimental setups by aligning twelve existing image databases. We conduct a series of analyses looking at how the datasets differ among each other and verifying the performance of existing debiasing methods under different representations. We learn important lessons on which part of the dataset bias problem can be considered solved and which open questions still need to be tackled.},
    address   = {Cham},
    author    = {Tommasi, Tatiana
                 and Patricia, Novi
                 and Caputo, Barbara
                 and Tuytelaars, Tinne},
    booktitle = {Domain Adaptation in Computer Vision Applications},
    doi       = {10.1007/978-3-319-58347-1_2},
    editor    = {Csurka, Gabriela},
    isbn      = {978-3-319-58347-1},
    pages     = {37--55},
    publisher = {Springer International Publishing},
    title     = {A Deeper Look at Dataset Bias},
    year      = {2017}
}
@article{tong2001support,
    author  = {TONG, S.},
    journal = {Proc. Seventeenth International Conference on Machine Learning, 2000},
    title   = {Support vector machine active learning with applications to text classification},
    url     = {https://cir.nii.ac.jp/crid/1574231874012815360},
    year    = {2000}
}
@article{treml2016speeding,
    author  = {Treml, Michael and Arjona-Medina, Jos{\ifmmode\acute{e}\else\'{e}\fi} and Unterthiner, Thomas and Durgesh, Rupesh and Friedmann, Felix and Schuberth, Peter and Mayr, Andreas and Heusel, Martin and Hofmarcher, Markus and Widrich, Michael and Nessler, Bernhard and Hochreiter, Sepp},
    journal = {OpenReview},
    month   = {10},
    title   = {{Speeding up Semantic Segmentation for Autonomous Driving}},
    url     = {https://openreview.net/forum?id=S1uHiFyyg},
    year    = {2016}
}
@incollection{tsien1998using,
    author    = {Tsien, Christine L. and Fraser, Hamish S. F. and Long, William J. and Kennedy, R. Lee},
    booktitle = {{MEDINFO '98}},
    doi       = {10.3233/978-1-60750-896-0-493},
    pages     = {493--497},
    publisher = {IOS Press},
    title     = {{Using Classification Tree and Logistic Regression Methods to Diagnose Myocardial Infarction}},
    year      = {1998}
}
@article{turchenko2017deep,
    author     = {Volodymyr Turchenko and
                  Eric Chalmers and
                  Artur Luczak},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/TurchenkoCL17.bib},
    doi        = {10.48550/arXiv.1701.04949},
    eprint     = {1701.04949},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Mon, 13 Aug 2018 16:47:34 +0200},
    title      = {A Deep Convolutional Auto-Encoder with Pooling - Unpooling Layers
                  in Caffe},
    volume     = {abs/1701.04949},
    year       = {2017}
}
@article{tversky1977features,
    author    = {Tversky, Amos},
    doi       = {10.1037/0033-295X.84.4.327},
    journal   = {Psychological review},
    number    = {4},
    pages     = {327},
    publisher = {American Psychological Association},
    title     = {Features of similarity.},
    volume    = {84},
    year      = {1977}
}
@misc{tzeng2014deep,
    author    = {Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.1412.3474},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Deep Domain Confusion: Maximizing for Domain Invariance},
    year      = {2014}
}
@article{Uddin2022,
    abstract = {Disease risk prediction is a rising challenge in the medical domain. Researchers have widely used machine learning algorithms to solve this challenge. The k-nearest neighbour (KNN) algorithm is the most frequently used among the wide range of machine learning algorithms. This paper presents a study on different KNN variants (Classic one, Adaptive, Locally adaptive, k-means clustering, Fuzzy, Mutual, Ensemble, Hassanat and Generalised mean distance) and their performance comparison for disease prediction. This study analysed these variants in-depth through implementations and experimentations using eight machine learning benchmark datasets obtained from Kaggle, UCI Machine learning repository and OpenML. The datasets were related to different disease contexts. We considered the performance measures of accuracy, precision and recall for comparative analysis. The average accuracy values of these variants ranged from 64.22{\%} to 83.62{\%}. The Hassanaat KNN showed the highest average accuracy (83.62{\%}), followed by the ensemble approach KNN (82.34{\%}). A relative performance index is also proposed based on each performance measure to assess each variant and compare the results. This study identified Hassanat KNN as the best performing variant based on the accuracy-based version of this index, followed by the ensemble approach KNN. This study also provided a relative comparison among KNN variants based on precision and recall measures. Finally, this paper summarises which KNN variant is the most promising candidate to follow under the consideration of three performance measures (accuracy, precision and recall) for disease prediction. Healthcare researchers and stakeholders could use the findings of this study to select the appropriate KNN variant for predictive disease risk analytics.},
    author   = {Uddin, Shahadat
                and Haque, Ibtisham
                and Lu, Haohui
                and Moni, Mohammad Ali
                and Gide, Ergun},
    day      = {15},
    doi      = {10.1038/s41598-022-10358-x},
    issn     = {2045-2322},
    journal  = {Scientific Reports},
    month    = {4},
    number   = {1},
    pages    = {6256},
    title    = {Comparative performance analysis of K-nearest neighbour (KNN) algorithm and its different variants for disease prediction},
    volume   = {12},
    year     = {2022}
}

@article{unsupervisedLearning1,
    author = {Siadati, Saman},
    doi    = {10.13140/RG.2.2.33325.10720},
    month  = {08},
    pages  = {},
    title  = {What is unsupervised Learning},
    year   = {2018}
}
@misc{vaihingenISPRS,
    month     = mar,
    note      = {[Online; accessed 14. Mar. 2023]},
    publisher = {ISPRS - International Society for Photogrammetry and Remote Sensing},
    title     = {{2D Semantic Label. - Vaihingen}},
    url       = {https://www.isprs.org/education/benchmarks/UrbanSemLab/2d-sem-label-vaihingen.aspx},
    year      = {2023}
}
@inproceedings{vamseekrishna2021prediction,
    abstract  = {In this paper, we analyze and predict the temperature and humidity using IoT and linear regression algorithm in machine learning. In ancient days, people use to check the climate conditions by seeing clouds or through storm warnings or by using animals they have noticed the weather conditions for many purposes like harvesting and involves many household activities. To overcome this situation, weather forecasting was found. We collect the temperature and humidity data in various places for few days using Message Queuing Telemetry Transport (MQTT) protocol. So, we initialize the collected data for 5 days in Amazon Web services (AWS) cloud. This data is stored in AWS and by using Dynamo Database (DynamoDB) the stored data is created in the form of the table and it is exported to .csv file. Hence, the data is recorded. Now by using linear regression algorithm in machine learning, we predict the temperature and humidity data. People can therefore easily monitor the weather conditions without eagerly waiting for tomorrow. This makes more easy and comfortable way to the people so that they will be able to know the climatic conditions within a short period of time.},
    address   = {Singapore},
    author    = {Vamseekrishna, A.
                 and Nishitha, R.
                 and Kumar, T. Anil
                 and Hanuman, K.
                 and Supriya, Ch. G.},
    booktitle = {International Conference on Intelligent and Smart Computing in Data Analytics},
    doi       = {10.1007/978-981-33-6176-8_30},
    editor    = {Bhattacharyya, Siddhartha
                 and Nayak, Janmenjoy
                 and Prakash, Kolla Bhanu
                 and Naik, Bighnaraj
                 and Abraham, Ajith},
    isbn      = {978-981-33-6176-8},
    pages     = {271--279},
    publisher = {Springer Singapore},
    title     = {Prediction of Temperature and Humidity Using IoT and Machine Learning Algorithm},
    year      = {2021}
}

@article{van_Hasselt_Guez_Silver_2016,
    abstractnote = { &lt;p&gt; The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games. &lt;/p&gt; },
    author       = {van Hasselt, Hado and Guez, Arthur and Silver, David},
    doi          = {10.1609/aaai.v30i1.10295},
    journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
    month        = {03},
    number       = {1},
    title        = {Deep Reinforcement Learning with Double Q-Learning},
    volume       = {30},
    year         = {2016}
}
@article{van2003noise,
    author  = {Van De Ville, D. and Nachtegael, M. and Van der Weken, D. and Kerre, E.E. and Philips, W. and Lemahieu, I.},
    doi     = {10.1109/TFUZZ.2003.814830},
    journal = {IEEE Transactions on Fuzzy Systems},
    number  = {4},
    pages   = {429-436},
    title   = {Noise reduction by fuzzy image filtering},
    volume  = {11},
    year    = {2003}
}
@inproceedings{van2013reinforcement,
    author    = {van der Ree, Michiel and Wiering, Marco},
    booktitle = {2013 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)},
    doi       = {10.1109/ADPRL.2013.6614996},
    number    = {},
    pages     = {108-115},
    title     = {Reinforcement learning in the game of Othello: Learning against a fixed opponent and learning from self-play},
    volume    = {},
    year      = {2013}
}
@article{van2016deep,
    author  = {van Hasselt, Hado and Guez, Arthur and Silver, David},
    doi     = {10.1609/aaai.v30i1.10295},
    issn    = {2374-3468},
    journal = {AAAI},
    month   = mar,
    number  = {1},
    title   = {{Deep Reinforcement Learning with Double Q-Learning}},
    volume  = {30},
    year    = {2016}
}
@article{van2020survey,
    abstract = {Semi-supervised learning is the branch of machine learning concerned with using labelled as well as unlabelled data to perform certain learning tasks. Conceptually situated between supervised and unsupervised learning, it permits harnessing the large amounts of unlabelled data available in many use cases in combination with typically smaller sets of labelled data. In recent years, research in this area has followed the general trends observed in machine learning, with much attention directed at neural network-based models and generative learning. The literature on the topic has also expanded in volume and scope, now encompassing a broad spectrum of theory, algorithms and applications. However, no recent surveys exist to collect and organize this knowledge, impeding the ability of researchers and engineers alike to utilize it. Filling this void, we present an up-to-date overview of semi-supervised learning methods, covering earlier work as well as more recent advances. We focus primarily on semi-supervised classification, where the large majority of semi-supervised learning research takes place. Our survey aims to provide researchers and practitioners new to the field as well as more advanced readers with a solid understanding of the main approaches and algorithms developed over the past two decades, with an emphasis on the most prominent and currently relevant work. Furthermore, we propose a new taxonomy of semi-supervised classification algorithms, which sheds light on the different conceptual and methodological approaches for incorporating unlabelled data into the training process. Lastly, we show how the fundamental assumptions underlying most semi-supervised learning algorithms are closely connected to each other, and how they relate to the well-known semi-supervised clustering assumption.},
    author   = {van Engelen, Jesper E.
                and Hoos, Holger H.},
    day      = {01},
    doi      = {10.1007/s10994-019-05855-6},
    issn     = {1573-0565},
    journal  = {Machine Learning},
    month    = {Feb},
    number   = {2},
    pages    = {373-440},
    title    = {A survey on semi-supervised learning},
    volume   = {109},
    year     = {2020}
}
@inproceedings{vaswani2017attention,
    author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
    booktitle = {Advances in Neural Information Processing Systems},
    doi       = {10.48550/arXiv.1706.03762},
    editor    = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {Attention is All you Need},
    volume    = {30},
    year      = {2017}
}
@article{vergara2014review,
    abstract = {In this work, we present a review of the state of the art of information-theoretic feature selection methods. The concepts of feature relevance, redundance, and complementarity (synergy) are clearly defined, as well as Markov blanket. The problem of optimal feature selection is defined. A unifying theoretical framework is described, which can retrofit successful heuristic criteria, indicating the approximations made by each method. A number of open problems in the field are presented.},
    author   = {Vergara, Jorge R.
                and Est{\'e}vez, Pablo A.},
    day      = {01},
    doi      = {10.1007/s00521-013-1368-0},
    issn     = {1433-3058},
    journal  = {Neural Computing and Applications},
    month    = {01},
    number   = {1},
    pages    = {175-186},
    title    = {A review of feature selection methods based on mutual information},
    volume   = {24},
    year     = {2014}
}
@article{Verma2020,
    abstract = {Jaccard index, originally proposed by Jaccard (Bull Soc Vaudoise Sci Nat 37:241--272, 1901), is a measure for examining the similarity (or dissimilarity) between two sample data objects. It is defined as the proportion of the intersection size to the union size of the two data samples. It provides a very simple and intuitive measure of similarity between data samples. This research examines the measures that are akin to the Jaccard index and may be used for modelling affinity between users (or items) in collaborative recommendations. Particularly, the measures such as simple matching coefficient (SMC), Sorensen--Dice coefficient (SDC), Salton's cosine index (SCI), and overlap coefficient (OLC) are compared and analysed in both theoretical and empirical perspectives with respect to the Jaccard index. Since these measures apprehend only the structural similarity information (overlapping information) between the data samples, these are very useful in situations where only the associations between users and items are available such as browsing or buying behaviours of the users on an e-commerce portal (i.e. unary rating data, a special case of ratings). Furthermore, a theoretical relation among these measures has been established. We have also derived an equivalent expression for each of these measures so that it can be directly applied for binary data samples in data mining/machine learning jargon. In order to compare and validate the effectiveness of these structural similarity measures, several experiments have been conducted using standardized benchmark datasets (MovieLens, FilmTrust, Epinions, Yahoo! Movies, and Yahoo! Music). Empirically obtained results demonstrate that the Salton's cosine index (SCI) provides better accuracy (in terms of MAE, RMSE, and precision) for large datasets, whereas the overlap coefficient (OLC) results in more accurate recommendations for small datasets.},
    author   = {Verma, Vijay
                and Aggarwal, Rajesh Kumar},
    day      = {09},
    doi      = {10.1007/s13278-020-00660-9},
    issn     = {1869-5469},
    journal  = {Social Network Analysis and Mining},
    month    = {06},
    number   = {1},
    pages    = {43},
    title    = {A comparative analysis of similarity measures akin to the Jaccard index in collaborative recommendations: empirical and theoretical perspective},
    volume   = {10},
    year     = {2020}
}
@article{vogelstein2014discovery,
    abstract = {Mapping functional neural circuits for many behaviors has been almost impossible, so Vogelstein et al. (p. 386, published online 27 March; see the Perspective by O'Leary and Marder) developed a broadly applicable optogenetic method for neuron-behavior mapping and used it to phenotype larval Drosophila and thus developed a reference atlas. As optogenetic experiments become routine in certain fields of neuroscience research, creating even more specialized tools is imperative (see the Perspective by Hayashi). By engineering channelrhodopsin, Wietek et al. (p. 409, published online 27 March) and Berndt et al. (p. 420) created two different light-gated anion channels to block action potential generation during synaptic stimulation or depolarizing current injections. These new tools not only improve understanding of channelrhodopsins but also provide a way to silence cells. An atlas is generated to reveal activation of which specific neurons in a Drosophila larva produce specific behaviors. [Also see Perspective by O'Leary and Marder] A single nervous system can generate many distinct motor patterns. Identifying which neurons and circuits control which behaviors has been a laborious piecemeal process, usually for one observer-defined behavior at a time. We present a fundamentally different approach to neuron-behavior mapping. We optogenetically activated 1054 identified neuron lines in Drosophila larvae and tracked the behavioral responses from 37,780 animals. Application of multiscale unsupervised structure learning methods to the behavioral data enabled us to identify 29 discrete, statistically distinguishable, observer-unbiased behavioral phenotypes. Mapping the neural lines to the behavior(s) they evoke provides a behavioral reference atlas for neuron subsets covering a large fraction of larval neurons. This atlas is a starting point for connectivity- and activity-mapping studies to further investigate the mechanisms by which neurons mediate diverse behaviors.},
    author   = {Joshua T. Vogelstein  and Youngser Park  and Tomoko Ohyama  and Rex A. Kerr  and James W. Truman  and Carey E. Priebe  and Marta Zlatic },
    doi      = {10.1126/science.1250298},
    eprint   = {https://www.science.org/doi/pdf/10.1126/science.1250298},
    journal  = {Science},
    number   = {6182},
    pages    = {386-392},
    title    = {Discovery of Brainwide Neural-Behavioral Maps via Multiscale Unsupervised Structure Learning},
    volume   = {344},
    year     = {2014}
}
@article{Voulodimos2018,
    abstract  = {Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields, with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, Convolutional Neural Networks, Deep Boltzmann Machines and Deep Belief Networks, and Stacked Denoising Autoencoders. A brief account of their history, structure, advantages, and limitations is given, followed by a description of their applications in various computer vision tasks, such as object detection, face recognition, action and activity recognition, and human pose estimation. Finally, a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.},
    author    = {Voulodimos, Athanasios
                 and Doulamis, Nikolaos
                 and Doulamis, Anastasios
                 and Protopapadakis, Eftychios},
    day       = {01},
    doi       = {10.1155/2018/7068349},
    issn      = {1687-5265},
    journal   = {Computational Intelligence and Neuroscience},
    month     = {02},
    pages     = {7068349},
    publisher = {Hindawi},
    title     = {Deep Learning for Computer Vision: A Brief Review},
    volume    = {2018},
    year      = {2018}
}
@inproceedings{wada2019joint,
    author    = {Wada, Kentaro and Okada, Kei and Inaba, Masayuki},
    booktitle = {2019 International Conference on Robotics and Automation (ICRA)},
    doi       = {10.1109/ICRA.2019.8793783},
    number    = {},
    pages     = {9558-9564},
    title     = {Joint Learning of Instance and Semantic Segmentation for Robotic Pick-and-Place with Heavy Occlusions in Clutter},
    volume    = {},
    year      = {2019}
}
@inproceedings{wan2014deep,
    abstract  = {Learning effective feature representations and similarity measures are crucial to the retrieval performance of a content-based image retrieval (CBIR) system. Despite extensive research efforts for decades, it remains one of the most challenging open problems that considerably hinders the successes of real-world CBIR systems. The key challenge has been attributed to the well-known ``semantic gap'' issue that exists between low-level image pixels captured by machines and high-level semantic concepts perceived by human. Among various techniques, machine learning has been actively investigated as a possible direction to bridge the semantic gap in the long term. Inspired by recent successes of deep learning techniques for computer vision and other applications, in this paper, we attempt to address an open problem: if deep learning is a hope for bridging the semantic gap in CBIR and how much improvements in CBIR tasks can be achieved by exploring the state-of-the-art deep learning techniques for learning feature representations and similarity measures. Specifically, we investigate a framework of deep learning with application to CBIR tasks with an extensive set of empirical studies by examining a state-of-the-art deep learning method (Convolutional Neural Networks) for CBIR tasks under varied settings. From our empirical studies, we find some encouraging results and summarize some important insights for future research.},
    author    = {Wan, Ji and Wang, Dayong and Hoi, Steven Chu Hong and Wu, Pengcheng and Zhu, Jianke and Zhang, Yongdong and Li, Jintao},
    booktitle = {Proceedings of the 22nd ACM International Conference on Multimedia},
    doi       = {10.1145/2647868.2654948},
    isbn      = {9781450330633},
    keywords  = {convolutional neural networks, content-based image retrieval, feature representation, deep learning},
    location  = {Orlando, Florida, USA},
    numpages  = {10},
    pages     = {157–166},
    publisher = {Association for Computing Machinery},
    series    = {MM '14},
    title     = {Deep Learning for Content-Based Image Retrieval: A Comprehensive Study},
    year      = {2014}
}
@article{wan2021fine,
    author  = {Wan, Jia and Kumar, Nikil Senthil and Chan, Antoni B.},
    doi     = {10.1109/TIP.2021.3049938},
    journal = {IEEE Transactions on Image Processing},
    number  = {},
    pages   = {2114-2126},
    title   = {Fine-Grained Crowd Counting},
    volume  = {30},
    year    = {2021}
}
@article{Wang_2018,
    abstract = {Deep domain adaptation has emerged as a new learning technique to address the lack of massive amounts of labeled data. Compared to conventional methods, which learn shared feature subspaces or reuse important source instances with shallow representations, deep domain adaptation methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning. There have been comprehensive surveys for shallow domain adaptation, but few timely reviews the emerging deep learning based methods. In this paper, we provide a comprehensive survey of deep domain adaptation methods for computer vision applications with four major contributions. First, we present a taxonomy of different deep domain adaptation scenarios according to the properties of data that define how two domains are diverged. Second, we summarize deep domain adaptation approaches into several categories based on training loss, and analyze and compare briefly the state-of-the-art methods under these categories. Third, we overview the computer vision applications that go beyond image classification, such as face recognition, semantic segmentation and object detection. Fourth, some potential deficiencies of current methods and several future directions are highlighted.},
    author   = {Mei Wang and Weihong Deng},
    issn     = {0925-2312},
    journal  = {Neurocomputing},
    keywords = {Deep domain adaptation, Deep networks, Transfer learning, Computer vision applications},
    pages    = {135-153},
    title    = {Deep visual domain adaptation: A survey},
    volume   = {312},
    year     = {2018},
    doi = {10.1016/j.neucom.2018.05.083}
}
@article{Wang_2020_CVPR,
    author     = {Yude Wang and
                  Jie Zhang and
                  Meina Kan and
                  Shiguang Shan and
                  Xilin Chen},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-2004-04581.bib},
    doi        = {10.48550/arXiv.2004.04581},
    eprint     = {2004.04581},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Thu, 02 Dec 2021 17:27:17 +0100},
    title      = {Self-supervised Equivariant Attention Mechanism for Weakly Supervised
                  Semantic Segmentation},
    volume     = {abs/2004.04581},
    year       = {2020}
}
@article{Wang_2020_CVPR,
    author     = {Yan Wang and
                  Xu Wei and
                  Fengze Liu and
                  Jieneng Chen and
                  Yuyin Zhou and
                  Wei Shen and
                  Elliot K. Fishman and
                  Alan L. Yuille},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1912-03383.bib},
    doi        = {10.48550/arXiv.1912.03383},
    eprint     = {1912.03383},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Thu, 02 Jan 2020 18:08:18 +0100},
    title      = {Deep Distance Transform for Tubular Structure Segmentation in {CT}
                  Scans},
    volume     = {abs/1912.03383},
    year       = {2019}
}
@inproceedings{wang2017uncertainty,
    author    = {Wang, Gaoang and Hwang, Jenq-Neng and Rose, Craig and Wallace, Farron},
    booktitle = {2017 IEEE 19th International Workshop on Multimedia Signal Processing (MMSP)},
    doi       = {10.1109/MMSP.2017.8122269},
    number    = {},
    pages     = {1-6},
    title     = {Uncertainty sampling based active learning with diversity constraint by sparse selection},
    volume    = {},
    year      = {2017}
}
@article{WANG2021102579,
    abstract = {Magnetic resonance imaging is a powerful imaging modality that can provide versatile information. However, it has a fundamental challenge that is time consuming to acquire images with high quality and high resolution. Reducing the scanned measurements can significantly accelerate its speed with the aid of the powerful reconstruction methods, which has evolved from linear analytic reconstructions to nonlinear iterative ones. The emerging trend in this area is replacing human-defined signal models with that learned from data. Specifically, from 2016, deep learning has been incorporated into the fast MR imaging task, which draws valuable prior knowledge from big datasets to facilitate accurate MR image reconstruction from limited measurements. Many researchers believed this started a new era of fast MR imaging techniques, namely learning reconstruction. This survey aims to review the main works in accelerating MR imaging with deep learning and will discuss merits, limitations and challenges associated with such methods. Last but not least, this paper will provide a starting point for researchers interested in contributing to this field by pointing out good tutorial resources, state-of-the-art open-source codes and meaningful data sources.},
    author   = {Shanshan Wang and Taohui Xiao and Qiegen Liu and Hairong Zheng},
    doi      = {10.1016/j.bspc.2021.102579},
    issn     = {1746-8094},
    journal  = {Biomedical Signal Processing and Control},
    keywords = {Deep learning, MRI, Undersampled image reconstruction},
    pages    = {102579},
    title    = {Deep learning for fast MR imaging: A review for learning reconstruction from incomplete k-space data},
    volume   = {68},
    year     = {2021}
}
@article{WANG2022102259,
    abstract = {In this paper, we present a Deep Convolutional Neural Networks (CNNs) for fully automatic brain tumor segmentation for both high- and low-grade gliomas in MRI images. Unlike normal tissues or organs that usually have a fixed location or shape, brain tumors with different grades have shown great variation in terms of the location, size, structure, and morphological appearance. Moreover, the severe data imbalance exists not only between the brain tumor and non-tumor tissues, but also among the different sub-regions inside brain tumor (e.g., enhancing tumor, necrotic, edema, and non-enhancing tumor). Therefore, we introduce a hybrid model to address the challenges in the multi-modality multi-class brain tumor segmentation task. First, we propose the dynamic focal Dice loss function that is able to focus more on the smaller tumor sub-regions with more complex structures during training, and the learning capacity of the model is dynamically distributed to each class independently based on its training performance in different training stages. Besides, to better recognize the overall structure of the brain tumor and the morphological relationship among different tumor sub-regions, we relax the boundary constraints for the inner tumor regions in coarse-to-fine fashion. Additionally, a symmetric attention branch is proposed to highlight the possible location of the brain tumor from the asymmetric features caused by growth and expansion of the abnormal tissues in the brain. Generally, to balance the learning capacity of the model between spatial details and high-level morphological features, the proposed model relaxes the constraints of the inner boundary and complex details and enforces more attention on the tumor shape, location, and the harder classes of the tumor sub-regions. The proposed model is validated on the publicly available brain tumor dataset from real patients, BRATS 2019. The experimental results reveal that our model improves the overall segmentation performance in comparison with the state-of-the-art methods, with major progress on the recognition of the tumor shape, the structural relationship of tumor sub-regions, and the segmentation of more challenging tumor sub-regions, e.g., the tumor core, and enhancing tumor.},
    author   = {Pei Wang and Albert C.S. Chung},
    doi      = {10.1016/j.media.2021.102259},
    issn     = {1361-8415},
    journal  = {Medical Image Analysis},
    keywords = {Brain tumor segmentation, Data imbalance, Dynamic loss, Attention network},
    pages    = {102259},
    title    = {Relax and focus on brain tumor segmentation},
    volume   = {75},
    year     = {2022}
}
@article{wang2022deep,
    abstract = {Abstract Visual understanding on construction sites by deep learning, such as semantic segmentation, is hardly mentioned in the literature due to the severe lack of labeled data sets. To resolve this issue, we collect and label 859 images, including 12 classes of objects in construction activities, from different construction sites. We then adopt DeepLabV3+ on this data set with modifications. We leverage the Cityscape data set to pretrain the model, and then fine-tune it on our collected data set. Moreover, multiple data augmentation techniques are utilized to expand the training data set. Our model reaches 0.6467 mean intersection over union (mIoU) and 92.62{\%} mean pixel accuracy (mPA) in the out-of-sample test with the capability of processing over 45 frames per second with a resolution of pixels. In addition, we develop a synthetic robotic system integrated with red–green–blue (RGB)-depth camera for visual understanding on sites. It can detect the depth information of objects and has high potential in automated construction and visual surveillance.},
    author   = {Wang, Zifeng and Zhang, Yuyang and Mosalam, Khalid M. and Gao, Yuqing and Huang, Shao-Lun},
    doi      = {10.1111/mice.12701},
    eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/mice.12701},
    journal  = {Computer-Aided Civil and Infrastructure Engineering},
    number   = {2},
    pages    = {145-162},
    title    = {Deep semantic segmentation for visual understanding on construction sites},
    volume   = {37},
    year     = {2022}
}

@article{weisstein2003beta,
    author    = {Weisstein, Eric W},
    journal   = {https://mathworld. wolfram. com/},
    publisher = {Wolfram Research, Inc.},
    title     = {Beta distribution},
    url       = {https://mathworld.wolfram.com/BetaDistribution.html},
    year      = {2003}
}
@article{wetzstein2012tensor,
    author    = {Wetzstein, Gordon and Lanman, Douglas R and Hirsch, Matthew Waggener and Raskar, Ramesh},
    doi       = {10.1145/2185520.2335431},
    publisher = {Association for Computing Machinery},
    title     = {Tensor displays: compressive light field synthesis using multilayer displays with directional backlighting},
    year      = {2012}
}
@article{willemink2020preparing,
    abstract = { Artificial intelligence (AI) continues to garner substantial interest in medical imaging. The potential applications are vast and include the entirety of the medical imaging life cycle from image creation to diagnosis to outcome prediction. The chief obstacles to development and clinical implementation of AI algorithms include availability of sufficiently large, curated, and representative training data that includes expert labeling (eg, annotations). Current supervised AI methods require a curation process for data to optimally train, validate, and test algorithms. Currently, most research groups and industry have limited data access based on small sample sizes from small geographic areas. In addition, the preparation of data is a costly and time-intensive process, the results of which are algorithms with limited utility and poor generalization. In this article, the authors describe fundamental steps for preparing medical imaging data in AI algorithm development, explain current limitations to data curation, and explore new approaches to address the problem of data availability. © RSNA, 2020 },
    author   = {Willemink, Martin J. and Koszek, Wojciech A. and Hardell, Cailin and Wu, Jie and Fleischmann, Dominik and Harvey, Hugh and Folio, Les R. and Summers, Ronald M. and Rubin, Daniel L. and Lungren, Matthew P.},
    doi      = {10.1148/radiol.2020192224},
    eprint   = {https://doi.org/10.1148/radiol.2020192224},
    journal  = {Radiology},
    note     = {PMID: 32068507},
    number   = {1},
    pages    = {4-15},
    title    = {Preparing Medical Imaging Data for Machine Learning},
    volume   = {295},
    year     = {2020}
}
@article{WOLPERT1992241,
    abstract = {This paper introduces stacked generalization, a scheme for minimizing the generalization error rate of one or more generalizers. Stacked generalization works by deducing the biases of the generalizer(s) with respect to a provided learning set. This deduction proceeds by generalizing in a second space whose inputs are (for example) the guesses of the original generalizers when taught with part of the learning set and trying to guess the rest of it, and whose output is (for example) the correct guess. When used with multiple generalizers, stacked generalization can be seen as a more sophisticated version of cross-validation, exploiting a strategy more sophisticated than cross-validation's crude winner-takes-all for combining the individual generalizers. When used with a single generalizer, stacked generalization is a scheme for estimating (and then correcting for) the error of a generalizer which has been trained on a particular learning set and then asked a particular question. After introducing stacked generalization and justifying its use, this paper presents two numerical experiments. The first demonstrates how stacked generalization improves upon a set of separate generalizers for the NETtalk task of translating text to phonemes. The second demonstrates how stacked generalization improves the performance of a single surface-fitter. With the other experimental evidence in the literature, the usual arguments supporting cross-validation, and the abstract justifications presented in this paper, the conclusion is that for almost any real-world generalization problem one should use some version of stacked generalization to minimize the generalization error rate. This paper ends by discussing some of the variations of stacked generalization, and how it touches on other fields like chaos theory.},
    author   = {David H. Wolpert},
    doi      = {10.1016/S0893-6080(05)80023-1},
    issn     = {0893-6080},
    journal  = {Neural Networks},
    keywords = {Generalization and induction, Combining generalizers, Learning set preprocessing, cross-validation, Error estimation and correction},
    number   = {2},
    pages    = {241-259},
    title    = {Stacked generalization},
    volume   = {5},
    year     = {1992}
} 

@article{WU201926,
    abstract = {Hyperparameters are important for machine learning algorithms since they directly control the behaviors of training algorithms and have a significant effect on the performance of machine learning models. Several techniques have been developed and successfully applied for certain application domains. However, this work demands professional knowledge and expert experience. And sometimes it has to resort to the brute-force search. Therefore, if an efficient hyperparameter optimization algorithm can be developed to optimize any given machine learning method, it will greatly improve the efficiency of machine learning. In this paper, we consider building the relationship between the performance of the machine learning models and their hyperparameters by Gaussian processes. In this way, the hyperparameter tuning problem can be abstracted as an optimization problem and Bayesian optimization is used to solve the problem. Bayesian optimization is based on the Bayesian theorem. It sets a prior over the optimization function and gathers the information from the previous sample to update the posterior of the optimization function. A utility function selects the next sample point to maximize the optimization function. Several experiments were conducted on standard test datasets. Experiment results show that the proposed method can find the best hyperparameters for the widely used machine learning models, such as the random forest algorithm and the neural networks, even multi-grained cascade forest under the consideration of time cost.},
    author   = {Jia Wu and Xiu-Yun Chen and Hao Zhang and Li-Dong Xiong and Hang Lei and Si-Hao Deng},
    doi      = {10.11989/JEST.1674-862X.80904120},
    issn     = {1674-862X},
    journal  = {Journal of Electronic Science and Technology},
    keywords = {Bayesian optimization, Gaussian process, hyperparameter optimization, machine learning},
    number   = {1},
    pages    = {26-40},
    title    = {Hyperparameter Optimization for Machine Learning Models Based on Bayesian Optimizationb},
    volume   = {17},
    year     = {2019}
}
@article{wu2020application,
    abstract = {Landslides are a common type of natural disaster that brings great threats to the human lives and economic development around the world, especially in the Chinese Loess Plateau. Longxian County (Shaanxi Province, China), a landslide-prone area located in the southwest part of the Loess Plateau, was selected as the study area. The main purpose of this paper is to map landslide susceptibility using Alternating decision tree (ADTree) as well as GIS-based new ensemble techniques involving ADTree with bootstrap aggregation (Bagging) and ADTree with adaptive boosting (AdaBoost). Initially, a landslide inventory map was prepared with 171 determined historical landslides events in the study area, 120 landslides (70{\%}) were randomly selected for training dataset and the remaining 51 landslides (30{\%}) were used for validation dataset. Subsequently, eleven landslide conditioning factors were considered in the landslide susceptibility mapping. Then, an optimization operation on selection of landslide conditioning factors was performed using correlation attribute evaluation method and Spearman’s rank correlation coefficient. Afterwards, landslide susceptibility maps were generated with the three models. Finally, receiver operating characteristic (ROC) curve, area under the ROC curve (AUC) and statistical measures were applied to evaluate and validate the performance of the models. The results show success rates of the ADTree model, the ADTree with Bagging (ADTree-Bagging) model and the ADTree with AdaBoost (ADTree-AdaBoost) model were 0.872, 0.917, and 0.984, respectively, while prediction rates of the three models were 0.696, 0.752 and 0.787, respectively. In sum, the two ensemble models proposed prohibited better performance than the ADTree model did, and the ADTree-AdaBoost model was selected as the best model in the study. Hence, ensemble techniques can provide new and promising methods for spatial prediction and zonation of landslide susceptibility.},
    author   = {Yanli Wu and Yutian Ke and Zhuo Chen and Shouyun Liang and Hongliang Zhao and Haoyuan Hong},
    doi      = {10.1016/j.catena.2019.104396},
    issn     = {0341-8162},
    journal  = {CATENA},
    keywords = {Landslides, Ensemble model, Alternating decision tree, Bagging, AdaBoost, Spatial Analysis},
    pages    = {104396},
    title    = {Application of alternating decision tree with AdaBoost and bagging ensembles for landslide susceptibility mapping},
    volume   = {187},
    year     = {2020}
}
@article{WURM201959,
    abstract = {Unprecedented urbanization in particular in countries of the global south result in informal urban development processes, especially in mega cities. With an estimated 1 billion slum dwellers globally, the United Nations have made the fight against poverty the number one sustainable development goal. To provide better infrastructure and thus a better life to slum dwellers, detailed information on the spatial location and size of slums is of crucial importance. In the past, remote sensing has proven to be an extremely valuable and effective tool for mapping slums. The nature of used mapping approaches by machine learning, however, made it necessary to invest a lot of effort in training the models. Recent advances in deep learning allow for transferring trained fully convolutional networks (FCN) from one data set to another. Thus, in our study we aim at analyzing transfer learning capabilities of FCNs to slum mapping in various satellite images. A model trained on very high resolution optical satellite imagery from QuickBird is transferred to Sentinel-2 and TerraSAR-X data. While free-of-charge Sentinel-2 data is widely available, its comparably lower resolution makes slum mapping a challenging task. TerraSAR-X data on the other hand, has a higher resolution and is considered a powerful data source for intra-urban structure analysis. Due to the different image characteristics of SAR compared to optical data, however, transferring the model could not improve the performance of semantic segmentation but we observe very high accuracies for mapped slums in the optical data: QuickBird image obtains 86–88{\%} (positive prediction value and sensitivity) and a significant increase for Sentinel-2 applying transfer learning can be observed (from 38 to 55{\%} and from 79 to 85{\%} for PPV and sensitivity, respectively). Using transfer learning proofs extremely valuable in retrieving information on small-scaled urban structures such as slum patches even in satellite images of decametric resolution.},
    author   = {Michael Wurm and Thomas Stark and Xiao Xiang Zhu and Matthias Weigand and Hannes Taubenböck},
    doi      = {10.1016/j.isprsjprs.2019.02.006},
    issn     = {0924-2716},
    journal  = {ISPRS Journal of Photogrammetry and Remote Sensing},
    keywords = {Slums, FCN, Convolutional neural networks, Deep learning, Transfer learning},
    pages    = {59-69},
    title    = {Semantic segmentation of slums in satellite images using transfer learning on fully convolutional neural networks},
    volume   = {150},
    year     = {2019}
}
@misc{Xie_2020_ACCV,
    author    = {Xie, Shuai and Feng, Zunlei and Chen, Ying and Sun, Songtao and Ma, Chao and Song, Mingli},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2010.08705},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {DEAL: Difficulty-aware Active Learning for Semantic Segmentation},
    year      = {2020}
}
@article{XU2014591,
    abstract = {Labeling a histopathology image as having cancerous regions or not is a critical task in cancer diagnosis; it is also clinically important to segment the cancer tissues and cluster them into various classes. Existing supervised approaches for image classification and segmentation require detailed manual annotations for the cancer pixels, which are time-consuming to obtain. In this paper, we propose a new learning method, multiple clustered instance learning (MCIL) (along the line of weakly supervised learning) for histopathology image segmentation. The proposed MCIL method simultaneously performs image-level classification (cancer vs. non-cancer image), medical image segmentation (cancer vs. non-cancer tissue), and patch-level clustering (different classes). We embed the clustering concept into the multiple instance learning (MIL) setting and derive a principled solution to performing the above three tasks in an integrated framework. In addition, we introduce contextual constraints as a prior for MCIL, which further reduces the ambiguity in MIL. Experimental results on histopathology colon cancer images and cytology images demonstrate the great advantage of MCIL over the competing methods.},
    author   = {Yan Xu and Jun-Yan Zhu and Eric I-Chao Chang and Maode Lai and Zhuowen Tu},
    doi      = {10.1016/j.media.2014.01.010},
    issn     = {1361-8415},
    journal  = {Medical Image Analysis},
    keywords = {Image segmentation, Classification, Clustering, Multiple instance learning, Histopathology image},
    number   = {3},
    pages    = {591-604},
    title    = {Weakly supervised histopathology cancer image segmentation and classification},
    volume   = {18},
    year     = {2014}
}

@misc{yang2019major,
    author = {Su Yang and Jihoon Kweon and Young-Hak Kim},
    title  = {Major Vessel Segmentation on X-ray Coronary Angiography using Deep Networks with a Novel Penalty Loss Function},
    url    = {https://openreview.net/forum?id=H1lTh8unKN},
    year   = {2019}
}
@article{YEUNG2022102026,
    abstract = {Automatic segmentation methods are an important advancement in medical image analysis. Machine learning techniques, and deep neural networks in particular, are the state-of-the-art for most medical image segmentation tasks. Issues with class imbalance pose a significant challenge in medical datasets, with lesions often occupying a considerably smaller volume relative to the background. Loss functions used in the training of deep learning algorithms differ in their robustness to class imbalance, with direct consequences for model convergence. The most commonly used loss functions for segmentation are based on either the cross entropy loss, Dice loss or a combination of the two. We propose the Unified Focal loss, a new hierarchical framework that generalises Dice and cross entropy-based losses for handling class imbalance. We evaluate our proposed loss function on five publicly available, class imbalanced medical imaging datasets: CVC-ClinicDB, Digital Retinal Images for Vessel Extraction (DRIVE), Breast Ultrasound 2017 (BUS2017), Brain Tumour Segmentation 2020 (BraTS20) and Kidney Tumour Segmentation 2019 (KiTS19). We compare our loss function performance against six Dice or cross entropy-based loss functions, across 2D binary, 3D binary and 3D multiclass segmentation tasks, demonstrating that our proposed loss function is robust to class imbalance and consistently outperforms the other loss functions. Source code is available at: https://github.com/mlyg/unified-focal-loss.},
    author   = {Michael Yeung and Evis Sala and Carola-Bibiane Schönlieb and Leonardo Rundo},
    doi      = {10.1016/j.compmedimag.2021.102026},
    issn     = {0895-6111},
    journal  = {Computerized Medical Imaging and Graphics},
    keywords = {Loss function, Class imbalance, Machine learning, Convolutional neural networks, Medical image segmentation},
    pages    = {102026},
    title    = {Unified Focal loss: Generalising Dice and cross entropy-based losses to handle class imbalanced medical image segmentation},
    volume   = {95},
    year     = {2022}
}
@article{yi2019generative,
    abstract = {Generative adversarial networks have gained a lot of attention in the computer vision community due to their capability of data generation without explicitly modelling the probability density function. The adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into training and imposing higher order consistency. This has proven to be useful in many cases, such as domain adaptation, data augmentation, and image-to-image translation. These properties have attracted researchers in the medical imaging community, and we have seen rapid adoption in many traditional and novel applications, such as image reconstruction, segmentation, detection, classification, and cross-modality synthesis. Based on our observations, this trend will continue and we therefore conducted a review of recent advances in medical imaging using the adversarial training scheme with the hope of benefiting researchers interested in this technique.},
    author   = {Xin Yi and Ekta Walia and Paul Babyn},
    doi      = {10.1016/j.media.2019.101552},
    issn     = {1361-8415},
    journal  = {Medical Image Analysis},
    keywords = {Deep learning, Generative adversarial network, Generative model, Medical imaging, Review},
    pages    = {101552},
    title    = {Generative adversarial network in medical imaging: A review},
    volume   = {58},
    year     = {2019}
}
@inproceedings{yoon2015learning,
    author    = {Yoon, Youngjin and Jeon, Hae-Gon and Yoo, Donggeun and Lee, Joon-Young and So Kweon, In},
    booktitle = {Proceedings of the IEEE international conference on computer vision workshops},
    doi       = {10.1109/ICCVW.2015.17},
    pages     = {24--32},
    title     = {Learning a deep convolutional network for light-field image super-resolution},
    year      = {2015}
}
@inproceedings{You_2019_CVPR,
    author    = {You, Kaichao and Long, Mingsheng and Cao, Zhangjie and Wang, Jianmin and Jordan, Michael I.},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {06},
    note      = {[Online; accessed 2. Jul. 2023]},
    title     = {Universal Domain Adaptation},
    url       = {https://openaccess.thecvf.com/content_CVPR_2019/html/You_Universal_Domain_Adaptation_CVPR_2019_paper.html},
    year      = {2019}
}

@misc{yu2016multiscale,
    archiveprefix = {arXiv},
    author        = {Fisher Yu and Vladlen Koltun},
    doi           = {10.48550/arXiv.1511.07122},
    eprint        = {1511.07122},
    primaryclass  = {cs.CV},
    title         = {Multi-Scale Context Aggregation by Dilated Convolutions},
    year          = {2016}
}
@article{YU201882,
    abstract = {Semantic segmentation, also called scene labeling, refers to the process of assigning a semantic label (e.g. car, people, and road) to each pixel of an image. It is an essential data processing step for robots and other unmanned systems to understand the surrounding scene. Despite decades of efforts, semantic segmentation is still a very challenging task due to large variations in natural scenes. In this paper, we provide a systematic review of recent advances in this field. In particular, three categories of methods are reviewed and compared, including those based on hand-engineered features, learned features and weakly supervised learning. In addition, we describe a number of popular datasets aiming for facilitating the development of new segmentation algorithms. In order to demonstrate the advantages and disadvantages of different semantic segmentation models, we conduct a series of comparisons between them. Deep discussions about the comparisons are also provided. Finally, this review is concluded by discussing future directions and challenges in this important field of research.},
    author   = {Hongshan Yu and Zhengeng Yang and Lei Tan and Yaonan Wang and Wei Sun and Mingui Sun and Yandong Tang},
    doi      = {10.1016/j.neucom.2018.03.037},
    issn     = {0925-2312},
    journal  = {Neurocomputing},
    keywords = {Semantic segmentation, Convolutional neural network, Markov random fields, Weakly supervised method, 3D point clouds labeling},
    pages    = {82-103},
    title    = {Methods and datasets on semantic segmentation: A review},
    volume   = {304},
    year     = {2018}
}
@article{Yu2022,
    abstract = {The Jaccard index, also known as Intersection-over-Union (IoU), is one of the most critical evaluation metrics in image semantic segmentation. However, direct optimization of IoU score is very difficult because the learning objective is neither differentiable nor decomposable. Although some algorithms have been proposed to optimize its surrogates, there is no guarantee provided for the generalization ability. In this paper, we propose a margin calibration method, which can be directly used as a learning objective, for an improved generalization of IoU over the data-distribution, underpinned by a rigid lower bound. This scheme theoretically ensures a better segmentation performance in terms of IoU score. We evaluated the effectiveness of the proposed margin calibration method on seven image datasets, showing substantial improvements in IoU score over other learning objectives using deep segmentation models.},
    author   = {Yu, Litao
                and Li, Zhibin
                and Xu, Min
                and Gao, Yongsheng
                and Luo, Jiebo
                and Zhang, Jian},
    day      = {01},
    doi      = {10.1007/s11263-021-01533-0},
    issn     = {1573-1405},
    journal  = {International Journal of Computer Vision},
    month    = {01},
    number   = {1},
    pages    = {95-110},
    title    = {Distribution-Aware Margin Calibration for Semantic Segmentation in Images},
    volume   = {130},
    year     = {2022}
}
@misc{yu2022generating,
    author    = {Yu, Sihyun and Tack, Jihoon and Mo, Sangwoo and Kim, Hyunsu and Kim, Junho and Ha, Jung-Woo and Shin, Jinwoo},
    copyright = {arXiv.org perpetual, non-exclusive license},
    doi       = {10.48550/ARXIV.2202.10571},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {Generating Videos with Dynamics-aware Implicit Generative Adversarial Networks},
    year      = {2022}
}
﻿@misc{Yuan_2021_ICCV,
    author    = {Yuan, Jianlong and Liu, Yifan and Shen, Chunhua and Wang, Zhibin and Li, Hao},
    copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
    doi       = {10.48550/ARXIV.2104.07256},
    keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    publisher = {arXiv},
    title     = {A Simple Baseline for Semi-supervised Semantic Segmentation with Strong Data Augmentation},
    year      = {2021}
}
@inproceedings{yun2017action,
    author    = {Yun, Sangdoo and Choi, Jongwon and Yoo, Youngjoon and Yun, Kimin and Young Choi, Jin},
    booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
    doi       = {10.1109/CVPR.2017.148},
    pages     = {2711--2720},
    title     = {Action-decision networks for visual tracking with deep reinforcement learning},
    year      = {2017}
}
﻿@article{Zhang2017ASO,
    author  = {Zhang, Yu and Yang, Qiang},
    doi     = {10.1109/TKDE.2021.3070203},
    doi     = {10.48550/arXiv.1707.08114},
    journal = {IEEE Transactions on Knowledge and Data Engineering},
    number  = {12},
    pages   = {5586-5609},
    title   = {A Survey on Multi-Task Learning},
    volume  = {34},
    year    = {2022}
}
@article{Zhang2018,
    abstract = {There is growing interest in applying machine learning techniques in the research of materials science. However, although it is recognized that materials datasets are typically smaller and sometimes more diverse compared to other fields, the influence of availability of materials data on training machine learning models has not yet been studied, which prevents the possibility to establish accurate predictive rules using small materials datasets. Here we analyzed the fundamental interplay between the availability of materials data and the predictive capability of machine learning models. Instead of affecting the model precision directly, the effect of data size is mediated by the degree of freedom (DoF) of model, resulting in the phenomenon of association between precision and DoF. The appearance of precision--DoF association signals the issue of underfitting and is characterized by large bias of prediction, which consequently restricts the accurate prediction in unknown domains. We proposed to incorporate the crude estimation of property in the feature space to establish ML models using small sized materials data, which increases the accuracy of prediction without the cost of higher DoF. In three case studies of predicting the band gap of binary semiconductors, lattice thermal conductivity, and elastic properties of zeolites, the integration of crude estimation effectively boosted the predictive capability of machine learning models to state-of-art levels, demonstrating the generality of the proposed strategy to construct accurate machine learning models using small materials dataset.},
    author   = {Zhang, Ying
                and Ling, Chen},
    day      = {14},
    doi      = {10.1038/s41524-018-0081-z},
    issn     = {2057-3960},
    journal  = {npj Computational Materials},
    month    = {05},
    number   = {1},
    pages    = {25},
    title    = {A strategy to apply machine learning to small datasets in materials science},
    volume   = {4},
    year     = {2018}
}
@inproceedings{zhang2020slimmer,
    author    = {Zhang, Huanle and Han, Bo and Ip, Cheuk Yiu and Mohapatra, Prasant},
    booktitle = {2020 IEEE 17th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)},
    doi       = {10.1109/MASS50613.2020.00079},
    number    = {},
    pages     = {603-612},
    title     = {Slimmer: Accelerating 3D Semantic Segmentation for Mobile Augmented Reality},
    volume    = {},
    year      = {2020}
}
@article{zhangzhonghengKNN,
    abstract = {Machine learning techniques have been widely used in many
                scientific fields, but its use in medical literature is limited
                partly because of technical difficulties. k-nearest neighbors
                (kNN) is a simple method of machine learning. The article
                introduces some basic ideas underlying the kNN algorithm, and
                then focuses on how to perform kNN modeling with R. The dataset
                should be prepared before running the knn() function in R. After
                prediction of outcome with kNN algorithm, the diagnostic
                performance of the model should be checked. Average accuracy is
                the mostly widely used statistic to reflect the kNN algorithm.
                Factors such as k value, distance calculation and choice of
                appropriate predictors all have significant impact on the model
                performance.},
    address  = {China},
    author   = {Zhang, Zhongheng},
    doi      = {10.21037/atm.2016.03.37},
    journal  = {Ann Transl Med},
    keywords = {Machine learning; R; average accuracy; class; k-nearest neighbors
                (kNN); kappa},
    language = {en},
    month    = jun,
    number   = 11,
    pages    = {218},
    title    = {Introduction to machine learning: k-nearest neighbors},
    volume   = 4,
    year     = 2016
}

@article{zhao2019object,
    author  = {Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-Tao and Wu, Xindong},
    doi     = {10.1109/TNNLS.2018.2876865},
    journal = {IEEE Transactions on Neural Networks and Learning Systems},
    number  = {11},
    pages   = {3212-3232},
    title   = {Object Detection With Deep Learning: A Review},
    volume  = {30},
    year    = {2019}
}
﻿@inproceedings{Zhou_2019_CVPR,
    author    = {Zhou, Yizhou and Sun, Xiaoyan and Zha, Zheng-Jun and Zeng, Wenjun},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    doi       = {10.1109/CVPR.2019.00417},
    month     = {06},
    title     = {Context-Reinforced Semantic Segmentation},
    year      = {2019}
}
@inproceedings{zhou2016learning,
    author    = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
    booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
    doi       = {10.48550/arXiv.1512.04150},
    pages     = {2921--2929},
    title     = {Learning deep features for discriminative localization},
    year      = {2016}
}
@inproceedings{zhou2017scene,
    author    = {Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
    booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
    doi       = {10.1109/CVPR.2017.544},
    pages     = {633--641},
    title     = {Scene parsing through ade20k dataset},
    year      = {2017}
}
@article{zhou2019automated,
    author  = {Zhou, Wei and Berrio, Julie Stephany and Worrall, Stewart and Nebot, Eduardo},
    doi     = {10.1109/TITS.2019.2909066},
    journal = {IEEE Transactions on Intelligent Transportation Systems},
    number  = {5},
    pages   = {1951-1963},
    title   = {Automated Evaluation of Semantic Segmentation Robustness for Autonomous Driving},
    volume  = {21},
    year    = {2020}
}
@article{zhou2019optimization,
    author     = {Zhenpeng Zhou and
                  Steven Kearnes and
                  Li Li and
                  Richard N. Zare and
                  Patrick Riley},
    bibsource  = {dblp computer science bibliography, https://dblp.org},
    biburl     = {https://dblp.org/rec/journals/corr/abs-1810-08678.bib},
    doi        = {10.1038/s41598-019-47148-x},
    eprint     = {1810.08678},
    eprinttype = {arXiv},
    journal    = {CoRR},
    timestamp  = {Wed, 20 Apr 2022 14:23:15 +0200},
    title      = {Optimization of Molecules via Deep Reinforcement Learning},
    volume     = {abs/1810.08678},
    year       = {2018}
}
@article{zhu2005semi,
    author    = {Zhu, Xiaojin Jerry},
    publisher = {University of Wisconsin-Madison Department of Computer Sciences},
    title     = {Semi-supervised learning literature survey},
    url       = {http://digital.library.wisc.edu/1793/60444},
    year      = {2005}
}
@article{zhu2009introduction,
    author    = {Zhu, Xiaojin and Goldberg, Andrew B},
    journal   = {Synthesis lectures on artificial intelligence and machine learning},
    number    = {1},
    pages     = {1--130},
    publisher = {Morgan \& Claypool Publishers},
    title     = {Introduction to semi-supervised learning},
    url       = {https://link.springer.com/book/10.1007/978-3-031-01548-9},
    volume    = {3},
    year      = {2009}
}
@inproceedings{zou2019finite,
    author    = {Zou, Shaofeng and Xu, Tengyu and Liang, Yingbin},
    booktitle = {Advances in Neural Information Processing Systems},
    doi       = {10.48550/arXiv.1902.02234},
    editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages     = {},
    publisher = {Curran Associates, Inc.},
    title     = {Finite-Sample Analysis for SARSA with Linear Function Approximation},
    volume    = {32},
    year      = {2019}
}
@article{zou2019primer,
    abstract = {Deep learning methods are a class of machine learning techniques capable of identifying highly complex patterns in large datasets. Here, we provide a perspective and primer on deep learning applications for genome analysis. We discuss successful applications in the fields of regulatory genomics, variant calling and pathogenicity scores. We include general guidance for how to effectively use deep learning methods as well as a practical guide to tools and resources. This primer is accompanied by an interactive online tutorial.},
    author   = {Zou, James
                and Huss, Mikael
                and Abid, Abubakar
                and Mohammadi, Pejman
                and Torkamani, Ali
                and Telenti, Amalio},
    day      = {01},
    doi      = {10.1038/s41588-018-0295-5},
    issn     = {1546-1718},
    journal  = {Nature Genetics},
    month    = {01},
    number   = {1},
    pages    = {12-18},
    title    = {A primer on deep learning in genomics},
    volume   = {51},
    year     = {2019}
}